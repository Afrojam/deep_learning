{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# MAI - Deep Learning: Autonomous Lab 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Jamie Arjona Mart√≠nez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from pathlib import Path\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import ipdb\n",
    "from ipdb import set_trace as bp\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import plot_model\n",
    "from keras.models import model_from_json #to load a model from a json file.\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "np.random.seed(12345678)\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Feedforward NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using keras version 2.2.2\n",
      "\n",
      "\n",
      "Number of training examples: '60000'\n",
      "Size of train samples: '(28, 28)'\n",
      "Size of test samples: '(28, 28)'\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.1193 - acc: 0.1907 - val_loss: 2.0099 - val_acc: 0.2334\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.9285 - acc: 0.2879 - val_loss: 1.8507 - val_acc: 0.3061\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.8212 - acc: 0.3080 - val_loss: 1.7815 - val_acc: 0.3216\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.7572 - acc: 0.3185 - val_loss: 1.7204 - val_acc: 0.3275\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.7034 - acc: 0.3260 - val_loss: 1.6766 - val_acc: 0.3361\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 1.6662 - acc: 0.3335 - val_loss: 1.6446 - val_acc: 0.3412\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 1.6368 - acc: 0.3439 - val_loss: 1.6179 - val_acc: 0.3616\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 1.6089 - acc: 0.3584 - val_loss: 1.5905 - val_acc: 0.3700\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.5815 - acc: 0.3717 - val_loss: 1.5631 - val_acc: 0.3841\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 1.5536 - acc: 0.3848 - val_loss: 1.5340 - val_acc: 0.4006\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 1.5004 - acc: 0.4291 - val_loss: 1.4546 - val_acc: 0.4778\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 1.4063 - acc: 0.5027 - val_loss: 1.3621 - val_acc: 0.5294\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.3201 - acc: 0.5361 - val_loss: 1.2933 - val_acc: 0.5438\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.2612 - acc: 0.5573 - val_loss: 1.2393 - val_acc: 0.5686\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.2066 - acc: 0.5895 - val_loss: 1.1782 - val_acc: 0.5952\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.1349 - acc: 0.6257 - val_loss: 1.1033 - val_acc: 0.6375\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 1.0615 - acc: 0.6657 - val_loss: 1.0331 - val_acc: 0.6726\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.9949 - acc: 0.6849 - val_loss: 0.9748 - val_acc: 0.6900\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.9426 - acc: 0.6974 - val_loss: 0.9322 - val_acc: 0.6972\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.9027 - acc: 0.7072 - val_loss: 0.9005 - val_acc: 0.7047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16045976978>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16045989198>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16045951748>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160459d76d8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160459d7828>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160459c70f0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       980\n",
      "           1       0.98      0.96      0.97      1135\n",
      "           2       0.28      0.02      0.03      1032\n",
      "           3       0.60      0.78      0.68      1010\n",
      "           4       0.84      0.91      0.87       982\n",
      "           5       0.73      0.66      0.69       892\n",
      "           6       0.36      0.89      0.51       958\n",
      "           7       0.92      0.89      0.90      1028\n",
      "           8       0.65      0.12      0.20       974\n",
      "           9       0.82      0.87      0.84      1009\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.71      0.70      0.66     10000\n",
      "weighted avg       0.71      0.70      0.67     10000\n",
      "\n",
      "[[ 907    0    0   17    0   48    1    7    0    0]\n",
      " [   0 1093    1    1   23    0    7    0    1    9]\n",
      " [   1    0   16   63   32    7  875    4   27    7]\n",
      " [   7    0    1  791    0  147   25   17   13    9]\n",
      " [   0    6    8    2  891    0   12    1    1   61]\n",
      " [  73    0    1  192    1  588   13   13    3    8]\n",
      " [   3    1   11   48   16    5  854    0   17    3]\n",
      " [   0    4    1   10    8    1    4  918    1   81]\n",
      " [   2    1   18  181   22   10  599    9  116   16]\n",
      " [   3    6    0   22   65    2    4   34    0  873]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 1.8007 - acc: 0.3532 - val_loss: 1.2641 - val_acc: 0.6390\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.8751 - acc: 0.7556 - val_loss: 0.6347 - val_acc: 0.8158\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.5559 - acc: 0.8422 - val_loss: 0.4756 - val_acc: 0.8635\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.4449 - acc: 0.8746 - val_loss: 0.3953 - val_acc: 0.8847\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.3800 - acc: 0.8931 - val_loss: 0.3469 - val_acc: 0.9018\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.3338 - acc: 0.9055 - val_loss: 0.3072 - val_acc: 0.9128\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2987 - acc: 0.9156 - val_loss: 0.2788 - val_acc: 0.9197\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2722 - acc: 0.9231 - val_loss: 0.2570 - val_acc: 0.9248\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2506 - acc: 0.9290 - val_loss: 0.2402 - val_acc: 0.9314\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2326 - acc: 0.9335 - val_loss: 0.2248 - val_acc: 0.9338\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2173 - acc: 0.9378 - val_loss: 0.2122 - val_acc: 0.9376\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2045 - acc: 0.9420 - val_loss: 0.2032 - val_acc: 0.9398\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1923 - acc: 0.9454 - val_loss: 0.1934 - val_acc: 0.9439\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1826 - acc: 0.9482 - val_loss: 0.1847 - val_acc: 0.9448\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1735 - acc: 0.9507 - val_loss: 0.1760 - val_acc: 0.9478\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1653 - acc: 0.9526 - val_loss: 0.1790 - val_acc: 0.9465\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1583 - acc: 0.9549 - val_loss: 0.1705 - val_acc: 0.9494\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1519 - acc: 0.9578 - val_loss: 0.1637 - val_acc: 0.9510\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1456 - acc: 0.9589 - val_loss: 0.1616 - val_acc: 0.9530\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1400 - acc: 0.9606 - val_loss: 0.1537 - val_acc: 0.9547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049ac16d8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049ac1b70>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16049adf2e8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160196f67f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160196f6cf8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160458edfd0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.94      0.97      0.95      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.96      0.95      0.95       982\n",
      "           5       0.97      0.93      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.94      0.93      0.93       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[[ 959    0    3    3    0    4    4    2    4    1]\n",
      " [   0 1116    2    2    0    1    4    2    8    0]\n",
      " [   4    1  997    3    4    0    2    7   10    4]\n",
      " [   2    1   15  959    0    8    0   12   10    3]\n",
      " [   2    0    9    0  934    0    9    3    5   20]\n",
      " [   6    3    0   19    2  832   14    3   10    3]\n",
      " [   5    4    3    0   11    7  926    0    2    0]\n",
      " [   2    7   27    6    2    0    0  967    0   17]\n",
      " [   5    3    6   17    7    8   11    4  908    5]\n",
      " [   8    2    3    5   18    2    0    8   14  949]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.8202 - acc: 0.4579 - val_loss: 1.0114 - val_acc: 0.7580\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.6554 - acc: 0.8262 - val_loss: 0.4692 - val_acc: 0.8638\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.4313 - acc: 0.8765 - val_loss: 0.3722 - val_acc: 0.8917\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3678 - acc: 0.8940 - val_loss: 0.3329 - val_acc: 0.8999\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3313 - acc: 0.9042 - val_loss: 0.3021 - val_acc: 0.9087\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3046 - acc: 0.9126 - val_loss: 0.2832 - val_acc: 0.9162\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2821 - acc: 0.9188 - val_loss: 0.2631 - val_acc: 0.9216\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2637 - acc: 0.9241 - val_loss: 0.2480 - val_acc: 0.9269\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2472 - acc: 0.9289 - val_loss: 0.2307 - val_acc: 0.9333\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2329 - acc: 0.9329 - val_loss: 0.2199 - val_acc: 0.9355\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2198 - acc: 0.9369 - val_loss: 0.2100 - val_acc: 0.9377\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2081 - acc: 0.9403 - val_loss: 0.1975 - val_acc: 0.9420\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1973 - acc: 0.9437 - val_loss: 0.1899 - val_acc: 0.9464\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1877 - acc: 0.9465 - val_loss: 0.1838 - val_acc: 0.9480\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1787 - acc: 0.9491 - val_loss: 0.1722 - val_acc: 0.9509\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1710 - acc: 0.9511 - val_loss: 0.1687 - val_acc: 0.9524\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1635 - acc: 0.9530 - val_loss: 0.1612 - val_acc: 0.9540\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1568 - acc: 0.9553 - val_loss: 0.1566 - val_acc: 0.9551\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1508 - acc: 0.9561 - val_loss: 0.1493 - val_acc: 0.9569\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1448 - acc: 0.9585 - val_loss: 0.1466 - val_acc: 0.9573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16041e25128>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16044cb9668>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16044cb9240>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16041b747f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16041b405f8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16041b55208>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.93      0.97      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.96      0.93      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.97      0.94      0.95      1028\n",
      "           8       0.95      0.93      0.94       974\n",
      "           9       0.95      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 961    1    2    1    0    4    6    4    1    0]\n",
      " [   0 1114    2    2    1    1    4    2    9    0]\n",
      " [   3    2  995   10    4    2    2    4   10    0]\n",
      " [   0    1    9  975    1    6    0    9    8    1]\n",
      " [   2    0    4    0  947    0    9    2    2   16]\n",
      " [   6    2    2   24    4  831    9    1    9    4]\n",
      " [   7    3    1    0    9   10  924    1    3    0]\n",
      " [   2   13   15    6    3    1    0  964    1   23]\n",
      " [   5    2    7   19    8    7    7    4  910    5]\n",
      " [   7    6    1   12   19    2    0    6    4  952]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6406 - acc: 0.5075 - val_loss: 0.8538 - val_acc: 0.7922\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.6041 - acc: 0.8399 - val_loss: 0.4427 - val_acc: 0.8768\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.4094 - acc: 0.8853 - val_loss: 0.3552 - val_acc: 0.8990\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.3450 - acc: 0.9014 - val_loss: 0.3106 - val_acc: 0.9086\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3083 - acc: 0.9116 - val_loss: 0.2857 - val_acc: 0.9168\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2819 - acc: 0.9194 - val_loss: 0.2647 - val_acc: 0.9231\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2610 - acc: 0.9245 - val_loss: 0.2427 - val_acc: 0.9306\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2439 - acc: 0.9300 - val_loss: 0.2317 - val_acc: 0.9338\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2290 - acc: 0.9336 - val_loss: 0.2174 - val_acc: 0.9378\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2165 - acc: 0.9369 - val_loss: 0.2092 - val_acc: 0.9382\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2050 - acc: 0.9404 - val_loss: 0.1962 - val_acc: 0.9431\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1946 - acc: 0.9430 - val_loss: 0.1920 - val_acc: 0.9436\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1859 - acc: 0.9453 - val_loss: 0.1820 - val_acc: 0.9472\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1771 - acc: 0.9482 - val_loss: 0.1771 - val_acc: 0.9479\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1697 - acc: 0.9506 - val_loss: 0.1678 - val_acc: 0.9503\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1630 - acc: 0.9528 - val_loss: 0.1606 - val_acc: 0.9529\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1563 - acc: 0.9546 - val_loss: 0.1558 - val_acc: 0.9540\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1509 - acc: 0.9559 - val_loss: 0.1516 - val_acc: 0.9552\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1451 - acc: 0.9578 - val_loss: 0.1475 - val_acc: 0.9575\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1400 - acc: 0.9594 - val_loss: 0.1439 - val_acc: 0.9578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160339b62b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160339b6128>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16033f73d68>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16033948f28>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16033956f60>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16033964908>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.93      0.97      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.93      0.94       892\n",
      "           6       0.96      0.95      0.96       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.95      0.94      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    2    2    0    5    3    1    1    0]\n",
      " [   0 1121    3    2    0    2    1    2    4    0]\n",
      " [   6    1  993   12    3    1    3    4    7    2]\n",
      " [   0    0    7  982    0    2    0    8   11    0]\n",
      " [   1    0    1    1  944    0   11    1    4   19]\n",
      " [   8    1    1   23    2  828   12    1   11    5]\n",
      " [   9    3    3    3    9   13  914    0    4    0]\n",
      " [   0   10   18    3    3    2    0  970    1   21]\n",
      " [   3    2    6   18    5    9    8    4  915    4]\n",
      " [   6    7    4   12   19    3    1    8    4  945]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 1.5410 - acc: 0.5615 - val_loss: 0.7669 - val_acc: 0.8040\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.5842 - acc: 0.8396 - val_loss: 0.4512 - val_acc: 0.8741\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.4192 - acc: 0.8802 - val_loss: 0.3649 - val_acc: 0.8954\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.3592 - acc: 0.8974 - val_loss: 0.3269 - val_acc: 0.9050\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3236 - acc: 0.9067 - val_loss: 0.2999 - val_acc: 0.9127\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2980 - acc: 0.9148 - val_loss: 0.2815 - val_acc: 0.9199\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2773 - acc: 0.9196 - val_loss: 0.2653 - val_acc: 0.9220\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2589 - acc: 0.9247 - val_loss: 0.2501 - val_acc: 0.9271\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2424 - acc: 0.9296 - val_loss: 0.2327 - val_acc: 0.9321\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2280 - acc: 0.9347 - val_loss: 0.2231 - val_acc: 0.9350\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2152 - acc: 0.9377 - val_loss: 0.2125 - val_acc: 0.9365\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2034 - acc: 0.9416 - val_loss: 0.2013 - val_acc: 0.9402\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1923 - acc: 0.9453 - val_loss: 0.1906 - val_acc: 0.9441\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1828 - acc: 0.9477 - val_loss: 0.1846 - val_acc: 0.9459\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1743 - acc: 0.9501 - val_loss: 0.1819 - val_acc: 0.9442\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1666 - acc: 0.9522 - val_loss: 0.1751 - val_acc: 0.9488\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1596 - acc: 0.9543 - val_loss: 0.1633 - val_acc: 0.9525\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1534 - acc: 0.9562 - val_loss: 0.1625 - val_acc: 0.9529\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1470 - acc: 0.9578 - val_loss: 0.1555 - val_acc: 0.9553\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1420 - acc: 0.9591 - val_loss: 0.1505 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1602e55c518>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1602e55ca58>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1602e59f748>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1602ff719b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1602ff71518>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1602a4a5cf8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.93      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.95      0.94      0.94       892\n",
      "           6       0.97      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.96      0.93      0.94       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 970    0    1    1    0    3    2    1    1    1]\n",
      " [   0 1118    2    2    0    2    1    2    8    0]\n",
      " [   6    4  978   15    9    1    6    4    9    0]\n",
      " [   1    0    6  972    0    8    0   10    9    4]\n",
      " [   1    0    6    0  944    1    7    2    2   19]\n",
      " [  10    1    1   17    3  838   10    1    7    4]\n",
      " [  10    3    3    1    5   12  919    2    3    0]\n",
      " [   1   12   12    5    5    0    0  973    1   19]\n",
      " [   4    3    5   23    6   14    5    4  905    5]\n",
      " [   8    5    0    8   22    5    0   11    2  948]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 1.3967 - acc: 0.6103 - val_loss: 0.6325 - val_acc: 0.8268\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.5033 - acc: 0.8605 - val_loss: 0.3994 - val_acc: 0.8872\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3774 - acc: 0.8932 - val_loss: 0.3336 - val_acc: 0.9042\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3264 - acc: 0.9073 - val_loss: 0.2977 - val_acc: 0.9134\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2955 - acc: 0.9160 - val_loss: 0.2751 - val_acc: 0.9210\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2728 - acc: 0.9225 - val_loss: 0.2585 - val_acc: 0.9238\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2541 - acc: 0.9276 - val_loss: 0.2429 - val_acc: 0.9287\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2383 - acc: 0.9322 - val_loss: 0.2279 - val_acc: 0.9332\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2239 - acc: 0.9365 - val_loss: 0.2166 - val_acc: 0.9354\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2118 - acc: 0.9401 - val_loss: 0.2051 - val_acc: 0.9386\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2000 - acc: 0.9435 - val_loss: 0.1989 - val_acc: 0.9406\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1904 - acc: 0.9455 - val_loss: 0.1866 - val_acc: 0.9442\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1811 - acc: 0.9486 - val_loss: 0.1814 - val_acc: 0.9452\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1728 - acc: 0.9507 - val_loss: 0.1746 - val_acc: 0.9475\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1651 - acc: 0.9528 - val_loss: 0.1652 - val_acc: 0.9519\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1578 - acc: 0.9547 - val_loss: 0.1616 - val_acc: 0.9518\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.1509 - acc: 0.9559 - val_loss: 0.1565 - val_acc: 0.9535\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1449 - acc: 0.9580 - val_loss: 0.1563 - val_acc: 0.9542\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.1392 - acc: 0.9596 - val_loss: 0.1484 - val_acc: 0.9566\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1341 - acc: 0.9611 - val_loss: 0.1415 - val_acc: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603d0da860>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603d0da4a8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1603d0ef908>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16038ed11d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1601dd21ac8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16038ee2940>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.95      0.95      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.97      0.96       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 967    0    1    2    1    4    3    2    0    0]\n",
      " [   0 1122    3    1    0    1    2    1    5    0]\n",
      " [   6    2  985    8    8    0    5   10    5    3]\n",
      " [   1    1   13  967    0    7    0    8    7    6]\n",
      " [   2    0    5    0  945    0    8    2    4   16]\n",
      " [   8    1    0   14    4  836   10    1   10    8]\n",
      " [   8    3    3    0    5   10  926    0    3    0]\n",
      " [   1   12   22    4    2    0    0  964    0   23]\n",
      " [   3    1    3   15    5   10    7    5  917    8]\n",
      " [   5    4    1    8   24    3    1    7    9  947]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.5103 - acc: 0.5833 - val_loss: 0.6952 - val_acc: 0.8279\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.5268 - acc: 0.8577 - val_loss: 0.4150 - val_acc: 0.8799\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3892 - acc: 0.8880 - val_loss: 0.3480 - val_acc: 0.8969\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3368 - acc: 0.9026 - val_loss: 0.3075 - val_acc: 0.9097\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3036 - acc: 0.9131 - val_loss: 0.2811 - val_acc: 0.9189\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2786 - acc: 0.9188 - val_loss: 0.2608 - val_acc: 0.9236\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2579 - acc: 0.9254 - val_loss: 0.2428 - val_acc: 0.9288\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2402 - acc: 0.9310 - val_loss: 0.2264 - val_acc: 0.9349\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2249 - acc: 0.9350 - val_loss: 0.2145 - val_acc: 0.9384\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2117 - acc: 0.9388 - val_loss: 0.2020 - val_acc: 0.9401\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2002 - acc: 0.9424 - val_loss: 0.1899 - val_acc: 0.9456\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1901 - acc: 0.9453 - val_loss: 0.1846 - val_acc: 0.9463\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1806 - acc: 0.9478 - val_loss: 0.1743 - val_acc: 0.9505\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1723 - acc: 0.9499 - val_loss: 0.1683 - val_acc: 0.9518\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1644 - acc: 0.9523 - val_loss: 0.1612 - val_acc: 0.9544\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.1572 - acc: 0.9539 - val_loss: 0.1549 - val_acc: 0.9563\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.1507 - acc: 0.9562 - val_loss: 0.1511 - val_acc: 0.9564\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1444 - acc: 0.9578 - val_loss: 0.1438 - val_acc: 0.9590\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1386 - acc: 0.9597 - val_loss: 0.1399 - val_acc: 0.9596\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1332 - acc: 0.9617 - val_loss: 0.1360 - val_acc: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1602ff206d8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603059d630>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160305313c8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160450f05c0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1601aa1a8d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1601aa1af98>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.95      0.96       892\n",
      "           6       0.96      0.97      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.94      0.95      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 962    0    0    3    0    3    7    2    1    2]\n",
      " [   0 1119    2    3    0    1    3    1    6    0]\n",
      " [   6    3  989    9    3    0    4    8    8    2]\n",
      " [   1    0   12  969    0   11    0    9    5    3]\n",
      " [   1    0    5    1  944    0    6    2    2   21]\n",
      " [   5    1    0   12    2  846    9    0   10    7]\n",
      " [   6    3    4    1    6    7  925    3    3    0]\n",
      " [   0    7   17    4    3    1    0  979    1   16]\n",
      " [   5    2    3   12    9    7   10    6  915    5]\n",
      " [   6    7    2   11   15    2    1    7    0  958]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 1.3729 - acc: 0.6280 - val_loss: 0.6263 - val_acc: 0.8323\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4993 - acc: 0.8655 - val_loss: 0.4020 - val_acc: 0.8835\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3757 - acc: 0.8944 - val_loss: 0.3362 - val_acc: 0.9041\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3254 - acc: 0.9069 - val_loss: 0.3012 - val_acc: 0.9115\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2948 - acc: 0.9160 - val_loss: 0.2726 - val_acc: 0.9202\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2719 - acc: 0.9224 - val_loss: 0.2553 - val_acc: 0.9246\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2536 - acc: 0.9272 - val_loss: 0.2418 - val_acc: 0.9294\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2379 - acc: 0.9313 - val_loss: 0.2284 - val_acc: 0.9330\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2241 - acc: 0.9358 - val_loss: 0.2198 - val_acc: 0.9339\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2123 - acc: 0.9392 - val_loss: 0.2081 - val_acc: 0.9383\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2009 - acc: 0.9424 - val_loss: 0.1984 - val_acc: 0.9401\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1917 - acc: 0.9446 - val_loss: 0.1891 - val_acc: 0.9455\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1825 - acc: 0.9477 - val_loss: 0.1837 - val_acc: 0.9443\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1743 - acc: 0.9501 - val_loss: 0.1774 - val_acc: 0.9468\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1670 - acc: 0.9519 - val_loss: 0.1687 - val_acc: 0.9507\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1601 - acc: 0.9539 - val_loss: 0.1634 - val_acc: 0.9520\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1533 - acc: 0.9555 - val_loss: 0.1577 - val_acc: 0.9526\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1473 - acc: 0.9572 - val_loss: 0.1544 - val_acc: 0.9533\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1420 - acc: 0.9590 - val_loss: 0.1496 - val_acc: 0.9555\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1367 - acc: 0.9604 - val_loss: 0.1463 - val_acc: 0.9566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160394716d8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16039471b70>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160394660f0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160394b6668>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160394b67b8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160394be1d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.96      0.96      1032\n",
      "           3       0.93      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.95      0.93      0.94       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.95      0.96      0.95      1028\n",
      "           8       0.97      0.92      0.94       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 962    0    1    1    0    4    7    3    1    1]\n",
      " [   0 1117    2    2    1    1    4    3    5    0]\n",
      " [   5    3  990   10    3    2    2    8    7    2]\n",
      " [   0    0    6  974    0   10    0   11    5    4]\n",
      " [   1    0    3    0  940    0   12    4    2   20]\n",
      " [   8    1    0   21    6  833   10    0    7    6]\n",
      " [   8    3    3    1    7   10  921    3    2    0]\n",
      " [   1    5   13    4    3    2    0  985    1   14]\n",
      " [   5    2    4   20    7   12   11   10  897    6]\n",
      " [   8    7    1   11   20    4    1    9    1  947]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 1.5289 - acc: 0.5759 - val_loss: 0.6550 - val_acc: 0.8283\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.5122 - acc: 0.8607 - val_loss: 0.4033 - val_acc: 0.8840\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3780 - acc: 0.8920 - val_loss: 0.3363 - val_acc: 0.9012\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3261 - acc: 0.9061 - val_loss: 0.2993 - val_acc: 0.9122\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2936 - acc: 0.9143 - val_loss: 0.2745 - val_acc: 0.9198\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2699 - acc: 0.9214 - val_loss: 0.2563 - val_acc: 0.9260\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2503 - acc: 0.9279 - val_loss: 0.2406 - val_acc: 0.9308\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2340 - acc: 0.9320 - val_loss: 0.2241 - val_acc: 0.9352\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2197 - acc: 0.9366 - val_loss: 0.2144 - val_acc: 0.9386\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2072 - acc: 0.9407 - val_loss: 0.2057 - val_acc: 0.9404\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1965 - acc: 0.9439 - val_loss: 0.1936 - val_acc: 0.9438\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1870 - acc: 0.9473 - val_loss: 0.1878 - val_acc: 0.9452\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1784 - acc: 0.9493 - val_loss: 0.1775 - val_acc: 0.9479\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1703 - acc: 0.9514 - val_loss: 0.1733 - val_acc: 0.9500\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1632 - acc: 0.9526 - val_loss: 0.1649 - val_acc: 0.9513\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1567 - acc: 0.9550 - val_loss: 0.1602 - val_acc: 0.9522\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1505 - acc: 0.9571 - val_loss: 0.1566 - val_acc: 0.9531\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1451 - acc: 0.9580 - val_loss: 0.1529 - val_acc: 0.9543\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1400 - acc: 0.9595 - val_loss: 0.1482 - val_acc: 0.9564\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1351 - acc: 0.9613 - val_loss: 0.1423 - val_acc: 0.9579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160397d2d68>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160397de2b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160397de828>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603a8241d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603a824320>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1603a80cba8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.96      0.95      0.95      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 967    0    1    0    0    2    7    1    2    0]\n",
      " [   0 1118    3    2    0    1    4    2    5    0]\n",
      " [   7    1  992    3    4    1    4   10    9    1]\n",
      " [   1    2   10  958    0   12    0    9   12    6]\n",
      " [   1    2    6    0  936    0   10    2    6   19]\n",
      " [   8    1    0   12    3  839    9    1   12    7]\n",
      " [   7    3    0    0    8   10  924    0    6    0]\n",
      " [   2    9   17    4    1    1    0  976    3   15]\n",
      " [   3    2    3   12    4    8    9    7  924    2]\n",
      " [   7    6    1   10   20    3    1    9    7  945]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.4810 - acc: 0.6019 - val_loss: 0.6388 - val_acc: 0.8310\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.4969 - acc: 0.8624 - val_loss: 0.3940 - val_acc: 0.8882\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3727 - acc: 0.8935 - val_loss: 0.3296 - val_acc: 0.9058\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3224 - acc: 0.9079 - val_loss: 0.2915 - val_acc: 0.9163\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2895 - acc: 0.9168 - val_loss: 0.2653 - val_acc: 0.9249\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2657 - acc: 0.9244 - val_loss: 0.2463 - val_acc: 0.9303\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2459 - acc: 0.9292 - val_loss: 0.2335 - val_acc: 0.9312\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2296 - acc: 0.9340 - val_loss: 0.2203 - val_acc: 0.9362\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2156 - acc: 0.9367 - val_loss: 0.2081 - val_acc: 0.9393\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2032 - acc: 0.9410 - val_loss: 0.1980 - val_acc: 0.9419\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1923 - acc: 0.9444 - val_loss: 0.1861 - val_acc: 0.9460\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1826 - acc: 0.9474 - val_loss: 0.1783 - val_acc: 0.9468\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1741 - acc: 0.9497 - val_loss: 0.1769 - val_acc: 0.9474\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1660 - acc: 0.9520 - val_loss: 0.1697 - val_acc: 0.9502\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1586 - acc: 0.9536 - val_loss: 0.1591 - val_acc: 0.9547\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1520 - acc: 0.9561 - val_loss: 0.1544 - val_acc: 0.9551\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1459 - acc: 0.9576 - val_loss: 0.1504 - val_acc: 0.9545\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1402 - acc: 0.9591 - val_loss: 0.1452 - val_acc: 0.9568\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1351 - acc: 0.9606 - val_loss: 0.1414 - val_acc: 0.9583\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1303 - acc: 0.9618 - val_loss: 0.1376 - val_acc: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603ab5e9e8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603ab5ee80>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1603ab4a400>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603abd9e10>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603abe2390>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1603abc9908>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.97      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    3    0    4    5    1    2    1]\n",
      " [   0 1119    2    1    0    1    5    2    5    0]\n",
      " [   7    1  988   10    4    2    6    5    6    3]\n",
      " [   0    0    3  974    0   13    0    8    9    3]\n",
      " [   1    1    7    0  937    0   10    2    2   22]\n",
      " [   7    1    0   19    1  837   10    0   12    5]\n",
      " [   7    3    2    0    9    9  925    0    3    0]\n",
      " [   0    8   14    4    3    2    0  973    1   23]\n",
      " [   4    2    3   15    5    4    8    4  924    5]\n",
      " [   4    6    1   12   18    4    1    7    4  952]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 1.4469 - acc: 0.6013 - val_loss: 0.6378 - val_acc: 0.8360\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.5027 - acc: 0.8634 - val_loss: 0.3918 - val_acc: 0.8876\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3745 - acc: 0.8933 - val_loss: 0.3366 - val_acc: 0.9017\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3245 - acc: 0.9056 - val_loss: 0.2928 - val_acc: 0.9147\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2925 - acc: 0.9151 - val_loss: 0.2687 - val_acc: 0.9217\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2684 - acc: 0.9222 - val_loss: 0.2526 - val_acc: 0.9250\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2493 - acc: 0.9287 - val_loss: 0.2334 - val_acc: 0.9322\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2331 - acc: 0.9330 - val_loss: 0.2203 - val_acc: 0.9348\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2195 - acc: 0.9373 - val_loss: 0.2091 - val_acc: 0.9375\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2067 - acc: 0.9414 - val_loss: 0.2013 - val_acc: 0.9408\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1959 - acc: 0.9440 - val_loss: 0.1872 - val_acc: 0.9434\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1863 - acc: 0.9466 - val_loss: 0.1811 - val_acc: 0.9464\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1775 - acc: 0.9487 - val_loss: 0.1795 - val_acc: 0.9452\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1695 - acc: 0.9512 - val_loss: 0.1688 - val_acc: 0.9483\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1618 - acc: 0.9539 - val_loss: 0.1603 - val_acc: 0.9520\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1556 - acc: 0.9556 - val_loss: 0.1576 - val_acc: 0.9529\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1493 - acc: 0.9573 - val_loss: 0.1497 - val_acc: 0.9556\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1438 - acc: 0.9591 - val_loss: 0.1452 - val_acc: 0.9576\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1386 - acc: 0.9602 - val_loss: 0.1440 - val_acc: 0.9560\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1339 - acc: 0.9612 - val_loss: 0.1371 - val_acc: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604132e588>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604132ea20>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1604132eda0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160413b29b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160413b2b00>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160413a23c8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.97      0.96      1032\n",
      "           3       0.96      0.95      0.96      1010\n",
      "           4       0.96      0.95      0.95       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.96      0.95      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    1    2    0    4    6    1    1    0]\n",
      " [   0 1117    3    2    0    1    4    2    6    0]\n",
      " [   8    1  996    7    4    0    5    6    4    1]\n",
      " [   1    1   14  963    0   10    0   10    8    3]\n",
      " [   1    0    4    0  934    1   11    1    3   27]\n",
      " [   8    3    1    5    3  846   10    1    9    6]\n",
      " [   6    3    0    0    7    7  932    0    3    0]\n",
      " [   1    8   20    1    2    1    0  970    2   23]\n",
      " [   4    1    5   10    6    8   10    3  924    3]\n",
      " [   5    7    2    8   19    5    2    6    6  949]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 1.4079 - acc: 0.6197 - val_loss: 0.5925 - val_acc: 0.8540\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.4725 - acc: 0.8738 - val_loss: 0.3776 - val_acc: 0.8961\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.3648 - acc: 0.8963 - val_loss: 0.3244 - val_acc: 0.9097\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3225 - acc: 0.9077 - val_loss: 0.2989 - val_acc: 0.9146\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2949 - acc: 0.9143 - val_loss: 0.2730 - val_acc: 0.9222\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2728 - acc: 0.9204 - val_loss: 0.2563 - val_acc: 0.9263\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2545 - acc: 0.9259 - val_loss: 0.2411 - val_acc: 0.9306\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2384 - acc: 0.9300 - val_loss: 0.2283 - val_acc: 0.9343\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2248 - acc: 0.9350 - val_loss: 0.2149 - val_acc: 0.9391\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2118 - acc: 0.9382 - val_loss: 0.2043 - val_acc: 0.9409\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2009 - acc: 0.9420 - val_loss: 0.1944 - val_acc: 0.9443\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1904 - acc: 0.9451 - val_loss: 0.1931 - val_acc: 0.9415\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1811 - acc: 0.9476 - val_loss: 0.1787 - val_acc: 0.9496\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1726 - acc: 0.9506 - val_loss: 0.1731 - val_acc: 0.9508\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1647 - acc: 0.9525 - val_loss: 0.1661 - val_acc: 0.9527\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1578 - acc: 0.9544 - val_loss: 0.1592 - val_acc: 0.9539\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1513 - acc: 0.9561 - val_loss: 0.1534 - val_acc: 0.9550\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1455 - acc: 0.9580 - val_loss: 0.1479 - val_acc: 0.9569\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1399 - acc: 0.9602 - val_loss: 0.1440 - val_acc: 0.9565\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1345 - acc: 0.9617 - val_loss: 0.1420 - val_acc: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160430cd128>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160430cd5c0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160430cdb70>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604314e0b8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604314e208>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16043135b70>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.97      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.95      0.97      0.96       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.97      0.92      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 967    0    1    2    0    2    5    2    1    0]\n",
      " [   0 1111    3    2    0    2    3    2   12    0]\n",
      " [   4    0  999    6    4    1    4    7    6    1]\n",
      " [   1    0    9  966    0   11    0    9   12    2]\n",
      " [   1    0    8    0  950    0    7    2    3   11]\n",
      " [   7    1    0   12    2  845   11    1   10    3]\n",
      " [   8    3    5    0   10   11  918    0    3    0]\n",
      " [   2    7   19    2    1    0    0  984    3   10]\n",
      " [   5    1    3   14    7    6    9    4  925    0]\n",
      " [   9    5    3   10   27    5    1   12    9  928]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 1.4774 - acc: 0.6068 - val_loss: 0.6376 - val_acc: 0.8409\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.4957 - acc: 0.8668 - val_loss: 0.3962 - val_acc: 0.8900\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3721 - acc: 0.8932 - val_loss: 0.3357 - val_acc: 0.9043\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.3236 - acc: 0.9074 - val_loss: 0.2987 - val_acc: 0.9121\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2932 - acc: 0.9154 - val_loss: 0.2764 - val_acc: 0.9213\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2697 - acc: 0.9217 - val_loss: 0.2550 - val_acc: 0.9269\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2501 - acc: 0.9274 - val_loss: 0.2370 - val_acc: 0.9318\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2334 - acc: 0.9321 - val_loss: 0.2230 - val_acc: 0.9350\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2190 - acc: 0.9365 - val_loss: 0.2127 - val_acc: 0.9371\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2058 - acc: 0.9407 - val_loss: 0.2023 - val_acc: 0.9385\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1950 - acc: 0.9441 - val_loss: 0.1923 - val_acc: 0.9409\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1850 - acc: 0.9469 - val_loss: 0.1830 - val_acc: 0.9435\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1760 - acc: 0.9487 - val_loss: 0.1776 - val_acc: 0.9452\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1677 - acc: 0.9520 - val_loss: 0.1698 - val_acc: 0.9480\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1604 - acc: 0.9536 - val_loss: 0.1630 - val_acc: 0.9480\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1536 - acc: 0.9556 - val_loss: 0.1580 - val_acc: 0.9491\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1476 - acc: 0.9577 - val_loss: 0.1554 - val_acc: 0.9511\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1419 - acc: 0.9594 - val_loss: 0.1470 - val_acc: 0.9541\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1366 - acc: 0.9614 - val_loss: 0.1477 - val_acc: 0.9533\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1317 - acc: 0.9626 - val_loss: 0.1400 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160434817b8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16043481c50>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1604347a1d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16043501be0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16043509160>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160434f26d8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.93      0.96      0.95      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.96      0.93      0.94       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    0    1    0    5    3    4    1    1]\n",
      " [   0 1117    3    2    0    1    3    3    6    0]\n",
      " [   6    1  992    8    4    1    4    9    6    1]\n",
      " [   0    0    8  973    0    7    0   10   10    2]\n",
      " [   1    0    5    1  935    0    8    4    2   26]\n",
      " [   5    1    1   23    3  839    9    1    5    5]\n",
      " [  12    3    5    0    6    8  919    0    5    0]\n",
      " [   0    8   17    3    4    0    0  976    1   19]\n",
      " [   6    2    7   21    4    7    9    9  902    7]\n",
      " [   3    6    1   13   19    3    1   11    5  947]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 1.4330 - acc: 0.6264 - val_loss: 0.6048 - val_acc: 0.8482\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.4795 - acc: 0.8706 - val_loss: 0.3798 - val_acc: 0.8936\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3625 - acc: 0.8987 - val_loss: 0.3214 - val_acc: 0.9099\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3179 - acc: 0.9093 - val_loss: 0.2900 - val_acc: 0.9188\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2888 - acc: 0.9173 - val_loss: 0.2667 - val_acc: 0.9246\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2668 - acc: 0.9234 - val_loss: 0.2500 - val_acc: 0.9295\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2491 - acc: 0.9279 - val_loss: 0.2396 - val_acc: 0.9321\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2339 - acc: 0.9322 - val_loss: 0.2232 - val_acc: 0.9356\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2206 - acc: 0.9363 - val_loss: 0.2112 - val_acc: 0.9410\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2091 - acc: 0.9395 - val_loss: 0.2047 - val_acc: 0.9428\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1983 - acc: 0.9428 - val_loss: 0.1950 - val_acc: 0.9448\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.1885 - acc: 0.9461 - val_loss: 0.1859 - val_acc: 0.9455\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1796 - acc: 0.9479 - val_loss: 0.1770 - val_acc: 0.9496\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1717 - acc: 0.9501 - val_loss: 0.1737 - val_acc: 0.9498\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1642 - acc: 0.9530 - val_loss: 0.1660 - val_acc: 0.9512\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1572 - acc: 0.9544 - val_loss: 0.1614 - val_acc: 0.9530\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1509 - acc: 0.9562 - val_loss: 0.1546 - val_acc: 0.9541\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1445 - acc: 0.9587 - val_loss: 0.1511 - val_acc: 0.9551\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1396 - acc: 0.9594 - val_loss: 0.1475 - val_acc: 0.9561\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1338 - acc: 0.9614 - val_loss: 0.1415 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16043840518>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160438409b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1604382dfd0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160438c34a8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160438c35f8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160438ace80>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.95      0.95      1032\n",
      "           3       0.96      0.95      0.95      1010\n",
      "           4       0.94      0.97      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.95      0.96      0.95      1028\n",
      "           8       0.95      0.93      0.94       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    1    2    0    4    6    1    1    1]\n",
      " [   0 1121    2    2    0    0    3    1    6    0]\n",
      " [   8    3  982    6    6    0    6   10   11    0]\n",
      " [   1    1   11  960    0    8    1   13   11    4]\n",
      " [   2    0    4    0  950    0    8    2    2   14]\n",
      " [   8    1    0   14    2  841   10    1   10    5]\n",
      " [   9    3    4    1   10    9  919    0    3    0]\n",
      " [   1    8   21    1    2    0    0  983    1   11]\n",
      " [   4    1    2   13    9   11   10   10  910    4]\n",
      " [   9    6    1    6   27    2    1   16    6  935]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 1.3482 - acc: 0.6489 - val_loss: 0.5537 - val_acc: 0.8616\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.4541 - acc: 0.8771 - val_loss: 0.3641 - val_acc: 0.8983\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3501 - acc: 0.9019 - val_loss: 0.3145 - val_acc: 0.9101\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3066 - acc: 0.9127 - val_loss: 0.2825 - val_acc: 0.9189\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2797 - acc: 0.9202 - val_loss: 0.2644 - val_acc: 0.9259\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2586 - acc: 0.9262 - val_loss: 0.2413 - val_acc: 0.9336\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2418 - acc: 0.9308 - val_loss: 0.2314 - val_acc: 0.9351\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2272 - acc: 0.9349 - val_loss: 0.2202 - val_acc: 0.9379\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2148 - acc: 0.9382 - val_loss: 0.2094 - val_acc: 0.9421\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2034 - acc: 0.9420 - val_loss: 0.1978 - val_acc: 0.9438\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1940 - acc: 0.9448 - val_loss: 0.1890 - val_acc: 0.9460\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1847 - acc: 0.9467 - val_loss: 0.1833 - val_acc: 0.9463\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1763 - acc: 0.9496 - val_loss: 0.1748 - val_acc: 0.9486\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1690 - acc: 0.9516 - val_loss: 0.1724 - val_acc: 0.9491\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1621 - acc: 0.9533 - val_loss: 0.1639 - val_acc: 0.9521\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1560 - acc: 0.9553 - val_loss: 0.1602 - val_acc: 0.9533\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1494 - acc: 0.9569 - val_loss: 0.1587 - val_acc: 0.9536\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1437 - acc: 0.9588 - val_loss: 0.1501 - val_acc: 0.9545\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1386 - acc: 0.9606 - val_loss: 0.1456 - val_acc: 0.9564\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1337 - acc: 0.9615 - val_loss: 0.1475 - val_acc: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049b34d68>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049b172b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16043bf2780>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049b89cf8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049b91278>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16049b79710>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.91      0.97      0.94      1010\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.97      0.93      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.97      0.92      0.95       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    1    3    0    4    4    1    1    0]\n",
      " [   0 1120    4    2    1    0    4    1    3    0]\n",
      " [   6    1  991    9    7    1    5    8    3    1]\n",
      " [   1    0    5  982    0    3    0    8    6    5]\n",
      " [   2    1    4    0  936    0   10    2    2   25]\n",
      " [   8    2    2   27    3  831    9    2    5    3]\n",
      " [   9    3    6    2    7    8  921    0    2    0]\n",
      " [   1   10   21    5    3    2    0  974    0   12]\n",
      " [   4    1    7   30    6    6    8    8  900    4]\n",
      " [   8    9    1   16   21    4    1    8    2  939]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 1.4415 - acc: 0.5849 - val_loss: 0.6565 - val_acc: 0.8320\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.5160 - acc: 0.8579 - val_loss: 0.4054 - val_acc: 0.8866\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.3766 - acc: 0.8931 - val_loss: 0.3301 - val_acc: 0.9059\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3207 - acc: 0.9076 - val_loss: 0.2947 - val_acc: 0.9171\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2885 - acc: 0.9169 - val_loss: 0.2698 - val_acc: 0.9242\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2650 - acc: 0.9239 - val_loss: 0.2558 - val_acc: 0.9287\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2469 - acc: 0.9290 - val_loss: 0.2325 - val_acc: 0.9354\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2320 - acc: 0.9333 - val_loss: 0.2220 - val_acc: 0.9365\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2185 - acc: 0.9371 - val_loss: 0.2115 - val_acc: 0.9394\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2071 - acc: 0.9408 - val_loss: 0.2002 - val_acc: 0.9428\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1965 - acc: 0.9437 - val_loss: 0.1910 - val_acc: 0.9457\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1867 - acc: 0.9465 - val_loss: 0.1845 - val_acc: 0.9472\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1784 - acc: 0.9485 - val_loss: 0.1757 - val_acc: 0.9494\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1707 - acc: 0.9506 - val_loss: 0.1722 - val_acc: 0.9507\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1632 - acc: 0.9530 - val_loss: 0.1648 - val_acc: 0.9519\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1564 - acc: 0.9546 - val_loss: 0.1606 - val_acc: 0.9531\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1502 - acc: 0.9564 - val_loss: 0.1571 - val_acc: 0.9551\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1445 - acc: 0.9587 - val_loss: 0.1489 - val_acc: 0.9565\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1390 - acc: 0.9599 - val_loss: 0.1435 - val_acc: 0.9581\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1337 - acc: 0.9618 - val_loss: 0.1420 - val_acc: 0.9567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049eb3f98>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049ec4470>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16049ea4a90>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049f49898>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16049f499e8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16049f3a2b0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.96      0.94      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.93      0.94       892\n",
      "           6       0.95      0.96      0.95       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.94      0.95      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 968    0    0    1    0    3    6    1    1    0]\n",
      " [   0 1118    3    2    0    1    4    1    6    0]\n",
      " [  10    3  988    3    5    1    9    4    8    1]\n",
      " [   2    1   12  954    0   12    0    8   14    7]\n",
      " [   1    1    6    0  939    1   10    1    2   21]\n",
      " [   9    2    0   16    2  829   13    0   14    7]\n",
      " [   8    3    5    0    9    8  921    1    3    0]\n",
      " [   1   12   16    3    4    1    0  971    0   20]\n",
      " [   6    2    3    9    5    5    9    4  924    7]\n",
      " [   6    7    2    8   17    3    1    5    5  955]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 1.4010 - acc: 0.6517 - val_loss: 0.6267 - val_acc: 0.8394\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.4965 - acc: 0.8674 - val_loss: 0.3852 - val_acc: 0.8951\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3693 - acc: 0.8971 - val_loss: 0.3232 - val_acc: 0.9102\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.3218 - acc: 0.9083 - val_loss: 0.2931 - val_acc: 0.9179\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2931 - acc: 0.9164 - val_loss: 0.2697 - val_acc: 0.9227\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2718 - acc: 0.9223 - val_loss: 0.2527 - val_acc: 0.9288\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2548 - acc: 0.9270 - val_loss: 0.2376 - val_acc: 0.9326\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2400 - acc: 0.9316 - val_loss: 0.2260 - val_acc: 0.9351\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2266 - acc: 0.9351 - val_loss: 0.2202 - val_acc: 0.9367\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2147 - acc: 0.9387 - val_loss: 0.2080 - val_acc: 0.9409\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2046 - acc: 0.9412 - val_loss: 0.2012 - val_acc: 0.9422\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1947 - acc: 0.9434 - val_loss: 0.1908 - val_acc: 0.9458\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1855 - acc: 0.9465 - val_loss: 0.1843 - val_acc: 0.9466\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1772 - acc: 0.9490 - val_loss: 0.1744 - val_acc: 0.9495\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1697 - acc: 0.9509 - val_loss: 0.1740 - val_acc: 0.9481\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1625 - acc: 0.9534 - val_loss: 0.1607 - val_acc: 0.9523\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1562 - acc: 0.9546 - val_loss: 0.1574 - val_acc: 0.9532\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1502 - acc: 0.9564 - val_loss: 0.1507 - val_acc: 0.9554\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1444 - acc: 0.9579 - val_loss: 0.1486 - val_acc: 0.9558\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1394 - acc: 0.9598 - val_loss: 0.1449 - val_acc: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604a2b91d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604a2b9668>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1604a27cba8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604a310160>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604a310710>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1604a2f8b38>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.95      0.96      0.96      1010\n",
      "           4       0.94      0.97      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.96      0.92      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 960    0    0    2    0    5    9    2    1    1]\n",
      " [   0 1110    3    2    0    0    4    2   14    0]\n",
      " [   6    2  984    7    6    1    6   10   10    0]\n",
      " [   1    0    6  973    0   10    0    8   10    2]\n",
      " [   1    0    9    0  952    0    3    2    2   13]\n",
      " [   9    1    0   14    3  836   11    3   10    5]\n",
      " [   9    3    1    1    6    9  924    0    5    0]\n",
      " [   2    7   18    5    4    0    0  975    4   13]\n",
      " [   4    1    3   11    5    8    7    5  927    3]\n",
      " [   9    7    1    9   34    3    0    9    8  929]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 1.4594 - acc: 0.6106 - val_loss: 0.6244 - val_acc: 0.8392\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.4837 - acc: 0.8692 - val_loss: 0.3836 - val_acc: 0.8959\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3635 - acc: 0.8957 - val_loss: 0.3255 - val_acc: 0.9077\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3188 - acc: 0.9077 - val_loss: 0.2940 - val_acc: 0.9160\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2910 - acc: 0.9159 - val_loss: 0.2682 - val_acc: 0.9235\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2687 - acc: 0.9215 - val_loss: 0.2495 - val_acc: 0.9297\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2508 - acc: 0.9278 - val_loss: 0.2363 - val_acc: 0.9321\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2354 - acc: 0.9321 - val_loss: 0.2236 - val_acc: 0.9364\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2220 - acc: 0.9357 - val_loss: 0.2138 - val_acc: 0.9387\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2100 - acc: 0.9389 - val_loss: 0.2052 - val_acc: 0.9401\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1996 - acc: 0.9420 - val_loss: 0.1972 - val_acc: 0.9415\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1901 - acc: 0.9446 - val_loss: 0.1865 - val_acc: 0.9449\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1812 - acc: 0.9474 - val_loss: 0.1810 - val_acc: 0.9468\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1735 - acc: 0.9494 - val_loss: 0.1725 - val_acc: 0.9494\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1659 - acc: 0.9520 - val_loss: 0.1662 - val_acc: 0.9509\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1588 - acc: 0.9537 - val_loss: 0.1645 - val_acc: 0.9519\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1528 - acc: 0.9555 - val_loss: 0.1590 - val_acc: 0.9529\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1473 - acc: 0.9571 - val_loss: 0.1516 - val_acc: 0.9551\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1415 - acc: 0.9589 - val_loss: 0.1478 - val_acc: 0.9554\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1367 - acc: 0.9606 - val_loss: 0.1423 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605138ea20>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605138eeb8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160513b9518>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605140ae48>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160514133c8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160513fc860>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.95      0.96      0.95      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.95      0.93      0.94       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    1    0    0    4    5    3    2    1]\n",
      " [   0 1116    3    2    0    1    3    2    8    0]\n",
      " [   7    3  986    9    6    1    4   10    6    0]\n",
      " [   0    2   14  958    0   12    0   11   10    3]\n",
      " [   1    0    4    0  945    0    9    2    2   19]\n",
      " [   8    1    2   13    5  831    8    2   18    4]\n",
      " [   9    3    1    0    8   10  921    0    6    0]\n",
      " [   1   10   20    3    1    1    0  977    3   12]\n",
      " [   3    2    2   11    6    7    9    5  928    1]\n",
      " [   6    8    2   10   25    4    1    6    8  939]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 1.4214 - acc: 0.6273 - val_loss: 0.6044 - val_acc: 0.8445\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.4858 - acc: 0.8664 - val_loss: 0.3889 - val_acc: 0.8894\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.3709 - acc: 0.8937 - val_loss: 0.3254 - val_acc: 0.9049\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.3257 - acc: 0.9059 - val_loss: 0.2920 - val_acc: 0.9150\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2961 - acc: 0.9142 - val_loss: 0.2719 - val_acc: 0.9205\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2733 - acc: 0.9209 - val_loss: 0.2540 - val_acc: 0.9260\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2543 - acc: 0.9257 - val_loss: 0.2390 - val_acc: 0.9302\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2387 - acc: 0.9303 - val_loss: 0.2281 - val_acc: 0.9340\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2245 - acc: 0.9345 - val_loss: 0.2167 - val_acc: 0.9367\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2120 - acc: 0.9389 - val_loss: 0.2028 - val_acc: 0.9405\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2008 - acc: 0.9420 - val_loss: 0.1951 - val_acc: 0.9426\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1905 - acc: 0.9447 - val_loss: 0.1866 - val_acc: 0.9454\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1810 - acc: 0.9482 - val_loss: 0.1781 - val_acc: 0.9472\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1727 - acc: 0.9505 - val_loss: 0.1695 - val_acc: 0.9503\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1652 - acc: 0.9524 - val_loss: 0.1639 - val_acc: 0.9521\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1578 - acc: 0.9542 - val_loss: 0.1585 - val_acc: 0.9527\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1515 - acc: 0.9564 - val_loss: 0.1532 - val_acc: 0.9545\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1453 - acc: 0.9582 - val_loss: 0.1482 - val_acc: 0.9553\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1398 - acc: 0.9599 - val_loss: 0.1446 - val_acc: 0.9571\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1346 - acc: 0.9615 - val_loss: 0.1408 - val_acc: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16052740780>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16052740c18>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16051742278>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16052799710>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16052799860>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16052789128>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.94      0.97      0.96      1032\n",
      "           3       0.94      0.95      0.94      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.95      0.94      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.95      0.92      0.94       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    1    3    0    3    4    2    1    0]\n",
      " [   0 1115    3    2    0    1    3    2    9    0]\n",
      " [   5    1  998    8    5    0    2    7    4    2]\n",
      " [   0    0   15  960    0    9    1   10   13    2]\n",
      " [   1    0    7    0  947    0    7    1    2   17]\n",
      " [   7    2    0   15    4  840   10    2    7    5]\n",
      " [   7    3    3    1    8   10  924    0    2    0]\n",
      " [   0    8   19    2    2    1    0  981    3   12]\n",
      " [   6    1    9   20    5   13   10    6  899    5]\n",
      " [   5    6    2   11   26    5    1   11    2  940]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 1.3859 - acc: 0.6528 - val_loss: 0.5934 - val_acc: 0.8579\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.4774 - acc: 0.8719 - val_loss: 0.3794 - val_acc: 0.8935\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3651 - acc: 0.8963 - val_loss: 0.3194 - val_acc: 0.9096\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3193 - acc: 0.9089 - val_loss: 0.2926 - val_acc: 0.9173\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2903 - acc: 0.9168 - val_loss: 0.2661 - val_acc: 0.9239\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2679 - acc: 0.9237 - val_loss: 0.2486 - val_acc: 0.9293\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2500 - acc: 0.9282 - val_loss: 0.2321 - val_acc: 0.9334\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2345 - acc: 0.9328 - val_loss: 0.2182 - val_acc: 0.9389\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2210 - acc: 0.9370 - val_loss: 0.2081 - val_acc: 0.9406\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2089 - acc: 0.9405 - val_loss: 0.1987 - val_acc: 0.9429\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1981 - acc: 0.9430 - val_loss: 0.1889 - val_acc: 0.9433\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1887 - acc: 0.9460 - val_loss: 0.1827 - val_acc: 0.9465\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1802 - acc: 0.9483 - val_loss: 0.1731 - val_acc: 0.9492\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1719 - acc: 0.9506 - val_loss: 0.1676 - val_acc: 0.9509\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1649 - acc: 0.9524 - val_loss: 0.1608 - val_acc: 0.9530\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1584 - acc: 0.9544 - val_loss: 0.1555 - val_acc: 0.9545\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1523 - acc: 0.9557 - val_loss: 0.1509 - val_acc: 0.9554\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1470 - acc: 0.9578 - val_loss: 0.1486 - val_acc: 0.9566\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1416 - acc: 0.9600 - val_loss: 0.1416 - val_acc: 0.9584\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1367 - acc: 0.9609 - val_loss: 0.1375 - val_acc: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16052ad8fd0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16052aff4a8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16052ac59e8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16052b53f60>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16052b5b0f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16052b42978>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.95      0.96      0.96      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    0    2    0    4    6    3    2    0]\n",
      " [   0 1116    2    2    0    1    4    2    8    0]\n",
      " [   8    3  980    9    4    3    6    9    8    2]\n",
      " [   0    0    7  974    0   10    0   10    9    0]\n",
      " [   1    1    3    0  944    0   10    2    2   19]\n",
      " [   8    2    1    9    1  845   10    2   10    4]\n",
      " [   6    3    3    0    8    8  927    0    3    0]\n",
      " [   0    7   18    4    1    1    0  976    2   19]\n",
      " [   3    1    3   11    4    3   11    5  928    5]\n",
      " [   6    7    1    9   24    4    1    6    7  944]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 1.4667 - acc: 0.6228 - val_loss: 0.6540 - val_acc: 0.8344\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.5076 - acc: 0.8635 - val_loss: 0.3896 - val_acc: 0.8909\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3745 - acc: 0.8950 - val_loss: 0.3278 - val_acc: 0.9062\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3256 - acc: 0.9066 - val_loss: 0.2954 - val_acc: 0.9141\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2951 - acc: 0.9156 - val_loss: 0.2701 - val_acc: 0.9225\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2726 - acc: 0.9208 - val_loss: 0.2534 - val_acc: 0.9284\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2536 - acc: 0.9267 - val_loss: 0.2373 - val_acc: 0.9321\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2372 - acc: 0.9308 - val_loss: 0.2244 - val_acc: 0.9349\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.2231 - acc: 0.9356 - val_loss: 0.2125 - val_acc: 0.9395\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2103 - acc: 0.9398 - val_loss: 0.1995 - val_acc: 0.9423\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1987 - acc: 0.9431 - val_loss: 0.1923 - val_acc: 0.9434\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1889 - acc: 0.9459 - val_loss: 0.1841 - val_acc: 0.9464\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1797 - acc: 0.9487 - val_loss: 0.1766 - val_acc: 0.9478\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1716 - acc: 0.9508 - val_loss: 0.1684 - val_acc: 0.9500\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1646 - acc: 0.9530 - val_loss: 0.1638 - val_acc: 0.9504\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1576 - acc: 0.9547 - val_loss: 0.1585 - val_acc: 0.9518\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1513 - acc: 0.9566 - val_loss: 0.1546 - val_acc: 0.9534\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1461 - acc: 0.9578 - val_loss: 0.1488 - val_acc: 0.9543\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1408 - acc: 0.9595 - val_loss: 0.1448 - val_acc: 0.9562\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1359 - acc: 0.9611 - val_loss: 0.1411 - val_acc: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16053e87860>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16053e87cf8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16053e72358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16053ee77f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16053ee7940>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16053ed72e8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.97      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.95      0.94      0.94       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    0    2    0    4    5    1    2    0]\n",
      " [   0 1119    3    2    0    1    4    2    4    0]\n",
      " [   7    2  993    8    4    1    2    8    6    1]\n",
      " [   0    0   11  965    0   10    0   10   12    2]\n",
      " [   1    0    8    0  939    1    7    3    3   20]\n",
      " [   9    1    0   16    2  841    9    1    7    6]\n",
      " [  10    4    1    1    5    8  925    1    3    0]\n",
      " [   1   11   15    2    4    0    0  981    2   12]\n",
      " [   5    2    5   15    6    7   11    7  912    4]\n",
      " [   8    6    2   12   26    4    1    8    6  936]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.4328 - acc: 0.6301 - val_loss: 0.6080 - val_acc: 0.8465\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4856 - acc: 0.8684 - val_loss: 0.3835 - val_acc: 0.8939\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3681 - acc: 0.8955 - val_loss: 0.3257 - val_acc: 0.9086\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3216 - acc: 0.9073 - val_loss: 0.2952 - val_acc: 0.9129\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2927 - acc: 0.9154 - val_loss: 0.2679 - val_acc: 0.9234\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2707 - acc: 0.9221 - val_loss: 0.2505 - val_acc: 0.9296\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2533 - acc: 0.9265 - val_loss: 0.2384 - val_acc: 0.9322\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2384 - acc: 0.9313 - val_loss: 0.2212 - val_acc: 0.9361\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2251 - acc: 0.9351 - val_loss: 0.2122 - val_acc: 0.9383\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2133 - acc: 0.9383 - val_loss: 0.2024 - val_acc: 0.9418\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2028 - acc: 0.9412 - val_loss: 0.1931 - val_acc: 0.9443\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1932 - acc: 0.9445 - val_loss: 0.1847 - val_acc: 0.9467\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1842 - acc: 0.9466 - val_loss: 0.1757 - val_acc: 0.9489\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1765 - acc: 0.9491 - val_loss: 0.1722 - val_acc: 0.9492\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1688 - acc: 0.9513 - val_loss: 0.1653 - val_acc: 0.9507\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1623 - acc: 0.9534 - val_loss: 0.1599 - val_acc: 0.9531\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1561 - acc: 0.9554 - val_loss: 0.1542 - val_acc: 0.9544\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1498 - acc: 0.9572 - val_loss: 0.1526 - val_acc: 0.9548\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1445 - acc: 0.9579 - val_loss: 0.1458 - val_acc: 0.9561\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1392 - acc: 0.9599 - val_loss: 0.1462 - val_acc: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605446f0f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605446f588>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605443cac8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160544cc080>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160544cc1d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160544ccac8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.93      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.94      0.94      0.94       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.95      0.94      0.95       974\n",
      "           9       0.97      0.92      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    1    2    0    3    6    1    1    0]\n",
      " [   0 1113    3    1    0    1    5    2   10    0]\n",
      " [   6    1  985   13    4    3    3    8    9    0]\n",
      " [   0    0    8  970    0   16    0    8    7    1]\n",
      " [   1    0    4    0  946    1    9    3    3   15]\n",
      " [   8    1    1   16    3  842   10    0    7    4]\n",
      " [   9    3    3    1    7    8  924    0    3    0]\n",
      " [   4    6   12    6    2    1    0  987    1    9]\n",
      " [   4    1    2   20    5   13    8    5  914    2]\n",
      " [  11    7    1   13   25    8    1    9    5  929]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.4796 - acc: 0.6125 - val_loss: 0.6325 - val_acc: 0.8491\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4901 - acc: 0.8690 - val_loss: 0.3888 - val_acc: 0.8927\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3675 - acc: 0.8947 - val_loss: 0.3204 - val_acc: 0.9078\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3219 - acc: 0.9071 - val_loss: 0.2975 - val_acc: 0.9170\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2934 - acc: 0.9147 - val_loss: 0.2712 - val_acc: 0.9242\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2722 - acc: 0.9213 - val_loss: 0.2517 - val_acc: 0.9270\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2549 - acc: 0.9263 - val_loss: 0.2385 - val_acc: 0.9312\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2398 - acc: 0.9308 - val_loss: 0.2290 - val_acc: 0.9331\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2263 - acc: 0.9343 - val_loss: 0.2155 - val_acc: 0.9369\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2141 - acc: 0.9379 - val_loss: 0.2057 - val_acc: 0.9407\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2037 - acc: 0.9416 - val_loss: 0.1948 - val_acc: 0.9406\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1935 - acc: 0.9442 - val_loss: 0.1850 - val_acc: 0.9447\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1845 - acc: 0.9467 - val_loss: 0.1769 - val_acc: 0.9469\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1760 - acc: 0.9491 - val_loss: 0.1711 - val_acc: 0.9480\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1683 - acc: 0.9516 - val_loss: 0.1705 - val_acc: 0.9484\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1614 - acc: 0.9531 - val_loss: 0.1608 - val_acc: 0.9505\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1548 - acc: 0.9551 - val_loss: 0.1550 - val_acc: 0.9526\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1487 - acc: 0.9565 - val_loss: 0.1503 - val_acc: 0.9539\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1432 - acc: 0.9581 - val_loss: 0.1456 - val_acc: 0.9542\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1378 - acc: 0.9602 - val_loss: 0.1388 - val_acc: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16055909940>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16055909dd8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160558f3358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16055983d68>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605598d2e8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16055974780>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 962    0    1    2    0    4    7    1    3    0]\n",
      " [   0 1118    3    2    0    1    4    2    5    0]\n",
      " [   6    2  984   12    7    0    5   10    6    0]\n",
      " [   1    2    7  965    0   11    0   11   10    3]\n",
      " [   1    1    3    1  940    0    8    4    4   20]\n",
      " [   6    2    1   12    2  844   10    1    9    5]\n",
      " [   7    3    1    0    7   11  924    0    5    0]\n",
      " [   1   13   13    8    5    1    0  971    1   15]\n",
      " [   4    1    4   13    5    9    9    4  921    4]\n",
      " [   5   10    2    6   24    4    1    8    7  942]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 1.4341 - acc: 0.6264 - val_loss: 0.6164 - val_acc: 0.8462\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.4861 - acc: 0.8685 - val_loss: 0.3943 - val_acc: 0.8890\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.3705 - acc: 0.8941 - val_loss: 0.3323 - val_acc: 0.9018\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3242 - acc: 0.9074 - val_loss: 0.3050 - val_acc: 0.9106\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2946 - acc: 0.9149 - val_loss: 0.2755 - val_acc: 0.9171\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2724 - acc: 0.9210 - val_loss: 0.2583 - val_acc: 0.9250\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2549 - acc: 0.9264 - val_loss: 0.2436 - val_acc: 0.9295\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2394 - acc: 0.9306 - val_loss: 0.2300 - val_acc: 0.9332\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2263 - acc: 0.9355 - val_loss: 0.2165 - val_acc: 0.9369\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2144 - acc: 0.9381 - val_loss: 0.2095 - val_acc: 0.9380\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2033 - acc: 0.9411 - val_loss: 0.2047 - val_acc: 0.9418\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1940 - acc: 0.9445 - val_loss: 0.1880 - val_acc: 0.9448\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1848 - acc: 0.9470 - val_loss: 0.1845 - val_acc: 0.9461\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1761 - acc: 0.9490 - val_loss: 0.1774 - val_acc: 0.9458\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1688 - acc: 0.9516 - val_loss: 0.1682 - val_acc: 0.9509\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1616 - acc: 0.9535 - val_loss: 0.1608 - val_acc: 0.9530\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1545 - acc: 0.9561 - val_loss: 0.1561 - val_acc: 0.9547\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1489 - acc: 0.9573 - val_loss: 0.1525 - val_acc: 0.9552\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1427 - acc: 0.9592 - val_loss: 0.1449 - val_acc: 0.9569\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1377 - acc: 0.9606 - val_loss: 0.1436 - val_acc: 0.9574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16055cdc6a0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16055cdcb38>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16055cc90b8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16056d25630>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16056d25780>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16056d25e80>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.96      0.95      0.95      1010\n",
      "           4       0.94      0.97      0.95       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.94      0.95      0.95       974\n",
      "           9       0.97      0.91      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    1    1    0    2    5    3    2    0]\n",
      " [   0 1116    3    2    0    1    4    2    7    0]\n",
      " [   6    2  991    6    3    2    6    9    6    1]\n",
      " [   0    1    9  957    0   16    1   11   12    3]\n",
      " [   1    0    6    0  949    0   12    1    2   11]\n",
      " [   9    1    1    6    2  848   10    0   10    5]\n",
      " [   6    3    1    0    9   10  927    0    2    0]\n",
      " [   1   11   18    3    2    1    0  978    3   11]\n",
      " [   6    1    3   12    5    9    9    6  923    0]\n",
      " [   9    7    2    8   37    6    1   10   10  919]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 1.4505 - acc: 0.6195 - val_loss: 0.6279 - val_acc: 0.8457\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.4917 - acc: 0.8687 - val_loss: 0.3844 - val_acc: 0.8966\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.3673 - acc: 0.8967 - val_loss: 0.3240 - val_acc: 0.9096\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.3209 - acc: 0.9070 - val_loss: 0.2922 - val_acc: 0.9178\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2919 - acc: 0.9167 - val_loss: 0.2675 - val_acc: 0.9246\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2705 - acc: 0.9222 - val_loss: 0.2505 - val_acc: 0.9288\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2531 - acc: 0.9276 - val_loss: 0.2375 - val_acc: 0.9314\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2378 - acc: 0.9311 - val_loss: 0.2228 - val_acc: 0.9368\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2244 - acc: 0.9351 - val_loss: 0.2128 - val_acc: 0.9379\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2127 - acc: 0.9379 - val_loss: 0.2023 - val_acc: 0.9415\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2019 - acc: 0.9414 - val_loss: 0.1924 - val_acc: 0.9445\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1926 - acc: 0.9442 - val_loss: 0.1878 - val_acc: 0.9448\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1834 - acc: 0.9470 - val_loss: 0.1792 - val_acc: 0.9467\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1754 - acc: 0.9493 - val_loss: 0.1717 - val_acc: 0.9493\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1679 - acc: 0.9517 - val_loss: 0.1647 - val_acc: 0.9509\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1613 - acc: 0.9536 - val_loss: 0.1605 - val_acc: 0.9528\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1551 - acc: 0.9553 - val_loss: 0.1541 - val_acc: 0.9548\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1493 - acc: 0.9572 - val_loss: 0.1525 - val_acc: 0.9557\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1437 - acc: 0.9582 - val_loss: 0.1478 - val_acc: 0.9567\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1388 - acc: 0.9604 - val_loss: 0.1438 - val_acc: 0.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16057076ef0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160570893c8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16057063908>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160570efe80>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160570f9400>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160570e0978>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.94      0.96      0.95      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.96      0.92      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 967    0    1    2    0    3    4    2    1    0]\n",
      " [   0 1116    3    2    0    1    4    2    7    0]\n",
      " [   6    1  987    7    5    2    8    9    7    0]\n",
      " [   1    0   14  963    0   12    0   11    7    2]\n",
      " [   1    0    6    0  941    0    9    3    2   20]\n",
      " [   9    2    2   12    3  841   11    1    5    6]\n",
      " [  10    3    2    1    9    9  922    0    2    0]\n",
      " [   0   10   13    3    1    2    0  991    0    8]\n",
      " [   6    3    1   14    7    6   11   13  911    2]\n",
      " [   9    7    1    9   26    3    1   17    6  930]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 1.4174 - acc: 0.6188 - val_loss: 0.6197 - val_acc: 0.8450\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.4899 - acc: 0.8679 - val_loss: 0.3912 - val_acc: 0.8932\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3683 - acc: 0.8952 - val_loss: 0.3231 - val_acc: 0.9064\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.3225 - acc: 0.9073 - val_loss: 0.2921 - val_acc: 0.9149\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2937 - acc: 0.9152 - val_loss: 0.2694 - val_acc: 0.9233\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2716 - acc: 0.9215 - val_loss: 0.2523 - val_acc: 0.9285\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2537 - acc: 0.9266 - val_loss: 0.2388 - val_acc: 0.9322\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2384 - acc: 0.9320 - val_loss: 0.2238 - val_acc: 0.9362\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.2249 - acc: 0.9357 - val_loss: 0.2140 - val_acc: 0.9385\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2132 - acc: 0.9387 - val_loss: 0.2010 - val_acc: 0.9417\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2020 - acc: 0.9418 - val_loss: 0.1943 - val_acc: 0.9430\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1919 - acc: 0.9445 - val_loss: 0.1852 - val_acc: 0.9440\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1829 - acc: 0.9470 - val_loss: 0.1756 - val_acc: 0.9464\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1747 - acc: 0.9501 - val_loss: 0.1691 - val_acc: 0.9492\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1666 - acc: 0.9522 - val_loss: 0.1649 - val_acc: 0.9505\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1599 - acc: 0.9538 - val_loss: 0.1615 - val_acc: 0.9529\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1533 - acc: 0.9554 - val_loss: 0.1522 - val_acc: 0.9536\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1470 - acc: 0.9579 - val_loss: 0.1463 - val_acc: 0.9555\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1417 - acc: 0.9586 - val_loss: 0.1427 - val_acc: 0.9575\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1362 - acc: 0.9606 - val_loss: 0.1365 - val_acc: 0.9594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16057446780>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16057446c18>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16057434198>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160574c3710>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160574c3860>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160574b1208>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.97      0.96      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 960    0    1    2    0    5    7    3    1    1]\n",
      " [   0 1114    3    2    1    1    5    1    8    0]\n",
      " [   4    1  992    5    7    2    6    9    6    0]\n",
      " [   1    0   13  965    0   10    0    8    9    4]\n",
      " [   1    0    4    1  940    0   11    1    3   21]\n",
      " [   9    1    0   11    3  846   10    0    6    6]\n",
      " [   7    3    0    0    7   10  927    0    4    0]\n",
      " [   1    7   14    1    3    2    0  983    2   15]\n",
      " [   4    1    4   16    7    7   10    3  918    4]\n",
      " [   8    6    2   10   20    3    0    7    4  949]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 1.4076 - acc: 0.6281 - val_loss: 0.5965 - val_acc: 0.8496\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.4795 - acc: 0.8690 - val_loss: 0.3813 - val_acc: 0.8898\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3644 - acc: 0.8962 - val_loss: 0.3218 - val_acc: 0.9091\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.3190 - acc: 0.9084 - val_loss: 0.2874 - val_acc: 0.9176\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2905 - acc: 0.9160 - val_loss: 0.2706 - val_acc: 0.9186\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2686 - acc: 0.9221 - val_loss: 0.2493 - val_acc: 0.9256\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2512 - acc: 0.9269 - val_loss: 0.2329 - val_acc: 0.9329\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2357 - acc: 0.9322 - val_loss: 0.2229 - val_acc: 0.9362\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.2226 - acc: 0.9356 - val_loss: 0.2096 - val_acc: 0.9395\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2107 - acc: 0.9395 - val_loss: 0.2008 - val_acc: 0.9407\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2002 - acc: 0.9427 - val_loss: 0.1908 - val_acc: 0.9430\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1907 - acc: 0.9453 - val_loss: 0.1838 - val_acc: 0.9460\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1821 - acc: 0.9472 - val_loss: 0.1762 - val_acc: 0.9474\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1740 - acc: 0.9498 - val_loss: 0.1715 - val_acc: 0.9504\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1668 - acc: 0.9516 - val_loss: 0.1643 - val_acc: 0.9502\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1603 - acc: 0.9535 - val_loss: 0.1578 - val_acc: 0.9521\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1541 - acc: 0.9557 - val_loss: 0.1539 - val_acc: 0.9537\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1484 - acc: 0.9573 - val_loss: 0.1479 - val_acc: 0.9563\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1432 - acc: 0.9591 - val_loss: 0.1454 - val_acc: 0.9548\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1382 - acc: 0.9606 - val_loss: 0.1418 - val_acc: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160587f1fd0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160588084a8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160587ddac8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605886cf60>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160588750f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605885ba58>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.94      0.95      0.94       892\n",
      "           6       0.95      0.98      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.97      0.92      0.94       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    1    1    0    3    6    1    2    1]\n",
      " [   0 1120    3    1    0    1    4    2    4    0]\n",
      " [   6    1  990    7    6    1    8    7    6    0]\n",
      " [   0    1    9  961    0   15    0   13    6    5]\n",
      " [   1    0    6    0  941    1   11    3    2   17]\n",
      " [   9    1    1   12    4  844   11    0    6    4]\n",
      " [   6    3    0    0    4    9  936    0    0    0]\n",
      " [   1    9   16    3    3    1    0  975    1   19]\n",
      " [   4    4    4   19    6   14   12   10  897    4]\n",
      " [   7    6    1    9   23    7    1    8    1  946]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 1.3876 - acc: 0.6480 - val_loss: 0.5816 - val_acc: 0.8517\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4706 - acc: 0.8743 - val_loss: 0.3745 - val_acc: 0.8953\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3601 - acc: 0.8982 - val_loss: 0.3210 - val_acc: 0.9097\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3183 - acc: 0.9084 - val_loss: 0.2869 - val_acc: 0.9166\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2918 - acc: 0.9158 - val_loss: 0.2657 - val_acc: 0.9248\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2713 - acc: 0.9220 - val_loss: 0.2526 - val_acc: 0.9289\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2539 - acc: 0.9271 - val_loss: 0.2351 - val_acc: 0.9332\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2390 - acc: 0.9314 - val_loss: 0.2260 - val_acc: 0.9346\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2259 - acc: 0.9359 - val_loss: 0.2127 - val_acc: 0.9379\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2139 - acc: 0.9391 - val_loss: 0.2038 - val_acc: 0.9429\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2037 - acc: 0.9418 - val_loss: 0.1921 - val_acc: 0.9456\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1937 - acc: 0.9443 - val_loss: 0.1852 - val_acc: 0.9472\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1846 - acc: 0.9473 - val_loss: 0.1794 - val_acc: 0.9475\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1768 - acc: 0.9494 - val_loss: 0.1708 - val_acc: 0.9510\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1696 - acc: 0.9517 - val_loss: 0.1648 - val_acc: 0.9523\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1629 - acc: 0.9534 - val_loss: 0.1590 - val_acc: 0.9536\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1565 - acc: 0.9554 - val_loss: 0.1544 - val_acc: 0.9552\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1507 - acc: 0.9565 - val_loss: 0.1522 - val_acc: 0.9549\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1457 - acc: 0.9581 - val_loss: 0.1448 - val_acc: 0.9569\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1403 - acc: 0.9598 - val_loss: 0.1441 - val_acc: 0.9559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16059b8f860>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16059b8fcf8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16059b7e358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16059c0c7f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16059c0cda0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16059c172e8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.96      0.95      0.95       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.94      0.96      0.95       958\n",
      "           7       0.95      0.96      0.96      1028\n",
      "           8       0.97      0.92      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 962    0    0    2    0    4    8    3    1    0]\n",
      " [   0 1119    1    3    1    1    3    2    5    0]\n",
      " [   7    3  985    9    3    1    9    8    6    1]\n",
      " [   1    0   11  966    0    8    0   10    6    8]\n",
      " [   1    0    7    0  929    2   10    2    2   29]\n",
      " [   7    2    0    9    0  847   12    2    6    7]\n",
      " [   9    3    3    1    6   10  922    2    2    0]\n",
      " [   1    8   15    4    3    1    0  985    0   11]\n",
      " [   5    4    4   16    8   11   12    9  898    7]\n",
      " [   7    8    1   10   20    7    1    9    0  946]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 1.4268 - acc: 0.6397 - val_loss: 0.6095 - val_acc: 0.8519\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4833 - acc: 0.8711 - val_loss: 0.3842 - val_acc: 0.8925\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.3645 - acc: 0.8966 - val_loss: 0.3189 - val_acc: 0.9116\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3190 - acc: 0.9086 - val_loss: 0.2916 - val_acc: 0.9171\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2911 - acc: 0.9161 - val_loss: 0.2652 - val_acc: 0.9244\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2694 - acc: 0.9224 - val_loss: 0.2512 - val_acc: 0.9292\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.2520 - acc: 0.9282 - val_loss: 0.2325 - val_acc: 0.9328\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2370 - acc: 0.9326 - val_loss: 0.2255 - val_acc: 0.9337\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2242 - acc: 0.9364 - val_loss: 0.2101 - val_acc: 0.9402\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2120 - acc: 0.9398 - val_loss: 0.2018 - val_acc: 0.9401\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2012 - acc: 0.9431 - val_loss: 0.1918 - val_acc: 0.9440\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1908 - acc: 0.9456 - val_loss: 0.1877 - val_acc: 0.9434\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1821 - acc: 0.9484 - val_loss: 0.1760 - val_acc: 0.9486\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1738 - acc: 0.9504 - val_loss: 0.1706 - val_acc: 0.9495\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1664 - acc: 0.9531 - val_loss: 0.1632 - val_acc: 0.9522\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1590 - acc: 0.9551 - val_loss: 0.1562 - val_acc: 0.9540\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1528 - acc: 0.9569 - val_loss: 0.1529 - val_acc: 0.9547\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1470 - acc: 0.9576 - val_loss: 0.1476 - val_acc: 0.9570\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1414 - acc: 0.9597 - val_loss: 0.1415 - val_acc: 0.9572\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1362 - acc: 0.9609 - val_loss: 0.1391 - val_acc: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16059f6e0f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16059f6e588>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16059f4bac8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605afb3080>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605afb31d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605afb3b38>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.97      0.96      1032\n",
      "           3       0.95      0.96      0.96      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.97      0.94      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    1    2    1    2    8    1    1    0]\n",
      " [   0 1114    2    2    1    1    5    2    8    0]\n",
      " [   5    1  999    5    3    0    6    7    5    1]\n",
      " [   0    0   13  966    0    8    1    8   13    1]\n",
      " [   1    0    7    0  945    0    5    2    3   19]\n",
      " [   8    1    0   12    2  837   11    2   15    4]\n",
      " [   9    3    2    1    6    8  925    0    4    0]\n",
      " [   0   10   23    2    4    1    0  976    1   11]\n",
      " [   6    2    4   14    4    4    8    7  921    4]\n",
      " [   6    8    2    9   21    2    1   11   12  937]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.5374 - acc: 0.6044 - val_loss: 0.6696 - val_acc: 0.8305\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.5127 - acc: 0.8606 - val_loss: 0.4004 - val_acc: 0.8867\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3752 - acc: 0.8935 - val_loss: 0.3337 - val_acc: 0.9026\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3249 - acc: 0.9059 - val_loss: 0.2964 - val_acc: 0.9143\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2942 - acc: 0.9147 - val_loss: 0.2747 - val_acc: 0.9205\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2720 - acc: 0.9210 - val_loss: 0.2560 - val_acc: 0.9236\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2535 - acc: 0.9266 - val_loss: 0.2410 - val_acc: 0.9309\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2378 - acc: 0.9314 - val_loss: 0.2276 - val_acc: 0.9348\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2240 - acc: 0.9353 - val_loss: 0.2155 - val_acc: 0.9365\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2121 - acc: 0.9388 - val_loss: 0.2041 - val_acc: 0.9396\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2008 - acc: 0.9423 - val_loss: 0.1966 - val_acc: 0.9425\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1912 - acc: 0.9448 - val_loss: 0.1904 - val_acc: 0.9412\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1822 - acc: 0.9474 - val_loss: 0.1800 - val_acc: 0.9461\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1741 - acc: 0.9500 - val_loss: 0.1725 - val_acc: 0.9484\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1664 - acc: 0.9522 - val_loss: 0.1675 - val_acc: 0.9506\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1597 - acc: 0.9541 - val_loss: 0.1606 - val_acc: 0.9519\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1530 - acc: 0.9566 - val_loss: 0.1536 - val_acc: 0.9532\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1472 - acc: 0.9577 - val_loss: 0.1509 - val_acc: 0.9540\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1416 - acc: 0.9592 - val_loss: 0.1468 - val_acc: 0.9564\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1364 - acc: 0.9605 - val_loss: 0.1418 - val_acc: 0.9578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605b300940>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605b300dd8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605b2ef358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605b37cd68>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605b3852e8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605b385898>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.97      0.95      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.97      0.93      0.95       974\n",
      "           9       0.94      0.95      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 958    0    1    1    0    8    5    6    1    0]\n",
      " [   0 1119    3    2    0    1    3    2    5    0]\n",
      " [   8    1  985   10    3    1    9   10    3    2]\n",
      " [   0    1    7  973    0   12    0    8    5    4]\n",
      " [   1    0    3    0  934    0   12    3    2   27]\n",
      " [   7    1    0   13    1  847   10    1    6    6]\n",
      " [   6    3    4    0    7   10  924    3    1    0]\n",
      " [   1    9   16    9    3    1    0  976    0   13]\n",
      " [   4    1    5   20    5   10   12    7  905    5]\n",
      " [   5    8    1   10   14    3    1    9    1  957]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 1.4385 - acc: 0.6317 - val_loss: 0.6251 - val_acc: 0.8433\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.4920 - acc: 0.8663 - val_loss: 0.3818 - val_acc: 0.8967\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3655 - acc: 0.8953 - val_loss: 0.3235 - val_acc: 0.9074\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3163 - acc: 0.9084 - val_loss: 0.2871 - val_acc: 0.9152\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.2861 - acc: 0.9169 - val_loss: 0.2623 - val_acc: 0.9239\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2639 - acc: 0.9238 - val_loss: 0.2490 - val_acc: 0.9289\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2454 - acc: 0.9284 - val_loss: 0.2322 - val_acc: 0.9344\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2305 - acc: 0.9341 - val_loss: 0.2183 - val_acc: 0.9371\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2174 - acc: 0.9381 - val_loss: 0.2117 - val_acc: 0.9387\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2057 - acc: 0.9409 - val_loss: 0.1976 - val_acc: 0.9436\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1952 - acc: 0.9434 - val_loss: 0.1891 - val_acc: 0.9449\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1857 - acc: 0.9466 - val_loss: 0.1839 - val_acc: 0.9464\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1774 - acc: 0.9484 - val_loss: 0.1756 - val_acc: 0.9474\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1697 - acc: 0.9505 - val_loss: 0.1722 - val_acc: 0.9501\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1628 - acc: 0.9523 - val_loss: 0.1628 - val_acc: 0.9506\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1562 - acc: 0.9540 - val_loss: 0.1609 - val_acc: 0.9518\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1501 - acc: 0.9564 - val_loss: 0.1534 - val_acc: 0.9540\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1446 - acc: 0.9579 - val_loss: 0.1483 - val_acc: 0.9556\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1396 - acc: 0.9591 - val_loss: 0.1484 - val_acc: 0.9552\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1349 - acc: 0.9610 - val_loss: 0.1415 - val_acc: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605b6d2b70>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605b6fb0b8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605b6c0588>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605b74db00>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605b759048>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605b73f518>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.96      0.95      1032\n",
      "           3       0.94      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.94      0.95      0.94       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.96      0.93      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    3    0    5    5    1    1    1]\n",
      " [   0 1119    2    2    0    2    3    2    5    0]\n",
      " [   7    2  986    9    6    1    3   10    8    0]\n",
      " [   0    0   14  963    0   15    0   10    6    2]\n",
      " [   1    0    7    0  947    0    4    3    3   17]\n",
      " [   7    1    1   13    1  845   10    0    8    6]\n",
      " [  10    3    2    0    8   12  920    0    3    0]\n",
      " [   0    8   17    2    2    2    0  988    1    8]\n",
      " [   4    1    2   20    5   12    8    8  912    2]\n",
      " [   8    7    3    9   23    4    1   11    4  939]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 1.4049 - acc: 0.6547 - val_loss: 0.5866 - val_acc: 0.8533\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.4671 - acc: 0.8739 - val_loss: 0.3732 - val_acc: 0.8958\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3579 - acc: 0.8973 - val_loss: 0.3197 - val_acc: 0.9068\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3169 - acc: 0.9084 - val_loss: 0.2901 - val_acc: 0.9184\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2910 - acc: 0.9160 - val_loss: 0.2685 - val_acc: 0.9240\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2708 - acc: 0.9218 - val_loss: 0.2527 - val_acc: 0.9281\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2544 - acc: 0.9265 - val_loss: 0.2395 - val_acc: 0.9309\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2397 - acc: 0.9305 - val_loss: 0.2329 - val_acc: 0.9345\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2263 - acc: 0.9346 - val_loss: 0.2139 - val_acc: 0.9376\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2144 - acc: 0.9378 - val_loss: 0.2063 - val_acc: 0.9411\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2040 - acc: 0.9410 - val_loss: 0.2016 - val_acc: 0.9414\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1943 - acc: 0.9440 - val_loss: 0.1859 - val_acc: 0.9465\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1858 - acc: 0.9462 - val_loss: 0.1796 - val_acc: 0.9469\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1776 - acc: 0.9488 - val_loss: 0.1741 - val_acc: 0.9494\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1700 - acc: 0.9519 - val_loss: 0.1662 - val_acc: 0.9506\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1631 - acc: 0.9535 - val_loss: 0.1648 - val_acc: 0.9519\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1564 - acc: 0.9551 - val_loss: 0.1552 - val_acc: 0.9548\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1505 - acc: 0.9572 - val_loss: 0.1517 - val_acc: 0.9548\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1451 - acc: 0.9584 - val_loss: 0.1453 - val_acc: 0.9572\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1399 - acc: 0.9598 - val_loss: 0.1411 - val_acc: 0.9572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605ca6e828>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605ca6ecc0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605ca57320>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605caf6c50>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605cb011d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605cae8668>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.94      0.95      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    2    0    5    5    2    1    1]\n",
      " [   0 1114    1    3    0    1    5    2    9    0]\n",
      " [   6    2  980   10    3    0   10   10   10    1]\n",
      " [   1    1    8  964    0    9    0    9   16    2]\n",
      " [   1    0    5    1  939    0    7    2    3   24]\n",
      " [   7    1    1   11    2  841   11    1   11    6]\n",
      " [   8    3    2    0    6   10  926    0    3    0]\n",
      " [   0    8   12    9    3    1    0  969    2   24]\n",
      " [   3    1    3   13    4    5    9    7  926    3]\n",
      " [   6    5    2    9   19    4    1    6    7  950]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 1.4742 - acc: 0.6324 - val_loss: 0.6340 - val_acc: 0.8518\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.4845 - acc: 0.8730 - val_loss: 0.3844 - val_acc: 0.8903\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3643 - acc: 0.8969 - val_loss: 0.3276 - val_acc: 0.9032\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3200 - acc: 0.9081 - val_loss: 0.2979 - val_acc: 0.9122\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2918 - acc: 0.9166 - val_loss: 0.2699 - val_acc: 0.9214\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2701 - acc: 0.9224 - val_loss: 0.2507 - val_acc: 0.9265\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2530 - acc: 0.9277 - val_loss: 0.2378 - val_acc: 0.9300\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2377 - acc: 0.9315 - val_loss: 0.2243 - val_acc: 0.9355\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2241 - acc: 0.9359 - val_loss: 0.2114 - val_acc: 0.9372\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2122 - acc: 0.9395 - val_loss: 0.2029 - val_acc: 0.9385\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2018 - acc: 0.9421 - val_loss: 0.1945 - val_acc: 0.9428\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1918 - acc: 0.9452 - val_loss: 0.1844 - val_acc: 0.9435\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1835 - acc: 0.9476 - val_loss: 0.1748 - val_acc: 0.9462\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1756 - acc: 0.9499 - val_loss: 0.1689 - val_acc: 0.9490\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1683 - acc: 0.9517 - val_loss: 0.1658 - val_acc: 0.9499\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1620 - acc: 0.9526 - val_loss: 0.1612 - val_acc: 0.9511\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1556 - acc: 0.9552 - val_loss: 0.1590 - val_acc: 0.9521\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1503 - acc: 0.9566 - val_loss: 0.1504 - val_acc: 0.9559\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1446 - acc: 0.9580 - val_loss: 0.1435 - val_acc: 0.9579\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1401 - acc: 0.9590 - val_loss: 0.1388 - val_acc: 0.9572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605de42550>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605de429e8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605de42f60>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605debb4e0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605debb630>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605dea4eb8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.97      0.96      1032\n",
      "           3       0.96      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.95      0.94      0.95       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 962    0    1    0    0    4    8    1    3    1]\n",
      " [   0 1116    2    2    1    1    4    2    7    0]\n",
      " [   5    1  996    5    3    0    4    8    8    2]\n",
      " [   2    0   13  956    0   10    0   12   14    3]\n",
      " [   1    0    9    0  941    0    9    1    2   19]\n",
      " [   8    2    1   13    2  838   10    2    8    8]\n",
      " [   6    3    3    1    5    9  925    2    4    0]\n",
      " [   0    7   21    2    2    1    0  979    0   16]\n",
      " [   4    1    5   13    6    6   10    7  920    2]\n",
      " [   6    8    1    7   27    5    1    8    7  939]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 1.4169 - acc: 0.6484 - val_loss: 0.6056 - val_acc: 0.8509\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.4829 - acc: 0.8698 - val_loss: 0.3830 - val_acc: 0.8953\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3644 - acc: 0.8967 - val_loss: 0.3266 - val_acc: 0.9073\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.3182 - acc: 0.9090 - val_loss: 0.2878 - val_acc: 0.9182\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2893 - acc: 0.9160 - val_loss: 0.2706 - val_acc: 0.9229\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2679 - acc: 0.9230 - val_loss: 0.2514 - val_acc: 0.9282\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2506 - acc: 0.9279 - val_loss: 0.2359 - val_acc: 0.9329\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2359 - acc: 0.9316 - val_loss: 0.2242 - val_acc: 0.9351\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2233 - acc: 0.9358 - val_loss: 0.2134 - val_acc: 0.9374\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2121 - acc: 0.9389 - val_loss: 0.2038 - val_acc: 0.9395\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2014 - acc: 0.9428 - val_loss: 0.1927 - val_acc: 0.9444\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1924 - acc: 0.9439 - val_loss: 0.1863 - val_acc: 0.9450\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1839 - acc: 0.9467 - val_loss: 0.1781 - val_acc: 0.9483\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1758 - acc: 0.9496 - val_loss: 0.1762 - val_acc: 0.9490\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1681 - acc: 0.9513 - val_loss: 0.1647 - val_acc: 0.9516\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1613 - acc: 0.9530 - val_loss: 0.1597 - val_acc: 0.9528\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1549 - acc: 0.9549 - val_loss: 0.1546 - val_acc: 0.9533\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1488 - acc: 0.9568 - val_loss: 0.1483 - val_acc: 0.9567\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1432 - acc: 0.9579 - val_loss: 0.1448 - val_acc: 0.9574\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1379 - acc: 0.9599 - val_loss: 0.1410 - val_acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605e20ada0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605e21a2e8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605e1f47b8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605e283d30>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605e28b2b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605e273748>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.95      0.94      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.97      0.96      0.96      1028\n",
      "           8       0.93      0.95      0.94       974\n",
      "           9       0.97      0.92      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    1    1    0    4    5    2    1    1]\n",
      " [   0 1113    3    2    0    1    4    3    9    0]\n",
      " [   7    1  991    9    3    1    8    5    7    0]\n",
      " [   1    1   11  963    0   12    0    7   15    0]\n",
      " [   1    1    4    0  946    0   11    1    4   14]\n",
      " [   9    1    1   11    0  842   12    0   12    4]\n",
      " [   9    3    1    1    5    7  926    2    4    0]\n",
      " [   1    8   17    4    2    1    0  982    4    9]\n",
      " [   4    2    2   14    4    8    7    3  930    0]\n",
      " [   7    8    1    9   28    7    1    7   11  930]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 1.3825 - acc: 0.6521 - val_loss: 0.5999 - val_acc: 0.8482\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.4817 - acc: 0.8698 - val_loss: 0.3874 - val_acc: 0.8915\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3670 - acc: 0.8961 - val_loss: 0.3263 - val_acc: 0.9079\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3216 - acc: 0.9072 - val_loss: 0.2935 - val_acc: 0.9169\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2928 - acc: 0.9156 - val_loss: 0.2728 - val_acc: 0.9220\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2708 - acc: 0.9217 - val_loss: 0.2518 - val_acc: 0.9281\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2530 - acc: 0.9271 - val_loss: 0.2397 - val_acc: 0.9318\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2375 - acc: 0.9313 - val_loss: 0.2254 - val_acc: 0.9359\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2238 - acc: 0.9350 - val_loss: 0.2115 - val_acc: 0.9388\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2119 - acc: 0.9386 - val_loss: 0.2068 - val_acc: 0.9404\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2010 - acc: 0.9414 - val_loss: 0.1959 - val_acc: 0.9430\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1916 - acc: 0.9451 - val_loss: 0.1870 - val_acc: 0.9454\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1825 - acc: 0.9473 - val_loss: 0.1804 - val_acc: 0.9480\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1742 - acc: 0.9496 - val_loss: 0.1705 - val_acc: 0.9507\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1670 - acc: 0.9518 - val_loss: 0.1679 - val_acc: 0.9516\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1602 - acc: 0.9534 - val_loss: 0.1608 - val_acc: 0.9539\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1538 - acc: 0.9556 - val_loss: 0.1539 - val_acc: 0.9554\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1476 - acc: 0.9567 - val_loss: 0.1520 - val_acc: 0.9565\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1423 - acc: 0.9593 - val_loss: 0.1476 - val_acc: 0.9576\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1374 - acc: 0.9600 - val_loss: 0.1408 - val_acc: 0.9598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605f5be630>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1605f5beac8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1605f5beef0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160606095c0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16060609710>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160605f2f98>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.96      0.95      0.96      1010\n",
      "           4       0.95      0.97      0.96       982\n",
      "           5       0.96      0.96      0.96       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.95      0.94      0.94       974\n",
      "           9       0.96      0.93      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 967    0    0    1    0    4    5    2    1    0]\n",
      " [   0 1118    3    2    0    1    3    1    7    0]\n",
      " [   7    3  991    5    4    2    6    9    5    0]\n",
      " [   0    0   14  961    0   13    0    9   12    1]\n",
      " [   1    0    4    0  948    0   10    1    2   16]\n",
      " [   8    2    0    6    2  852    9    0    9    4]\n",
      " [   9    3    1    0    7    9  924    0    5    0]\n",
      " [   2    8   18    2    4    0    0  982    1   11]\n",
      " [   6    2    4   14    7    8   12    5  912    4]\n",
      " [   8    5    1    6   26    3    1   10    6  943]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.3544 - acc: 0.6529 - val_loss: 0.5844 - val_acc: 0.8534\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.4742 - acc: 0.8718 - val_loss: 0.3866 - val_acc: 0.8921\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3675 - acc: 0.8960 - val_loss: 0.3360 - val_acc: 0.9006\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.3232 - acc: 0.9077 - val_loss: 0.2945 - val_acc: 0.9153\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2938 - acc: 0.9153 - val_loss: 0.2707 - val_acc: 0.9237\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2715 - acc: 0.9221 - val_loss: 0.2541 - val_acc: 0.9267\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2526 - acc: 0.9270 - val_loss: 0.2374 - val_acc: 0.9321\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2369 - acc: 0.9328 - val_loss: 0.2276 - val_acc: 0.9329\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2227 - acc: 0.9366 - val_loss: 0.2128 - val_acc: 0.9374\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2101 - acc: 0.9399 - val_loss: 0.2035 - val_acc: 0.9407\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1998 - acc: 0.9428 - val_loss: 0.1928 - val_acc: 0.9420\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1900 - acc: 0.9456 - val_loss: 0.1854 - val_acc: 0.9430\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1812 - acc: 0.9479 - val_loss: 0.1786 - val_acc: 0.9473\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1735 - acc: 0.9503 - val_loss: 0.1706 - val_acc: 0.9491\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1663 - acc: 0.9526 - val_loss: 0.1636 - val_acc: 0.9510\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1594 - acc: 0.9542 - val_loss: 0.1581 - val_acc: 0.9525\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1528 - acc: 0.9561 - val_loss: 0.1538 - val_acc: 0.9535\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1476 - acc: 0.9582 - val_loss: 0.1521 - val_acc: 0.9556\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1419 - acc: 0.9592 - val_loss: 0.1489 - val_acc: 0.9553\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1371 - acc: 0.9608 - val_loss: 0.1420 - val_acc: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16060952e80>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606095f3c8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606095f8d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160609d4e10>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160609dd390>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160609dd940>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.95      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.94      0.95      0.95       892\n",
      "           6       0.94      0.97      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.97      0.93      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    1    0    4    7    3    1    0]\n",
      " [   0 1119    1    3    0    1    4    2    5    0]\n",
      " [   9    2  987    9    3    0    7    8    5    2]\n",
      " [   1    1   14  956    0   16    0   11    6    5]\n",
      " [   1    1    3    0  938    0   14    2    2   21]\n",
      " [   7    1    0   11    2  848   12    1    5    5]\n",
      " [   7    3    0    0    5   12  926    2    3    0]\n",
      " [   1   12   14    6    2    1    0  983    1    8]\n",
      " [   5    2    4   17    7   11   10    8  906    4]\n",
      " [   6    7    4   10   20    6    1    8    3  944]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 1.4523 - acc: 0.6262 - val_loss: 0.6139 - val_acc: 0.8535\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.4834 - acc: 0.8717 - val_loss: 0.3798 - val_acc: 0.8949\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3653 - acc: 0.8964 - val_loss: 0.3230 - val_acc: 0.9106\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.3195 - acc: 0.9081 - val_loss: 0.2937 - val_acc: 0.9162\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2907 - acc: 0.9167 - val_loss: 0.2690 - val_acc: 0.9234\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2692 - acc: 0.9228 - val_loss: 0.2510 - val_acc: 0.9289\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2510 - acc: 0.9277 - val_loss: 0.2352 - val_acc: 0.9343\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2363 - acc: 0.9321 - val_loss: 0.2218 - val_acc: 0.9378\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2228 - acc: 0.9361 - val_loss: 0.2117 - val_acc: 0.9394\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2115 - acc: 0.9392 - val_loss: 0.2002 - val_acc: 0.9421\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2004 - acc: 0.9425 - val_loss: 0.1929 - val_acc: 0.9441\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1910 - acc: 0.9448 - val_loss: 0.1892 - val_acc: 0.9454\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1824 - acc: 0.9473 - val_loss: 0.1770 - val_acc: 0.9485\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1744 - acc: 0.9495 - val_loss: 0.1704 - val_acc: 0.9510\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1670 - acc: 0.9509 - val_loss: 0.1628 - val_acc: 0.9515\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1599 - acc: 0.9541 - val_loss: 0.1569 - val_acc: 0.9525\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1537 - acc: 0.9560 - val_loss: 0.1527 - val_acc: 0.9547\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1480 - acc: 0.9573 - val_loss: 0.1490 - val_acc: 0.9551\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1425 - acc: 0.9590 - val_loss: 0.1460 - val_acc: 0.9556\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1374 - acc: 0.9605 - val_loss: 0.1413 - val_acc: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603e8d9710>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603e8d9ba8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1603e8ee198>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603e9536a0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1603e9537f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1603e95d160>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.97      0.94      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.95      0.94      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    0    1    1    3    5    1    2    2]\n",
      " [   0 1118    2    2    0    1    4    2    6    0]\n",
      " [   7    3  975    8    7    2    7   12   10    1]\n",
      " [   1    0    7  964    1   15    2    8    9    3]\n",
      " [   1    0    5    0  946    0    9    2    2   17]\n",
      " [   8    2    0   13    3  838   12    3    7    6]\n",
      " [   9    3    2    0    7    9  927    0    1    0]\n",
      " [   1    8   15    2    1    1    0  982    0   18]\n",
      " [   6    2    2   11    6    8   12    7  915    5]\n",
      " [   9    7    0   11   23    4    0    6    2  947]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.4740 - acc: 0.6384 - val_loss: 0.6275 - val_acc: 0.8467\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.4935 - acc: 0.8659 - val_loss: 0.3818 - val_acc: 0.8931\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3677 - acc: 0.8961 - val_loss: 0.3208 - val_acc: 0.9073\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3215 - acc: 0.9077 - val_loss: 0.2898 - val_acc: 0.9155\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2929 - acc: 0.9157 - val_loss: 0.2675 - val_acc: 0.9233\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2718 - acc: 0.9215 - val_loss: 0.2530 - val_acc: 0.9270\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2543 - acc: 0.9271 - val_loss: 0.2408 - val_acc: 0.9298\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2396 - acc: 0.9313 - val_loss: 0.2283 - val_acc: 0.9351\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2262 - acc: 0.9352 - val_loss: 0.2154 - val_acc: 0.9382\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2148 - acc: 0.9383 - val_loss: 0.2063 - val_acc: 0.9404\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2038 - acc: 0.9412 - val_loss: 0.1980 - val_acc: 0.9418\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1942 - acc: 0.9440 - val_loss: 0.1905 - val_acc: 0.9435\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1853 - acc: 0.9465 - val_loss: 0.1860 - val_acc: 0.9450\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1772 - acc: 0.9491 - val_loss: 0.1731 - val_acc: 0.9487\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1696 - acc: 0.9513 - val_loss: 0.1676 - val_acc: 0.9487\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1630 - acc: 0.9530 - val_loss: 0.1646 - val_acc: 0.9497\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1567 - acc: 0.9551 - val_loss: 0.1558 - val_acc: 0.9526\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1507 - acc: 0.9563 - val_loss: 0.1499 - val_acc: 0.9548\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1451 - acc: 0.9582 - val_loss: 0.1463 - val_acc: 0.9564\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1397 - acc: 0.9593 - val_loss: 0.1413 - val_acc: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16062233f60>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16062241438>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16062241a58>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160622b1ef0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160622ba080>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160622a19e8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.94      0.97      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.97      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.95      0.94      0.94       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    1    1    4    7    2    1    0]\n",
      " [   0 1118    3    2    0    0    3    2    7    0]\n",
      " [   3    2 1000    5    5    0    2    7    7    1]\n",
      " [   0    0   18  960    0   13    0    8   11    0]\n",
      " [   1    1    7    0  935    0   11    1    4   22]\n",
      " [   8    2    1   15    2  842    9    1    8    4]\n",
      " [   9    3    1    0    6    8  927    0    4    0]\n",
      " [   0    8   20    3    3    1    0  982    1   10]\n",
      " [   3    3    7   16    5    7   10    9  912    2]\n",
      " [   5    8    2   10   23    6    1   10    6  938]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.4096 - acc: 0.6507 - val_loss: 0.5831 - val_acc: 0.8585\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.4663 - acc: 0.8756 - val_loss: 0.3721 - val_acc: 0.8958\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3556 - acc: 0.8980 - val_loss: 0.3150 - val_acc: 0.9098\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3132 - acc: 0.9098 - val_loss: 0.2850 - val_acc: 0.9188\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2858 - acc: 0.9177 - val_loss: 0.2632 - val_acc: 0.9263\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2654 - acc: 0.9229 - val_loss: 0.2446 - val_acc: 0.9317\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2481 - acc: 0.9283 - val_loss: 0.2356 - val_acc: 0.9335\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2336 - acc: 0.9325 - val_loss: 0.2234 - val_acc: 0.9372\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2206 - acc: 0.9373 - val_loss: 0.2095 - val_acc: 0.9412\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.2095 - acc: 0.9397 - val_loss: 0.2017 - val_acc: 0.9424\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1989 - acc: 0.9429 - val_loss: 0.1921 - val_acc: 0.9436\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1900 - acc: 0.9450 - val_loss: 0.1837 - val_acc: 0.9462\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1815 - acc: 0.9478 - val_loss: 0.1787 - val_acc: 0.9485\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1739 - acc: 0.9501 - val_loss: 0.1708 - val_acc: 0.9506\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1666 - acc: 0.9520 - val_loss: 0.1637 - val_acc: 0.9520\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1603 - acc: 0.9539 - val_loss: 0.1559 - val_acc: 0.9532\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1537 - acc: 0.9564 - val_loss: 0.1564 - val_acc: 0.9523\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1482 - acc: 0.9574 - val_loss: 0.1496 - val_acc: 0.9551\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1428 - acc: 0.9590 - val_loss: 0.1453 - val_acc: 0.9563\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1378 - acc: 0.9606 - val_loss: 0.1413 - val_acc: 0.9585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160635e97f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160635e9c88>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160635d6208>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16063661780>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160636618d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16063652198>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.95      0.94      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 969    0    1    2    0    2    3    1    1    1]\n",
      " [   0 1116    3    2    0    1    4    2    7    0]\n",
      " [   5    1  995    5    2    1    9    7    7    0]\n",
      " [   1    0    9  972    0   13    0    8    6    1]\n",
      " [   1    0    5    1  943    1   12    1    2   16]\n",
      " [   9    1    2   13    1  840   13    0    9    4]\n",
      " [   8    3    2    0    5   10  925    2    3    0]\n",
      " [   1    9   17    6    1    2    0  980    1   11]\n",
      " [   8    2    7   15    8    4   10    7  911    2]\n",
      " [   9    7    1   10   24    7    1   11    5  934]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 1.3853 - acc: 0.6834 - val_loss: 0.5945 - val_acc: 0.8434\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.4765 - acc: 0.8705 - val_loss: 0.3805 - val_acc: 0.8974\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3648 - acc: 0.8966 - val_loss: 0.3238 - val_acc: 0.9070\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3211 - acc: 0.9075 - val_loss: 0.2955 - val_acc: 0.9161\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2938 - acc: 0.9145 - val_loss: 0.2751 - val_acc: 0.9215\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2734 - acc: 0.9203 - val_loss: 0.2573 - val_acc: 0.9264\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2570 - acc: 0.9257 - val_loss: 0.2423 - val_acc: 0.9301\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2426 - acc: 0.9302 - val_loss: 0.2296 - val_acc: 0.9332\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2299 - acc: 0.9343 - val_loss: 0.2214 - val_acc: 0.9344\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2183 - acc: 0.9374 - val_loss: 0.2109 - val_acc: 0.9367\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2075 - acc: 0.9408 - val_loss: 0.2002 - val_acc: 0.9404\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1980 - acc: 0.9435 - val_loss: 0.1920 - val_acc: 0.9441\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1895 - acc: 0.9457 - val_loss: 0.1860 - val_acc: 0.9464\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1815 - acc: 0.9482 - val_loss: 0.1792 - val_acc: 0.9479\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1738 - acc: 0.9501 - val_loss: 0.1707 - val_acc: 0.9493\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1668 - acc: 0.9523 - val_loss: 0.1655 - val_acc: 0.9504\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1602 - acc: 0.9536 - val_loss: 0.1587 - val_acc: 0.9524\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1541 - acc: 0.9553 - val_loss: 0.1540 - val_acc: 0.9544\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1484 - acc: 0.9569 - val_loss: 0.1488 - val_acc: 0.9565\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1431 - acc: 0.9587 - val_loss: 0.1443 - val_acc: 0.9572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160639bc080>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160639bc518>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160639bcb38>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16063a2cb00>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160639d0048>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160639d05f8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.95      0.94      0.94       892\n",
      "           6       0.97      0.95      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.95      0.94      0.94       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    0    2    0    5    4    2    2    0]\n",
      " [   0 1116    3    2    0    1    3    2    8    0]\n",
      " [   4    1  995    9    6    1    4    7    5    0]\n",
      " [   2    1    9  964    1   11    0   10    9    3]\n",
      " [   1    1    7    0  943    0    5    1    4   20]\n",
      " [   8    2    0   18    3  836    9    0   11    5]\n",
      " [  10    3    2    0    9   14  914    0    6    0]\n",
      " [   1    9   15    5    2    2    0  983    1   10]\n",
      " [   5    2    3   16    5    9    7    6  919    2]\n",
      " [   9    7    1   11   24    5    1    8    6  937]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 1.3475 - acc: 0.6940 - val_loss: 0.5914 - val_acc: 0.8482\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.4790 - acc: 0.8704 - val_loss: 0.3766 - val_acc: 0.8968\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3664 - acc: 0.8961 - val_loss: 0.3214 - val_acc: 0.9090\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3214 - acc: 0.9079 - val_loss: 0.2910 - val_acc: 0.9171\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2931 - acc: 0.9156 - val_loss: 0.2707 - val_acc: 0.9230\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2726 - acc: 0.9209 - val_loss: 0.2571 - val_acc: 0.9277\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2556 - acc: 0.9259 - val_loss: 0.2383 - val_acc: 0.9311\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2408 - acc: 0.9306 - val_loss: 0.2303 - val_acc: 0.9337\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2280 - acc: 0.9340 - val_loss: 0.2154 - val_acc: 0.9386\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2167 - acc: 0.9375 - val_loss: 0.2070 - val_acc: 0.9408\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2066 - acc: 0.9400 - val_loss: 0.1984 - val_acc: 0.9427\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1968 - acc: 0.9429 - val_loss: 0.1912 - val_acc: 0.9437\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1886 - acc: 0.9450 - val_loss: 0.1823 - val_acc: 0.9468\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1806 - acc: 0.9475 - val_loss: 0.1788 - val_acc: 0.9487\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1734 - acc: 0.9494 - val_loss: 0.1718 - val_acc: 0.9468\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1668 - acc: 0.9513 - val_loss: 0.1702 - val_acc: 0.9489\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1603 - acc: 0.9536 - val_loss: 0.1667 - val_acc: 0.9500\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1545 - acc: 0.9548 - val_loss: 0.1560 - val_acc: 0.9530\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1494 - acc: 0.9564 - val_loss: 0.1520 - val_acc: 0.9541\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1446 - acc: 0.9584 - val_loss: 0.1470 - val_acc: 0.9552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16064d67400>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16064d67898>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16064d4cdd8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16065da6e80>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16065db1400>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16065d98898>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.93      0.96      0.94      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.95      0.93      0.94       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.95      0.94      0.95       974\n",
      "           9       0.93      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.95      0.95     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 961    0    0    2    0    4    6    3    1    3]\n",
      " [   0 1116    3    2    0    1    3    2    8    0]\n",
      " [   5    1  994    7    3    1    4    8    6    3]\n",
      " [   2    0    9  967    0   11    0   10   10    1]\n",
      " [   1    0    5    0  933    0    9    2    2   30]\n",
      " [   8    1    0   23    1  829   10    1   11    8]\n",
      " [  11    3    2    1    7   10  921    0    3    0]\n",
      " [   0    8   22    6    2    1    0  968    1   20]\n",
      " [   4    3    4   20    3    7    7    8  912    6]\n",
      " [   5    8    2   10   18    5    1    8    1  951]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 1.3929 - acc: 0.6545 - val_loss: 0.6071 - val_acc: 0.8430\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.4833 - acc: 0.8697 - val_loss: 0.3857 - val_acc: 0.8934\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3652 - acc: 0.8974 - val_loss: 0.3251 - val_acc: 0.9105\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3185 - acc: 0.9093 - val_loss: 0.2899 - val_acc: 0.9187\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2896 - acc: 0.9168 - val_loss: 0.2741 - val_acc: 0.9204\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2683 - acc: 0.9227 - val_loss: 0.2512 - val_acc: 0.9280\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2510 - acc: 0.9282 - val_loss: 0.2373 - val_acc: 0.9326\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2359 - acc: 0.9322 - val_loss: 0.2232 - val_acc: 0.9351\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2229 - acc: 0.9362 - val_loss: 0.2169 - val_acc: 0.9370\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2114 - acc: 0.9400 - val_loss: 0.2025 - val_acc: 0.9416\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2006 - acc: 0.9427 - val_loss: 0.1947 - val_acc: 0.9443\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1915 - acc: 0.9458 - val_loss: 0.1874 - val_acc: 0.9464\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1829 - acc: 0.9479 - val_loss: 0.1784 - val_acc: 0.9481\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1749 - acc: 0.9506 - val_loss: 0.1724 - val_acc: 0.9480\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1675 - acc: 0.9526 - val_loss: 0.1651 - val_acc: 0.9515\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1607 - acc: 0.9543 - val_loss: 0.1610 - val_acc: 0.9534\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1547 - acc: 0.9558 - val_loss: 0.1563 - val_acc: 0.9544\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1487 - acc: 0.9576 - val_loss: 0.1522 - val_acc: 0.9548\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1438 - acc: 0.9589 - val_loss: 0.1465 - val_acc: 0.9565\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1421 - val_acc: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160660fc780>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160660fcc18>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606610c208>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606617b710>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606617b860>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606616a128>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.96      0.95      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.97      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.93      0.95      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 968    0    0    1    0    4    3    1    2    1]\n",
      " [   0 1117    3    2    0    2    2    2    7    0]\n",
      " [   7    1  988    8    6    1    4    8    8    1]\n",
      " [   0    1    8  973    1    6    0   10    7    4]\n",
      " [   1    0    4    0  935    0    7    3    3   29]\n",
      " [   8    1    0   15    1  842    8    2    8    7]\n",
      " [   8    3    2    1   10   10  917    0    7    0]\n",
      " [   0    7   13    5    5    0    0  974    0   24]\n",
      " [   4    2    3   14    4    8    6    6  923    4]\n",
      " [   6    5    1   11   16    6    0    7    2  955]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 1.4201 - acc: 0.6510 - val_loss: 0.5867 - val_acc: 0.8578\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.4755 - acc: 0.8715 - val_loss: 0.3789 - val_acc: 0.8941\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.3665 - acc: 0.8960 - val_loss: 0.3224 - val_acc: 0.9080\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3223 - acc: 0.9080 - val_loss: 0.2901 - val_acc: 0.9175\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2937 - acc: 0.9163 - val_loss: 0.2682 - val_acc: 0.9228\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2725 - acc: 0.9214 - val_loss: 0.2530 - val_acc: 0.9277\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2547 - acc: 0.9268 - val_loss: 0.2380 - val_acc: 0.9317\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2398 - acc: 0.9304 - val_loss: 0.2255 - val_acc: 0.9365\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.2264 - acc: 0.9349 - val_loss: 0.2169 - val_acc: 0.9382\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2147 - acc: 0.9380 - val_loss: 0.2048 - val_acc: 0.9408\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2039 - acc: 0.9414 - val_loss: 0.1980 - val_acc: 0.9428\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1944 - acc: 0.9443 - val_loss: 0.1888 - val_acc: 0.9446\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1855 - acc: 0.9459 - val_loss: 0.1813 - val_acc: 0.9464\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1771 - acc: 0.9485 - val_loss: 0.1754 - val_acc: 0.9478\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1696 - acc: 0.9507 - val_loss: 0.1664 - val_acc: 0.9509\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1625 - acc: 0.9531 - val_loss: 0.1632 - val_acc: 0.9517\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1560 - acc: 0.9545 - val_loss: 0.1554 - val_acc: 0.9535\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1497 - acc: 0.9562 - val_loss: 0.1517 - val_acc: 0.9553\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1445 - acc: 0.9584 - val_loss: 0.1469 - val_acc: 0.9563\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1390 - acc: 0.9594 - val_loss: 0.1452 - val_acc: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160664c6fd0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160664d7518>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160664d7a20>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16066545f60>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606654d0f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606654da58>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.92      0.97      0.95      1010\n",
      "           4       0.96      0.95      0.95       982\n",
      "           5       0.96      0.93      0.94       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    1    2    0    5    5    1    1    0]\n",
      " [   0 1112    3    2    0    1    3    3   11    0]\n",
      " [   6    1  991    8    4    0    7    6    7    2]\n",
      " [   1    0    6  979    0    7    0    6    9    2]\n",
      " [   2    1    5    0  930    0   11    3    7   23]\n",
      " [   8    1    1   27    0  829    9    3    9    5]\n",
      " [  10    3    3    1    8   10  918    0    5    0]\n",
      " [   2    7   20    8    2    1    0  971    3   14]\n",
      " [   3    1    4   18    4    5    8    5  926    0]\n",
      " [   5    7    1   15   20    5    1    7    9  939]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 1.4658 - acc: 0.6415 - val_loss: 0.6412 - val_acc: 0.8371\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.4958 - acc: 0.8655 - val_loss: 0.3859 - val_acc: 0.8928\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3678 - acc: 0.8961 - val_loss: 0.3240 - val_acc: 0.9065\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3214 - acc: 0.9075 - val_loss: 0.2902 - val_acc: 0.9169\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2926 - acc: 0.9150 - val_loss: 0.2702 - val_acc: 0.9222\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2718 - acc: 0.9208 - val_loss: 0.2534 - val_acc: 0.9273\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2541 - acc: 0.9268 - val_loss: 0.2385 - val_acc: 0.9309\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2392 - acc: 0.9308 - val_loss: 0.2283 - val_acc: 0.9338\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2256 - acc: 0.9345 - val_loss: 0.2110 - val_acc: 0.9380\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2137 - acc: 0.9383 - val_loss: 0.2021 - val_acc: 0.9431\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2023 - acc: 0.9420 - val_loss: 0.1950 - val_acc: 0.9439\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1924 - acc: 0.9447 - val_loss: 0.1837 - val_acc: 0.9469\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1831 - acc: 0.9473 - val_loss: 0.1778 - val_acc: 0.9487\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1747 - acc: 0.9491 - val_loss: 0.1684 - val_acc: 0.9518\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1671 - acc: 0.9513 - val_loss: 0.1651 - val_acc: 0.9511\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1599 - acc: 0.9538 - val_loss: 0.1610 - val_acc: 0.9532\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1534 - acc: 0.9555 - val_loss: 0.1530 - val_acc: 0.9558\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1471 - acc: 0.9573 - val_loss: 0.1461 - val_acc: 0.9573\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1419 - acc: 0.9589 - val_loss: 0.1420 - val_acc: 0.9577\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1365 - acc: 0.9605 - val_loss: 0.1404 - val_acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160675e0860>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160675e0cf8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16067608278>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160676677f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067667940>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16067656208>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.95      0.97      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.97      0.96      0.96       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.95      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 967    0    0    2    0    3    4    1    2    1]\n",
      " [   0 1111    3    2    1    2    3    1   12    0]\n",
      " [   6    1  983   11    6    1    7    7    9    1]\n",
      " [   1    0    4  974    0    9    0    6   12    4]\n",
      " [   1    0    6    0  950    0    2    1    5   17]\n",
      " [   6    1    0   14    2  848    9    0    6    6]\n",
      " [  10    3    0    0   11   13  915    0    6    0]\n",
      " [   0    8   17    7    6    1    0  971    2   16]\n",
      " [   4    1    2   19    5    8    4    6  922    3]\n",
      " [   5    6    1   10   22    5    0    5    8  947]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 1.4006 - acc: 0.6647 - val_loss: 0.6045 - val_acc: 0.8503\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.4762 - acc: 0.8724 - val_loss: 0.3829 - val_acc: 0.8932\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3636 - acc: 0.8968 - val_loss: 0.3266 - val_acc: 0.9051\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.3199 - acc: 0.9080 - val_loss: 0.2904 - val_acc: 0.9172\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.2920 - acc: 0.9166 - val_loss: 0.2707 - val_acc: 0.9220\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2707 - acc: 0.9227 - val_loss: 0.2561 - val_acc: 0.9255\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2531 - acc: 0.9272 - val_loss: 0.2365 - val_acc: 0.9329\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2382 - acc: 0.9314 - val_loss: 0.2244 - val_acc: 0.9357\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2245 - acc: 0.9352 - val_loss: 0.2142 - val_acc: 0.9379\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.2128 - acc: 0.9385 - val_loss: 0.2044 - val_acc: 0.9402\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.2024 - acc: 0.9418 - val_loss: 0.1943 - val_acc: 0.9439\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1926 - acc: 0.9440 - val_loss: 0.1856 - val_acc: 0.9456\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1843 - acc: 0.9464 - val_loss: 0.1774 - val_acc: 0.9470\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1761 - acc: 0.9489 - val_loss: 0.1709 - val_acc: 0.9481\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1683 - acc: 0.9511 - val_loss: 0.1646 - val_acc: 0.9508\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1620 - acc: 0.9527 - val_loss: 0.1633 - val_acc: 0.9511\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1558 - acc: 0.9548 - val_loss: 0.1577 - val_acc: 0.9533\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1499 - acc: 0.9565 - val_loss: 0.1505 - val_acc: 0.9554\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1443 - acc: 0.9582 - val_loss: 0.1447 - val_acc: 0.9566\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.1395 - acc: 0.9594 - val_loss: 0.1416 - val_acc: 0.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c300f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c30588>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16068c16ac8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068ca8080>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068ca81d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16068c8fa58>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.96      0.95      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.97      0.93      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 969    0    1    1    0    2    4    2    1    0]\n",
      " [   0 1115    3    2    0    1    4    2    8    0]\n",
      " [   8    1  989    7    5    0    4    9    8    1]\n",
      " [   1    2   14  963    0    8    0   10   11    1]\n",
      " [   1    0    6    1  938    0   11    2    4   19]\n",
      " [   9    2    2   15    3  834   11    1   10    5]\n",
      " [  10    3    3    0    8    7  921    0    6    0]\n",
      " [   0   10   18    4    2    0    0  977    2   15]\n",
      " [   5    2    4   12    5    6   10    7  921    2]\n",
      " [   9    8    1   11   22    2    1    5    8  942]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 1.3700 - acc: 0.6654 - val_loss: 0.5923 - val_acc: 0.8456\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.4784 - acc: 0.8695 - val_loss: 0.3792 - val_acc: 0.8955\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.3635 - acc: 0.8977 - val_loss: 0.3208 - val_acc: 0.9089\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.3177 - acc: 0.9091 - val_loss: 0.2865 - val_acc: 0.9190\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.2880 - acc: 0.9175 - val_loss: 0.2681 - val_acc: 0.9239\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2662 - acc: 0.9239 - val_loss: 0.2507 - val_acc: 0.9301\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.2480 - acc: 0.9287 - val_loss: 0.2370 - val_acc: 0.9315\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2329 - acc: 0.9331 - val_loss: 0.2229 - val_acc: 0.9366\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2197 - acc: 0.9369 - val_loss: 0.2098 - val_acc: 0.9397\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2084 - acc: 0.9401 - val_loss: 0.1993 - val_acc: 0.9419\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1976 - acc: 0.9431 - val_loss: 0.1902 - val_acc: 0.9439\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1880 - acc: 0.9459 - val_loss: 0.1841 - val_acc: 0.9458\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1793 - acc: 0.9485 - val_loss: 0.1762 - val_acc: 0.9472\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1714 - acc: 0.9514 - val_loss: 0.1692 - val_acc: 0.9486\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.1643 - acc: 0.9526 - val_loss: 0.1656 - val_acc: 0.9516\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1575 - acc: 0.9549 - val_loss: 0.1561 - val_acc: 0.9531\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1513 - acc: 0.9569 - val_loss: 0.1527 - val_acc: 0.9532\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1458 - acc: 0.9577 - val_loss: 0.1503 - val_acc: 0.9555\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1407 - acc: 0.9598 - val_loss: 0.1430 - val_acc: 0.9558\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1354 - acc: 0.9616 - val_loss: 0.1386 - val_acc: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16069007940>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16069007dd8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16068ff7358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16069085518>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16069085668>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606906efd0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.96      0.93      0.94       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 962    0    1    1    0    6    5    2    2    1]\n",
      " [   0 1117    3    2    0    1    5    2    5    0]\n",
      " [   4    1  986   10    6    3    6    8    8    0]\n",
      " [   0    0    5  973    0   12    0   10    8    2]\n",
      " [   1    0    3    0  941    0   11    4    2   20]\n",
      " [   8    1    1   14    2  843   11    0    6    6]\n",
      " [   8    3    0    0    7   10  926    0    4    0]\n",
      " [   2    8   14    6    4    1    0  977    2   14]\n",
      " [   5    1    4   17    6   10   11    9  907    4]\n",
      " [   7    5    1   11   23    4    1    9    4  944]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 1.3900 - acc: 0.6607 - val_loss: 0.6063 - val_acc: 0.8473\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.4827 - acc: 0.8701 - val_loss: 0.3801 - val_acc: 0.8964\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3646 - acc: 0.8967 - val_loss: 0.3208 - val_acc: 0.9089\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.3196 - acc: 0.9082 - val_loss: 0.2900 - val_acc: 0.9162\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2911 - acc: 0.9162 - val_loss: 0.2708 - val_acc: 0.9218\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2702 - acc: 0.9222 - val_loss: 0.2541 - val_acc: 0.9250\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.2526 - acc: 0.9275 - val_loss: 0.2396 - val_acc: 0.9311\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.2377 - acc: 0.9315 - val_loss: 0.2288 - val_acc: 0.9355\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2240 - acc: 0.9351 - val_loss: 0.2132 - val_acc: 0.9365\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2124 - acc: 0.9386 - val_loss: 0.2075 - val_acc: 0.9386\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2011 - acc: 0.9420 - val_loss: 0.1951 - val_acc: 0.9419\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1914 - acc: 0.9441 - val_loss: 0.1872 - val_acc: 0.9441\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1822 - acc: 0.9473 - val_loss: 0.1794 - val_acc: 0.9483\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1741 - acc: 0.9490 - val_loss: 0.1726 - val_acc: 0.9484\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1660 - acc: 0.9515 - val_loss: 0.1685 - val_acc: 0.9495\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1592 - acc: 0.9539 - val_loss: 0.1602 - val_acc: 0.9517\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1527 - acc: 0.9561 - val_loss: 0.1565 - val_acc: 0.9525\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1465 - acc: 0.9576 - val_loss: 0.1498 - val_acc: 0.9554\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1406 - acc: 0.9594 - val_loss: 0.1455 - val_acc: 0.9560\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1354 - acc: 0.9603 - val_loss: 0.1393 - val_acc: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606a3a8da0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606a3b22e8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606a3d87b8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606a42ed30>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606a43a208>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606a43a828>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.95      0.97      0.96       982\n",
      "           5       0.94      0.95      0.94       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.96      0.93      0.94       974\n",
      "           9       0.96      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 961    0    1    2    0    7    7    1    1    0]\n",
      " [   0 1114    3    2    1    1    3    2    9    0]\n",
      " [   6    2  990    6    7    1    6    8    5    1]\n",
      " [   0    0    7  972    0   12    0    9    8    2]\n",
      " [   1    0    5    0  948    1    4    2    2   19]\n",
      " [   6    1    0   17    3  843    9    1    7    5]\n",
      " [   9    3    3    0    6   17  916    0    4    0]\n",
      " [   0    8   18    5    3    1    0  981    1   11]\n",
      " [   3    3    3   20    7    9   10    7  909    3]\n",
      " [   5    6    2   10   19    3    1    8    5  950]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 1.3433 - acc: 0.6782 - val_loss: 0.5846 - val_acc: 0.8462\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.4737 - acc: 0.8694 - val_loss: 0.3780 - val_acc: 0.8948\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.3653 - acc: 0.8959 - val_loss: 0.3219 - val_acc: 0.9078\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.3215 - acc: 0.9077 - val_loss: 0.2957 - val_acc: 0.9154\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2941 - acc: 0.9147 - val_loss: 0.2694 - val_acc: 0.9214\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2741 - acc: 0.9206 - val_loss: 0.2524 - val_acc: 0.9278\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2566 - acc: 0.9255 - val_loss: 0.2383 - val_acc: 0.9311\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2421 - acc: 0.9299 - val_loss: 0.2281 - val_acc: 0.9342\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2289 - acc: 0.9333 - val_loss: 0.2216 - val_acc: 0.9353\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2164 - acc: 0.9374 - val_loss: 0.2061 - val_acc: 0.9402\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2060 - acc: 0.9411 - val_loss: 0.1945 - val_acc: 0.9440\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1956 - acc: 0.9432 - val_loss: 0.1869 - val_acc: 0.9442\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1864 - acc: 0.9461 - val_loss: 0.1809 - val_acc: 0.9474\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1781 - acc: 0.9489 - val_loss: 0.1720 - val_acc: 0.9485\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1700 - acc: 0.9514 - val_loss: 0.1659 - val_acc: 0.9516\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1630 - acc: 0.9531 - val_loss: 0.1590 - val_acc: 0.9540\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1561 - acc: 0.9551 - val_loss: 0.1552 - val_acc: 0.9526\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1500 - acc: 0.9573 - val_loss: 0.1476 - val_acc: 0.9558\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1440 - acc: 0.9586 - val_loss: 0.1434 - val_acc: 0.9576\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1386 - acc: 0.9605 - val_loss: 0.1426 - val_acc: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606c72e630>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606c72eac8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606c72ee48>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606c7b00f0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606c7b0240>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606c799ac8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.95      0.97      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.93      0.96      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.97      0.91      0.94       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 967    0    1    1    0    4    4    1    1    1]\n",
      " [   0 1122    3    2    0    1    3    0    4    0]\n",
      " [   3    1  998    7    3    1    7    6    4    2]\n",
      " [   0    2    9  963    0   18    1    9    4    4]\n",
      " [   1    0    9    0  939    0    7    2    3   21]\n",
      " [   6    2    1    6    3  857   10    0    3    4]\n",
      " [   9    3    3    0    6   10  923    1    3    0]\n",
      " [   1    9   22    7    2    1    0  969    1   16]\n",
      " [   7    4    9   20    5   19   12    6  886    6]\n",
      " [   9    9    1   11   20   10    2    7    0  940]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 1.3949 - acc: 0.6626 - val_loss: 0.6102 - val_acc: 0.8378\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4817 - acc: 0.8701 - val_loss: 0.3844 - val_acc: 0.8911\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.3672 - acc: 0.8963 - val_loss: 0.3268 - val_acc: 0.9060\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.3238 - acc: 0.9065 - val_loss: 0.2976 - val_acc: 0.9142\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2965 - acc: 0.9140 - val_loss: 0.2753 - val_acc: 0.9214\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2758 - acc: 0.9202 - val_loss: 0.2631 - val_acc: 0.9224\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2586 - acc: 0.9251 - val_loss: 0.2430 - val_acc: 0.9303\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2434 - acc: 0.9294 - val_loss: 0.2348 - val_acc: 0.9311\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2301 - acc: 0.9336 - val_loss: 0.2217 - val_acc: 0.9369\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2182 - acc: 0.9368 - val_loss: 0.2086 - val_acc: 0.9411\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2073 - acc: 0.9399 - val_loss: 0.2014 - val_acc: 0.9414\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1975 - acc: 0.9429 - val_loss: 0.1914 - val_acc: 0.9439\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1880 - acc: 0.9459 - val_loss: 0.1823 - val_acc: 0.9480\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1794 - acc: 0.9480 - val_loss: 0.1763 - val_acc: 0.9475\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1718 - acc: 0.9503 - val_loss: 0.1667 - val_acc: 0.9515\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1644 - acc: 0.9527 - val_loss: 0.1606 - val_acc: 0.9528\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1577 - acc: 0.9548 - val_loss: 0.1570 - val_acc: 0.9555\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1512 - acc: 0.9561 - val_loss: 0.1533 - val_acc: 0.9560\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1456 - acc: 0.9582 - val_loss: 0.1461 - val_acc: 0.9569\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1399 - acc: 0.9597 - val_loss: 0.1432 - val_acc: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606b4c89b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606b4c8e48>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606b4e33c8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606b54c940>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606b54ca90>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606b53a358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.95      0.96      0.96      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.96      0.95       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    1    3    1    3    6    1    1    0]\n",
      " [   0 1116    2    2    0    1    5    2    7    0]\n",
      " [   7    1  984    5    8    1    7   10    8    1]\n",
      " [   1    1    9  970    0    7    0    8   11    3]\n",
      " [   1    0    4    0  940    0   11    2    2   22]\n",
      " [   8    2    0   12    3  840   10    0   11    6]\n",
      " [  11    3    2    0    7   10  920    1    4    0]\n",
      " [   1    8   15    4    2    1    0  975    2   20]\n",
      " [   6    1    3   14    6    5   10    4  921    4]\n",
      " [   8    6    1    7   24    3    0    5    9  946]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 142us/step - loss: 1.4888 - acc: 0.6451 - val_loss: 0.6238 - val_acc: 0.8467\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.4896 - acc: 0.8686 - val_loss: 0.3906 - val_acc: 0.8904\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.3717 - acc: 0.8953 - val_loss: 0.3308 - val_acc: 0.9043\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3254 - acc: 0.9066 - val_loss: 0.3024 - val_acc: 0.9126\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2962 - acc: 0.9151 - val_loss: 0.2739 - val_acc: 0.9198\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2740 - acc: 0.9208 - val_loss: 0.2598 - val_acc: 0.9246\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2557 - acc: 0.9268 - val_loss: 0.2414 - val_acc: 0.9302\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2397 - acc: 0.9307 - val_loss: 0.2270 - val_acc: 0.9349\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2255 - acc: 0.9346 - val_loss: 0.2146 - val_acc: 0.9375\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2132 - acc: 0.9387 - val_loss: 0.2033 - val_acc: 0.9405\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2014 - acc: 0.9422 - val_loss: 0.1943 - val_acc: 0.9436\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1910 - acc: 0.9448 - val_loss: 0.1842 - val_acc: 0.9460\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1817 - acc: 0.9477 - val_loss: 0.1783 - val_acc: 0.9481\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1734 - acc: 0.9503 - val_loss: 0.1687 - val_acc: 0.9491\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1656 - acc: 0.9523 - val_loss: 0.1629 - val_acc: 0.9530\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1584 - acc: 0.9547 - val_loss: 0.1587 - val_acc: 0.9545\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1519 - acc: 0.9567 - val_loss: 0.1519 - val_acc: 0.9547\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1458 - acc: 0.9577 - val_loss: 0.1494 - val_acc: 0.9559\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1400 - acc: 0.9601 - val_loss: 0.1432 - val_acc: 0.9576\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1351 - acc: 0.9615 - val_loss: 0.1369 - val_acc: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606d16f240>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606d16f6d8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606d16fc50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606d1f21d0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606d1f2320>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606d1d9ba8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.98      0.95      0.96      1032\n",
      "           3       0.94      0.97      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.95      0.94      0.95       974\n",
      "           9       0.95      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 961    0    0    2    0    5    5    4    2    1]\n",
      " [   0 1118    2    3    0    1    4    2    5    0]\n",
      " [   8    2  977   14    3    0    9    9    9    1]\n",
      " [   0    0    3  979    1    6    0    8   11    2]\n",
      " [   1    0    3    0  942    1   11    3    2   19]\n",
      " [   6    1    0   13    1  850    8    1    8    4]\n",
      " [   3    3    1    0    7   13  925    1    5    0]\n",
      " [   1   10   13    8    1    3    0  978    0   14]\n",
      " [   4    1    1   14    8    7   10    8  917    4]\n",
      " [   5    5    1   14   16    3    1    8    4  952]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ########################## FINISHED ##########################\n",
      "\n",
      " Total execution time 3712.6284423172474\n"
     ]
    }
   ],
   "source": [
    "#global variables\n",
    "plots_folder = Path(\"plots/\")\n",
    "models_folder = Path(\"models/\")\n",
    "times_dict = {\"Compilation time\": [], \"Training time\": []}\n",
    "total_history = []\n",
    "text_file = \"score file.txt\"\n",
    "train_scores = []\n",
    "evaluation_scores = []\n",
    "\n",
    "#neural net architecture config\n",
    "n_hlayers = 0\n",
    "n_neurons = 401\n",
    "initial_neurons = 128\n",
    "neurons_step = 10\n",
    "n_epochs= 20\n",
    "n_batch_size= 128\n",
    "    \n",
    "text_file =  model_name + \"_\" + text_file\n",
    "\n",
    "start_time = time.clock()\n",
    "print(\"Using keras version %s\" % keras.__version__)\n",
    "\n",
    "#Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # loading of MNIST dataset\n",
    "\n",
    "#check sizes\n",
    "print(\"\\n\")\n",
    "print(\"Number of training examples: '{0}'\".format(x_train.shape[0]))\n",
    "print(\"Size of train samples: '{0}'\".format(x_train.shape[1:]))\n",
    "print(\"Size of test samples: '{0}'\".format(x_test.shape[1:]))\n",
    "\n",
    "#Data to 1D and normalization\n",
    "x_train = x_train.reshape(60000, 784) #60000 observations of 784 features\n",
    "x_test = x_test.reshape(10000, 784) # 10000 observations of 784 features\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Adapts labels to one hot encoding vector for softmax classifier\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "#Neural network architecture\n",
    "if n_neurons==0:\n",
    "    neurons=64\n",
    "    model_name = \"fnn_fixed_neurons\"\n",
    "    text_file = model_name + \"_\" + text_file\n",
    "    for layers in range(n_hlayers):\n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(initial_neurons, activation='relu', input_shape=(784,)))\n",
    "        for i in range(layers):\n",
    "            nn.add(Dense(neurons, activation = 'relu'))\n",
    "        nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        #Model visualization\n",
    "        #The plot of the model needs pydot, graphviz and pydot-ng\n",
    "        #plot_model(nn, to_file='nn.png', show_shapes = True)\n",
    "\n",
    "        #Compile the model\n",
    "        time_compiling = time.clock()\n",
    "        nn.compile(optimizer = 'sgd', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "        print(\"Compiling the network time {0} with layers equal to {1}\".format(time.clock() - time_compiling, layers + 1))\n",
    "        times_dict[\"Compilation time\"].append(time.clock() - time_compiling)\n",
    "        time_training = time.clock()\n",
    "        #train the model\n",
    "        history = nn.fit(x_train, y_train, batch_size = n_batch_size, epochs=n_epochs, validation_data=(x_test,y_test))\n",
    "        print(\"Training time {0} with layers equal to {1}\".format(time.clock() - time_training, layers + 1))\n",
    "        times_dict[\"Training time\"].append(time.clock() - time_training)\n",
    "        train_scores.append((history.history[\"acc\"][-1], history.history[\"loss\"][-1]))\n",
    "\n",
    "        #Evaluate the model\n",
    "        score = nn.evaluate(x_test, y_test, verbose=0) #returns loss and metrics (accuracy)\n",
    "        evaluation_scores.append(score)\n",
    "\n",
    "        with open('{}'.format(text_file), 'a') as f:\n",
    "            f.write(\"Scores for neural network with {} layers: \\n\".format(layers + 1))\n",
    "            f.write(\"Loss {}\".format(score[0]))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"Accuracy {}\".format(score[1]))\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "        #Store plots\n",
    "        # Accuracy plot\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plot_name = \"model_accuracy_with_{}_layers_and_{}_neurons.pdf\".format(layers+1, neurons)\n",
    "        plt.savefig(plots_folder / plot_name)\n",
    "        plt.close()\n",
    "        # Loss plot\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plot_name = 'model_loss_with_{}_layers_{}_neurons.pdf'.format(layers + 1, neurons)\n",
    "        plt.savefig(plots_folder / plot_name)\n",
    "        plt.close()\n",
    "\n",
    "        total_history.append(history)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        # Compute probabilities\n",
    "        Y_pred = nn.predict(x_test)\n",
    "        # Assign most probable label\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "        # Plot statistics\n",
    "        print('Analysis of results')\n",
    "        target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "        print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "else:\n",
    "    layers = 2\n",
    "    model_name = \"fnn_fixed_layers\"\n",
    "    text_file = model_name + \"_\" + text_file\n",
    "    for neurons in range(2, n_neurons, neurons_step):\n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(initial_neurons, activation='relu', input_shape=(784,)))\n",
    "        for i in range(layers):\n",
    "            nn.add(Dense(neurons, activation = 'relu'))\n",
    "        nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        #Model visualization\n",
    "        #The plot of the model needs pydot, graphviz and pydot-ng\n",
    "        #plot_model(nn, to_file='nn.png', show_shapes = True)\n",
    "\n",
    "        #Compile the model\n",
    "        time_compiling = time.clock()\n",
    "        nn.compile(optimizer = 'sgd', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "        times_dict[\"Compilation time\"].append(time.clock() - time_compiling)\n",
    "        time_training = time.clock()\n",
    "        #train the model\n",
    "        history = nn.fit(x_train, y_train, batch_size = n_batch_size, epochs=n_epochs, validation_data=(x_test,y_test))\n",
    "        times_dict[\"Training time\"].append(time.clock() - time_training)\n",
    "        train_scores.append((history.history[\"acc\"][-1], history.history[\"loss\"][-1]))\n",
    "\n",
    "        #Evaluate the model\n",
    "        score = nn.evaluate(x_test, y_test, verbose=0) #returns loss and metrics (accuracy)\n",
    "        evaluation_scores.append(score)\n",
    "\n",
    "        with open('{}'.format(text_file), 'a') as f:\n",
    "            f.write(\"Scores for neural network with {} layers: \\n\".format(layers + 1))\n",
    "            f.write(\"Loss {}\".format(score[0]))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"Accuracy {}\".format(score[1]))\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "        #Store plots\n",
    "        # Accuracy plot\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plot_name = \"model_accuracy_with_{}_layers_and_{}_neurons.pdf\".format(layers+1, neurons)\n",
    "        plt.savefig(plots_folder / plot_name)\n",
    "        plt.close()\n",
    "        # Loss plot\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plot_name = 'model_loss_with_{}_layers_{}_neurons.pdf'.format(layers + 1, neurons)\n",
    "        plt.savefig(plots_folder / plot_name)\n",
    "        plt.close()\n",
    "\n",
    "        total_history.append(history)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        # Compute probabilities\n",
    "        Y_pred = nn.predict(x_test)\n",
    "        # Assign most probable label\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "        # Plot statistics\n",
    "        print('Analysis of results')\n",
    "        target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "        print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "#Execution time\n",
    "print(\"\\n\\n\\n\\n ########################## FINISHED ##########################\")\n",
    "print(\"\\n Total execution time {}\".format(time.clock()-start_time))\n",
    "\n",
    "# Ejemplo Confunde el 0 con el 6 (7 errores), el 9 con el 4 (20 errores) y el 3 con el 8 (21 errores).\n",
    "#La NN tiene un 96% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068cc57f0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068cc5da0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068ceb198>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068cebc88>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068ceb4a8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068ca8e80>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068ca8a20>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068ca8710>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068ca8160>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068cb7048>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068cf4e80>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c65240>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c65e48>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c65278>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c65860>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c31390>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c31780>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c31da0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068bf8ef0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c58390>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c580b8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c586d8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c6aef0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c6aa90>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c6a0f0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c6a7f0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c45d68>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c45d30>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c452b0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c45320>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c0ed68>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c0eef0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16068c0e978>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160676adc50>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160676ad8d0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160676ad4a8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606768ecf8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606768e4a8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606768e668>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606768e2b0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067697748>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067697080>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067684be0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067684320>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067684550>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067684400>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067675e80>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067675128>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16067843fd0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1606761a710>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1606761ac88>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy by number of neurons')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAMjCAYAAABK+QySAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend = []\n",
    "if n_neurons == 0:\n",
    "    for i in range(n_hlayers):\n",
    "        plt.plot(total_history[i].history['acc'])\n",
    "        legend.append('{} layers'.format(i+1))\n",
    "    plt.legend(legend, loc='lower right')\n",
    "    plt.title('model accuracy by layers')\n",
    "else:\n",
    "    for i in range(len(range(2, n_neurons, neurons_step))):\n",
    "        plt.plot(total_history[i].history['acc'])\n",
    "        legend.append('{} neurons'.format((i+1)*neurons_step))\n",
    "    plt.legend(legend, loc='lower right')\n",
    "    plt.title('model accuracy by number of neurons')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plot_name = \"model_accuracy_by_{}\".format(model_name)\n",
    "#plt.savefig(plots_folder / plot_name)    \n",
    "plt.figure(figsize=(18, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604538c780>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16045110208>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy by fnn_fixed_layers')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'layers')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgoiIlLt/wf1mDRt8O1XvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs = []\n",
    "if n_neurons == 0:\n",
    "    for i in range(n_hlayers):\n",
    "        accs.append(total_history[i].history['acc'][-1])\n",
    "else:\n",
    "    for i in range(len(range(2, n_neurons, neurons_step))):\n",
    "        accs.append(total_history[i].history['acc'][-1])\n",
    "plt.plot(accs)\n",
    "plt.legend([\"accuracy\"], loc='lower right')\n",
    "plt.title('model accuracy by {}'.format(model_name))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('layers')\n",
    "plot_name = \"model_accuracy_by_{}_end_train\".format(model_name)\n",
    "# plt.savefig(plots_folder / plot_name)\n",
    "plt.figure(figsize=(18, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**What is the impact of using more fully connected layers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original code will be rewrited in order to control the number of hidden layers via a global variables called *n_layers* and we will iterate adding that number of hidden layers and comparing the results for *Execution time*, *Accuracy* and *Overfit*.\n",
    "\n",
    "**Observations**\n",
    "1. **Loss / Accuracy**: As we increment the number of layers, usually the first epoch have more loss than the neural network with one less hidden layer but in the following epochs, this loss reduces greatly achieving better accuracy as more hidden layers are in the neural network.\n",
    "2. **Execution time**: It can be seen that compiling time for each new architecture with more layers increases a little. The important one, training time, increases notably as we increment the number of layers. See the table.\n",
    "\n",
    "3. **Overfitting**: An increment on the number of layers is translated to an overfit of the model to the train data in early epochs, meaning that as epochs go, more overfitted is the model.\n",
    "4. It can be seen that the model accuracy increases as more layers are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Compilation time  Training time\n",
      "0           0.096816      47.962571\n",
      "1           0.046975      48.235103\n",
      "2           0.042444      48.411325\n",
      "3           0.042291      53.318072\n",
      "4           0.042862      55.063720\n",
      "5           0.047598      53.644906\n",
      "6           0.042339      53.117295\n",
      "7           0.044225      55.598140\n",
      "8           0.045431      55.785045\n",
      "9           0.046777      55.671752\n",
      "10          0.045471      56.889878\n",
      "11          0.043127      58.835386\n",
      "12          0.042396      55.970629\n",
      "13          0.053397      55.750248\n",
      "14          0.042777      55.446095\n",
      "15          0.045554      55.505354\n",
      "16          0.042679      61.191555\n",
      "17          0.097888      57.406310\n",
      "18          0.043692      70.076035\n",
      "19          0.043320      66.213153\n",
      "20          0.043814      70.696612\n",
      "21          0.073000      69.192440\n",
      "22          0.042162      71.173200\n",
      "23          0.042000      63.222998\n",
      "24          0.042118      67.784642\n",
      "25          0.043888      73.656941\n",
      "26          0.066471      73.587211\n",
      "27          0.042627      74.606259\n",
      "28          0.042328      70.932465\n",
      "29          0.043311      69.862133\n",
      "30          0.046464      73.544751\n",
      "31          0.042889      70.716104\n",
      "32          0.044438      71.149578\n",
      "33          0.042844      73.512042\n",
      "34          0.044342      73.733184\n",
      "35          0.044381      76.991187\n",
      "36          0.042379      77.111312\n",
      "37          0.043121      83.731247\n",
      "38          0.042209      85.709452\n",
      "39          0.067785      87.986229\n",
      "40          0.042425      87.045797\n",
      "41          0.049715      89.807392\n",
      "42          0.042265      93.908049\n",
      "43          0.045472      88.775121\n",
      "44          0.051291     105.426029\n",
      "45          0.043158     100.196789\n",
      "46          0.043695      98.148595\n",
      "47          0.043361      99.426774\n",
      "48          0.046468     102.755237\n",
      "49          0.043464     100.446728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1605ca46160>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7v8Dhzhne0E9K7IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compilation_time = [0.24594317327546378, 0.043510568686087936, 0.04459838010097883, 0.045250085238876636, 0.056358901495514147, 0.052324446456623264, 0.053702240227266884, 0.05874068365619678, 0.05362408092014448, 0.05278094211780626] \n",
    "# train_time = [39.99011794503713, 43.14482466451, 47.26708281148467, 49.6701730114778, 51.091938377238876, 51.03244404152338, 52.43567205865202, 55.833798198711065, 59.904547097023624, 61.02969902625591]\n",
    "\n",
    "times_df = pd.DataFrame(times_dict)\n",
    "print(times_df)\n",
    "times_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the impact of increasing the number of neurons per layer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From increasing the number of neurons we can draw conclusions similar to the increase of the number of layers:\n",
    "1. An increase in the overall of the training time.\n",
    "2. As more neurons are used, higher is the accuracy.\n",
    "3. Using more neurons seems to be **harder** to get overfitting issues compared to when increasing the number of layers, that makes the overfitting to happen earlier (in epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the best performance you can get out of a basic neural net?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because FNN can get good scores with the MNIST dataset, we will use the CIFAR10 dataset and try to achieve a good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using keras version 2.2.2\n",
      "\n",
      "\n",
      "Number of training examples: '50000'\n",
      "Number of test examples: '10000'\n",
      "Size of train samples: '(32, 32, 3)'\n",
      "--Call--\n",
      "> \u001b[1;32mc:\\users\\worldsensing\\anaconda3\\lib\\site-packages\\ipython\\core\\displayhook.py\u001b[0m(247)\u001b[0;36m__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    246 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 247 \u001b[1;33m    \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    248 \u001b[1;33m        \"\"\"Printing with history cache management.\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 14s 275us/step - loss: 2.0359 - acc: 0.2152\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.8486 - acc: 0.3041\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.7761 - acc: 0.3476\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 1.7090 - acc: 0.3744\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 1.6575 - acc: 0.3985\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 1.6155 - acc: 0.4155\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.5756 - acc: 0.4324\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.5504 - acc: 0.4416\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 1.5185 - acc: 0.4547\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.4821 - acc: 0.4691\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 1.4669 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.4472 - acc: 0.4791\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.4189 - acc: 0.4932\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.4049 - acc: 0.4935\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 1.3818 - acc: 0.5049\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3680 - acc: 0.5088\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.3445 - acc: 0.5189\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.3351 - acc: 0.5223\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3174 - acc: 0.5262\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.3003 - acc: 0.53470s - loss: 1.2997 - acc:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22e15bc0208>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22e15bc07f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22e159e0710>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22e159e0860>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.59      0.54      1000\n",
      "           1       0.61      0.58      0.60      1000\n",
      "           2       0.39      0.21      0.27      1000\n",
      "           3       0.32      0.22      0.26      1000\n",
      "           4       0.42      0.43      0.42      1000\n",
      "           5       0.43      0.40      0.42      1000\n",
      "           6       0.46      0.62      0.53      1000\n",
      "           7       0.48      0.61      0.54      1000\n",
      "           8       0.56      0.68      0.62      1000\n",
      "           9       0.61      0.52      0.56      1000\n",
      "\n",
      "   micro avg       0.49      0.49      0.49     10000\n",
      "   macro avg       0.48      0.49      0.48     10000\n",
      "weighted avg       0.48      0.49      0.48     10000\n",
      "\n",
      "[[589  27  39  22  31  10  31  51 162  38]\n",
      " [ 79 582   7  37  17   7  23  34  89 125]\n",
      " [108  23 212  67 196  94 140 110  40  10]\n",
      " [ 44  25  66 221  49 240 183  86  50  36]\n",
      " [ 65  13  89  38 430  43 147 132  33  10]\n",
      " [ 33  15  56 152  53 404 107 118  50  12]\n",
      " [  5  15  37  44 147  61 616  42  19  14]\n",
      " [ 72  22  29  48  78  53  31 610  20  37]\n",
      " [110  53   4  26  20  14  17  19 680  57]\n",
      " [ 65 181   6  44   8  12  31  69  64 520]]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models\\\\fnn_cifar.json'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-cb214e88005f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[0mnn_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[0mjson_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{0}.json'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_folder\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mjson_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mweights_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"weights-{0}_\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".hdf5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models\\\\fnn_cifar.json'"
     ],
     "output_type": "error"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4P8DciHopTweeCQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NN architecture\n",
    "# n_hlayers = 10\n",
    "# n_neurons = 401\n",
    "\n",
    "initial_neurons = 128\n",
    "neurons = 200\n",
    "layers = 10\n",
    "neurons_step = 8\n",
    "n_epochs= 40\n",
    "n_batch_size= 128\n",
    "\n",
    "\n",
    "#global variables\n",
    "plots_folder = Path(\"plots/\")\n",
    "models_folder = Path(\"models/\")\n",
    "dataset_name = \"cifar\"\n",
    "model_name = 'fnn_{}'.format(dataset_name)\n",
    "cifar_nn_times_dict = {\"Compilation time\": [], \"Training time\": []}\n",
    "cifar_fnn_total_history = []\n",
    "text_file = \"CIFAR-FNN score file.txt\"\n",
    "cifar_fnn_train_scores = []\n",
    "cifar_fnn_evaluation_scores = []\n",
    "start_time = time.clock()\n",
    "print(\"Using keras version {0}\".format(keras.__version__))\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # loading of CIFAR10 dataset\n",
    "\n",
    "# check sizes\n",
    "print(\"\\n\")\n",
    "print(\"Number of training examples: '{0}'\".format(x_train.shape[0]))\n",
    "print(\"Number of test examples: '{0}'\".format(x_test.shape[0]))\n",
    "print(\"Size of train samples: '{0}'\".format(x_train.shape[1:]))\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape(50000,np.prod(x_train.shape[1:]))\n",
    "x_test = x_test.reshape(10000, np.prod(x_train.shape[1:]))\n",
    "bp()\n",
    "\n",
    "# Adapts labels to one hot encoding vector for softmax classifier\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Neural network architecture\n",
    "nn = Sequential()\n",
    "nn.add(Dense(initial_neurons, activation='relu', input_shape=x_train.shape[1:]))\n",
    "for i in range(layers):\n",
    "    nn.add(Dense(neurons, activation = 'relu'))\n",
    "nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn.fit(x_train, y_train, batch_size=128, epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Store plots\n",
    "# Accuracy plot\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plot_name = 'model_accuracy_{0}.pdf'.format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "plt.close()\n",
    "# Loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plot_name = 'model_loss_{0}.pdf'.format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "\n",
    "# Confusion Matrix\n",
    "# Compute probabilities\n",
    "Y_pred = nn.predict(test_input_shape)\n",
    "# Assign most probable label\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "# Plot statistics\n",
    "print('Analysis of results')\n",
    "target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "# Saving model and weights\n",
    "nn_json = nn.to_json()\n",
    "json_file_name = '{0}.json'.format(model_name)\n",
    "with open(models_folder / json_file_name, 'w') as json_file:\n",
    "    json_file.write(nn_json)\n",
    "weights_file_name = \"weights-{0}_\".format(model_name) + str(score[1]) + \".hdf5\"\n",
    "weights_file = models_folder / weights_file_name\n",
    "nn.save_weights(weights_file, overwrite=True)\n",
    "\n",
    "# Loading model and weights\n",
    "json_file = open(models_folder / json_file_name, 'r')\n",
    "nn_json = json_file.read()\n",
    "json_file.close()\n",
    "nn = model_from_json(nn_json)\n",
    "nn.load_weights(weights_file)\n",
    "\n",
    "#measuring execution time\n",
    "print(\"Total execution time {} seconds\".format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CNN part the CIFAR10 dataset will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-b0e48495b435>\", line 24, in <module>\n",
      "    get_ipython().magic('matplotlib inline')\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2146, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2067, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-108>\", line 2, in matplotlib\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2930, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 307, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import ipdb\n",
    "from ipdb import set_trace as bp\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import plot_model\n",
    "from keras.models import model_from_json #to load a model from a json file.\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(12345678)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global variables\n",
    "plots_folder = Path(\"plots/\")\n",
    "models_folder = Path(\"models/\")\n",
    "times_dict = {\"Compilation time\": [], \"Training time\": []}\n",
    "total_history = []\n",
    "text_file = \"CNN score file.txt\"\n",
    "train_scores = []\n",
    "evaluation_scores = []\n",
    "\n",
    "#neural net architecture config\n",
    "n_hlayers = 0\n",
    "n_neurons = 10\n",
    "initial_neurons = 128\n",
    "neurons_step = 2\n",
    "n_epochs= 20\n",
    "n_batch_size= 128\n",
    "    \n",
    "text_file =  model_name + \"_\" + text_file\n",
    "\n",
    "start_time = time.clock()\n",
    "print(\"Using keras version %s\" % keras.__version__)\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # loading of MNIST dataset\n",
    "\n",
    "# check sizes\n",
    "print(\"\\n\")\n",
    "print(\"Number of training examples: '{0}'\".format(x_train.shape[0]))\n",
    "print(\"Number of test examples: '{0}'\".format(x_test.shape[0]))\n",
    "print(\"Size of train samples: '{0}'\".format(x_train.shape[1:]))\n",
    "\n",
    "# Data to 1D and normalization\n",
    "#x_train = x_train.reshape(60000, 784)  # 60000 observations of 784 features\n",
    "#x_test = x_test.reshape(10000, 784)  # 10000 observations of 784 features\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "train_input_shape = x_train.reshape(*x_train.shape)\n",
    "test_input_shape = x_test.reshape(*x_test.shape)\n",
    "\n",
    "# Adapts labels to one hot encoding vector for softmax classifier\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Neural network architecture\n",
    "# CNN\n",
    "nn = Sequential()\n",
    "nn.add(Conv2D(32, kernel_size=(3,3), activation = 'relu', input_shape=x_train.shape[1:]))\n",
    "nn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "nn.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "nn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(128, activation='relu'))\n",
    "nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Model visualization\n",
    "# The plot of the model needs pydot, graphviz and pydot-ng\n",
    "#plot_model(nn, to_file='nn.png', show_shapes=True)\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn.fit(train_input_shape, y_train, batch_size=128, epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "score = nn.evaluate(test_input_shape, y_test, verbose=0)\n",
    "\n",
    "# Store plots\n",
    "# Accuracy plot\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plot_name = 'model_accuracy_{0}.pdf'.format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "plt.close()\n",
    "# Loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plot_name = 'model_loss_{0}.pdf'.format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "\n",
    "# Confusion Matrix\n",
    "# Compute probabilities\n",
    "Y_pred = nn.predict(test_input_shape)\n",
    "# Assign most probable label\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "# Plot statistics\n",
    "print('Analysis of results')\n",
    "target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "# Saving model and weights\n",
    "nn_json = nn.to_json()\n",
    "json_file_name = '{0}.json'.format(model_name)\n",
    "with open(models_folder / json_file_name, 'w') as json_file:\n",
    "    json_file.write(nn_json)\n",
    "weights_file_name = \"weights-{0}_\".format(model_name) + str(score[1]) + \".hdf5\"\n",
    "weights_file = models_folder / weights_file_name\n",
    "nn.save_weights(weights_file, overwrite=True)\n",
    "\n",
    "# Loading model and weights\n",
    "json_file = open(models_folder / json_file_name, 'r')\n",
    "nn_json = json_file.read()\n",
    "json_file.close()\n",
    "nn = model_from_json(nn_json)\n",
    "nn.load_weights(weights_file)\n",
    "\n",
    "#measuring execution time\n",
    "print(\"Total execution time {} seconds\".format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "1. **Can you design and train a model that overfits on the training data (or on a subset of it)?**\n",
    "2. **When overfitting, what is the result of applying various regularization techniques?**\n",
    "3. **When using ReLUs, how many neurons are dead after a training?**\n",
    "4. **Adding data augmentation improves performance?**\n",
    "5. **How do the different learning algorithms behave for equal architectures? Does regularization have the same affect when using different algorithms?**\n",
    "6. **How hard is it to match the performance of an adaptative algorithm (e.g., Adam) by using an algorithm where parameters have to be hand tunned (e.g., SGD)?**\n",
    "7. **What is the result of using different weight initializations in the training process?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self normalizing activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House numbers, mnist and transer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function visualization"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
