{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# MAI - Deep Learning: Autonomous Lab 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Jamie Arjona Mart√≠nez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from pathlib import Path\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import ipdb\n",
    "from ipdb import set_trace as bp\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import plot_model\n",
    "from keras.models import model_from_json #to load a model from a json file.\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "np.random.seed(12345678)\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Feedforward NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using keras version 2.2.2\n",
      "\n",
      "\n",
      "Number of training examples: '60000'\n",
      "Size of train samples: '(28, 28)'\n",
      "Size of test samples: '(28, 28)'\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 2.1724 - acc: 0.1811 - val_loss: 2.0583 - val_acc: 0.2110\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 2.0262 - acc: 0.2128 - val_loss: 1.9842 - val_acc: 0.2207\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.9698 - acc: 0.2256 - val_loss: 1.9387 - val_acc: 0.2398\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 1.9258 - acc: 0.2452 - val_loss: 1.8962 - val_acc: 0.2583\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 1.8758 - acc: 0.2703 - val_loss: 1.8405 - val_acc: 0.2701\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 1.8141 - acc: 0.2836 - val_loss: 1.7825 - val_acc: 0.2864\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.7563 - acc: 0.3047 - val_loss: 1.7259 - val_acc: 0.3294\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.6965 - acc: 0.3328 - val_loss: 1.6630 - val_acc: 0.3528\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 1.6312 - acc: 0.3588 - val_loss: 1.5974 - val_acc: 0.3746\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.5648 - acc: 0.3837 - val_loss: 1.5305 - val_acc: 0.3988\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 1.4995 - acc: 0.3990 - val_loss: 1.4654 - val_acc: 0.4158\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.4365 - acc: 0.4178 - val_loss: 1.4070 - val_acc: 0.4378\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.3820 - acc: 0.4421 - val_loss: 1.3586 - val_acc: 0.4587\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.3375 - acc: 0.4647 - val_loss: 1.3206 - val_acc: 0.4814\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.2999 - acc: 0.4902 - val_loss: 1.2872 - val_acc: 0.5001\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.2668 - acc: 0.5140 - val_loss: 1.2577 - val_acc: 0.5332\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 1.2340 - acc: 0.5375 - val_loss: 1.2247 - val_acc: 0.5408\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 1.2007 - acc: 0.5526 - val_loss: 1.1897 - val_acc: 0.5454\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.1648 - acc: 0.5570 - val_loss: 1.1543 - val_acc: 0.5633\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 1.1239 - acc: 0.5517 - val_loss: 1.0998 - val_acc: 0.5603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29151433630>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29151433588>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29151412a20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2914e2277f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2914e2278d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2914e23c2b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.28      0.96      0.43      1135\n",
      "           2       0.03      0.00      0.00      1032\n",
      "           3       0.51      0.50      0.50      1010\n",
      "           4       0.89      0.95      0.92       982\n",
      "           5       0.61      0.79      0.69       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.92      0.87      0.89      1028\n",
      "           8       0.65      0.60      0.62       974\n",
      "           9       0.90      0.89      0.90      1009\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     10000\n",
      "   macro avg       0.48      0.56      0.50     10000\n",
      "weighted avg       0.48      0.56      0.49     10000\n",
      "\n",
      "[[   0  947    2    2    1    1    0    1   26    0]\n",
      " [   0 1088   17    0   17    0    0    0   13    0]\n",
      " [   0  892    1    6   25    3    0    2  100    3]\n",
      " [   0    3    2  500    0  404    0   25   70    6]\n",
      " [   0   16    2    0  932    0    0    0    1   31]\n",
      " [   0    9    0  126    0  703    0   18   33    3]\n",
      " [   0  908    0    1    8    0    0    0   41    0]\n",
      " [   0    4    3   28    6   20    0  895   23   49]\n",
      " [   0   50   12  296    8    9    0   11  581    7]\n",
      " [   0    6    1   18   45    5    0   22    9  903]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 1.7603 - acc: 0.3936 - val_loss: 1.1236 - val_acc: 0.6975\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7249 - acc: 0.8177 - val_loss: 0.4753 - val_acc: 0.8708\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.4329 - acc: 0.8802 - val_loss: 0.3716 - val_acc: 0.8952\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3599 - acc: 0.8972 - val_loss: 0.3250 - val_acc: 0.9073\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3208 - acc: 0.9082 - val_loss: 0.2980 - val_acc: 0.9125\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2940 - acc: 0.9158 - val_loss: 0.2778 - val_acc: 0.9175\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2718 - acc: 0.9220 - val_loss: 0.2567 - val_acc: 0.9255\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2536 - acc: 0.9273 - val_loss: 0.2426 - val_acc: 0.9282\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2376 - acc: 0.9320 - val_loss: 0.2291 - val_acc: 0.9310\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2234 - acc: 0.9357 - val_loss: 0.2147 - val_acc: 0.9388\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.2111 - acc: 0.9398 - val_loss: 0.2043 - val_acc: 0.9396\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1998 - acc: 0.9428 - val_loss: 0.1965 - val_acc: 0.9434\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1896 - acc: 0.9462 - val_loss: 0.1853 - val_acc: 0.9469\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1799 - acc: 0.9486 - val_loss: 0.1802 - val_acc: 0.9470\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1713 - acc: 0.9512 - val_loss: 0.1702 - val_acc: 0.9506\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1639 - acc: 0.9528 - val_loss: 0.1664 - val_acc: 0.9524\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1563 - acc: 0.9548 - val_loss: 0.1568 - val_acc: 0.9531\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1500 - acc: 0.9565 - val_loss: 0.1537 - val_acc: 0.9535\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1430 - acc: 0.9593 - val_loss: 0.1473 - val_acc: 0.9555\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1379 - acc: 0.9605 - val_loss: 0.1468 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2915a4aa5c0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2915a4aaef0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2914c59dcc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291000add30>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291000af2b0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29100081748>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.95      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.95      0.94      0.94       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 969    0    0    2    0    3    3    2    1    0]\n",
      " [   0 1113    3    2    0    2    3    2   10    0]\n",
      " [  10    2  981   10    3    1    9    6    9    1]\n",
      " [   0    0   12  960    0   15    0   10   12    1]\n",
      " [   1    1    4    0  944    0   10    2    2   18]\n",
      " [  10    0    0   11    1  846   11    1    8    4]\n",
      " [   6    3    2    0    9    7  929    0    2    0]\n",
      " [   2    9   19    9    2    0    0  968    0   19]\n",
      " [   6    2    4   12    4    9    8    3  917    9]\n",
      " [  10    8    2    7   22    4    1   10    7  938]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.4554 - acc: 0.5713 - val_loss: 0.6833 - val_acc: 0.8272\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.5361 - acc: 0.8559 - val_loss: 0.4224 - val_acc: 0.8832\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3953 - acc: 0.8899 - val_loss: 0.3471 - val_acc: 0.8996\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3381 - acc: 0.9039 - val_loss: 0.3082 - val_acc: 0.9098\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3019 - acc: 0.9137 - val_loss: 0.2790 - val_acc: 0.9196\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2748 - acc: 0.9217 - val_loss: 0.2593 - val_acc: 0.9232\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2535 - acc: 0.9270 - val_loss: 0.2427 - val_acc: 0.9277\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2361 - acc: 0.9318 - val_loss: 0.2297 - val_acc: 0.9323\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2207 - acc: 0.9364 - val_loss: 0.2161 - val_acc: 0.9350\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2077 - acc: 0.9413 - val_loss: 0.2008 - val_acc: 0.9410\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1963 - acc: 0.9436 - val_loss: 0.1928 - val_acc: 0.9422\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.1862 - acc: 0.9462 - val_loss: 0.1855 - val_acc: 0.9442\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1774 - acc: 0.9496 - val_loss: 0.1798 - val_acc: 0.9455\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1688 - acc: 0.9520 - val_loss: 0.1714 - val_acc: 0.9477\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1619 - acc: 0.9534 - val_loss: 0.1653 - val_acc: 0.9508\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1547 - acc: 0.9557 - val_loss: 0.1609 - val_acc: 0.9511\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1486 - acc: 0.9579 - val_loss: 0.1540 - val_acc: 0.9533\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1430 - acc: 0.9587 - val_loss: 0.1507 - val_acc: 0.9550\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1377 - acc: 0.9606 - val_loss: 0.1473 - val_acc: 0.9551\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1327 - acc: 0.9622 - val_loss: 0.1462 - val_acc: 0.9543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910032ebe0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29100331128>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910030a5f8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101334080>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291013341d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29101334be0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.97      0.96      0.96      1032\n",
      "           3       0.95      0.94      0.95      1010\n",
      "           4       0.94      0.96      0.95       982\n",
      "           5       0.94      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.96      0.92      0.94       974\n",
      "           9       0.93      0.93      0.93      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[[ 959    0    0    3    1    4    6    4    1    2]\n",
      " [   0 1124    3    0    0    1    2    1    4    0]\n",
      " [   8    2  986    9    5    1    8    7    6    0]\n",
      " [   0    4    6  950    1   19    1   10   13    6]\n",
      " [   1    0    1    1  941    0   11    3    2   22]\n",
      " [   9    2    0    9    3  849    8    2    4    6]\n",
      " [   6    3    4    1    7    9  926    0    1    1]\n",
      " [   0   11   15    4    2    0    0  970    2   24]\n",
      " [   6    4    3   11    9   12   13   11  898    7]\n",
      " [  10    8    1    8   29    5    0    7    1  940]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.3897 - acc: 0.6179 - val_loss: 0.6828 - val_acc: 0.8256\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.5509 - acc: 0.8489 - val_loss: 0.4392 - val_acc: 0.8790\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4118 - acc: 0.8827 - val_loss: 0.3641 - val_acc: 0.8979\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3509 - acc: 0.8995 - val_loss: 0.3161 - val_acc: 0.9104\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3128 - acc: 0.9101 - val_loss: 0.2877 - val_acc: 0.9177\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2855 - acc: 0.9184 - val_loss: 0.2631 - val_acc: 0.9250\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2633 - acc: 0.9252 - val_loss: 0.2460 - val_acc: 0.9308\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2449 - acc: 0.9302 - val_loss: 0.2308 - val_acc: 0.9333\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2298 - acc: 0.9347 - val_loss: 0.2215 - val_acc: 0.9363\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2166 - acc: 0.9389 - val_loss: 0.2130 - val_acc: 0.9384\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2050 - acc: 0.9418 - val_loss: 0.2022 - val_acc: 0.9426\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1943 - acc: 0.9454 - val_loss: 0.1946 - val_acc: 0.9437\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1851 - acc: 0.9472 - val_loss: 0.1863 - val_acc: 0.9455\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1768 - acc: 0.9503 - val_loss: 0.1781 - val_acc: 0.9486\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1689 - acc: 0.9523 - val_loss: 0.1709 - val_acc: 0.9506\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1619 - acc: 0.9538 - val_loss: 0.1701 - val_acc: 0.9525\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1552 - acc: 0.9570 - val_loss: 0.1635 - val_acc: 0.9516\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1495 - acc: 0.9573 - val_loss: 0.1598 - val_acc: 0.9537\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1438 - acc: 0.9590 - val_loss: 0.1542 - val_acc: 0.9561\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1387 - acc: 0.9605 - val_loss: 0.1488 - val_acc: 0.9568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101611780>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101603ef0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910162e278>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101682828>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101682978>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29101665320>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    1    2    0    4    4    2    1    2]\n",
      " [   0 1114    3    2    0    0    3    1   12    0]\n",
      " [   5    2  982    9    9    2    4    8   10    1]\n",
      " [   1    1    8  961    0   16    0   12    7    4]\n",
      " [   1    0    3    2  939    0    9    2    2   24]\n",
      " [   8    3    1   10    2  847   10    0    6    5]\n",
      " [   9    3    1    0    8   13  917    0    7    0]\n",
      " [   0    9   14    4    3    1    0  976    2   19]\n",
      " [   4    1    2   12    5    5    7    9  923    6]\n",
      " [   8    8    2   10   17    6    0    9    4  945]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 1.3243 - acc: 0.6172 - val_loss: 0.6502 - val_acc: 0.8314\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.5123 - acc: 0.8601 - val_loss: 0.3985 - val_acc: 0.8903\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3749 - acc: 0.8939 - val_loss: 0.3264 - val_acc: 0.9081\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.3224 - acc: 0.9076 - val_loss: 0.2895 - val_acc: 0.9166\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2914 - acc: 0.9164 - val_loss: 0.2691 - val_acc: 0.9232\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2696 - acc: 0.9225 - val_loss: 0.2496 - val_acc: 0.9292\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2518 - acc: 0.9274 - val_loss: 0.2377 - val_acc: 0.9320\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2368 - acc: 0.9313 - val_loss: 0.2246 - val_acc: 0.9358\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2235 - acc: 0.9357 - val_loss: 0.2139 - val_acc: 0.9394\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2124 - acc: 0.9386 - val_loss: 0.2120 - val_acc: 0.9384\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2022 - acc: 0.9414 - val_loss: 0.1981 - val_acc: 0.9423\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1930 - acc: 0.9444 - val_loss: 0.1927 - val_acc: 0.9443\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1842 - acc: 0.9473 - val_loss: 0.1848 - val_acc: 0.9468\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1765 - acc: 0.9489 - val_loss: 0.1786 - val_acc: 0.9485\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1691 - acc: 0.9507 - val_loss: 0.1715 - val_acc: 0.9500\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1623 - acc: 0.9533 - val_loss: 0.1690 - val_acc: 0.9517\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1561 - acc: 0.9556 - val_loss: 0.1605 - val_acc: 0.9527\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1500 - acc: 0.9568 - val_loss: 0.1572 - val_acc: 0.9531\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1444 - acc: 0.9584 - val_loss: 0.1519 - val_acc: 0.9543\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1389 - acc: 0.9601 - val_loss: 0.1495 - val_acc: 0.9546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291019bcef0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291019ca438>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291019ad908>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101a35f98>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101a3f128>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29101a279b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.96      0.95      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.95      0.96       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.95      0.93      0.94       974\n",
      "           9       0.92      0.95      0.94      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[[ 966    0    1    2    0    3    3    2    1    2]\n",
      " [   0 1111    3    2    0    1    3    3   12    0]\n",
      " [   8    1  987    6    7    0    5    8    9    1]\n",
      " [   0    0    9  968    0   10    0    9    9    5]\n",
      " [   2    1    6    1  930    0    7    2    2   31]\n",
      " [  10    2    1   14    3  836   10    0    9    7]\n",
      " [  11    3    6    0    8   15  912    0    3    0]\n",
      " [   1    6   19    3    5    1    0  965    1   27]\n",
      " [   5    1    4   16    6    7    8    5  910   12]\n",
      " [   6    5    1    8   15    1    1    6    5  961]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 1.4710 - acc: 0.5639 - val_loss: 0.6661 - val_acc: 0.8259\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.5204 - acc: 0.8586 - val_loss: 0.4072 - val_acc: 0.8877\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3836 - acc: 0.8921 - val_loss: 0.3403 - val_acc: 0.9024\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3295 - acc: 0.9067 - val_loss: 0.2989 - val_acc: 0.9156\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2960 - acc: 0.9156 - val_loss: 0.2753 - val_acc: 0.9224\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2708 - acc: 0.9216 - val_loss: 0.2529 - val_acc: 0.9306\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.2507 - acc: 0.9285 - val_loss: 0.2401 - val_acc: 0.9307\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2332 - acc: 0.9334 - val_loss: 0.2227 - val_acc: 0.9373\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2181 - acc: 0.9371 - val_loss: 0.2156 - val_acc: 0.9378\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.2043 - acc: 0.9416 - val_loss: 0.1979 - val_acc: 0.9430\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1927 - acc: 0.9446 - val_loss: 0.1915 - val_acc: 0.9451\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1824 - acc: 0.9486 - val_loss: 0.1807 - val_acc: 0.9468\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1731 - acc: 0.9504 - val_loss: 0.1721 - val_acc: 0.9478\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1649 - acc: 0.9537 - val_loss: 0.1643 - val_acc: 0.9497\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1575 - acc: 0.9554 - val_loss: 0.1630 - val_acc: 0.9513\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1504 - acc: 0.9572 - val_loss: 0.1539 - val_acc: 0.9529\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1445 - acc: 0.9591 - val_loss: 0.1491 - val_acc: 0.9558\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1385 - acc: 0.9608 - val_loss: 0.1442 - val_acc: 0.9573\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1333 - acc: 0.9621 - val_loss: 0.1404 - val_acc: 0.9596\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1283 - acc: 0.9637 - val_loss: 0.1358 - val_acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101d761d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29101d76668>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2915852d198>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2915ac09240>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2915ac09dd8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2915ac71518>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.97      0.97      0.97       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.96      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    1    2    0    5    5    2    1    0]\n",
      " [   0 1116    2    4    0    1    4    2    6    0]\n",
      " [   4    1  993    9    3    1    4    9    8    0]\n",
      " [   0    0    8  969    0    5    0   10   17    1]\n",
      " [   1    0    7    0  942    1    4    2    3   22]\n",
      " [   6    1    0   18    3  838   10    1    9    6]\n",
      " [   6    3    3    1    7    8  925    1    4    0]\n",
      " [   2   10   16    1    1    0    0  985    2   11]\n",
      " [   4    1    3   16    7    8    6    6  920    3]\n",
      " [   7    6    1    9   16    2    0    9   11  948]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 1.6162 - acc: 0.5297 - val_loss: 0.7345 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.5350 - acc: 0.8581 - val_loss: 0.4097 - val_acc: 0.8891\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3767 - acc: 0.8940 - val_loss: 0.3311 - val_acc: 0.9063\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3225 - acc: 0.9077 - val_loss: 0.2925 - val_acc: 0.9173\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2902 - acc: 0.9165 - val_loss: 0.2690 - val_acc: 0.9243\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2670 - acc: 0.9222 - val_loss: 0.2521 - val_acc: 0.9314\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2479 - acc: 0.9284 - val_loss: 0.2337 - val_acc: 0.9348\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2314 - acc: 0.9329 - val_loss: 0.2209 - val_acc: 0.9375\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2172 - acc: 0.9377 - val_loss: 0.2108 - val_acc: 0.9395\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2048 - acc: 0.9407 - val_loss: 0.2001 - val_acc: 0.9430\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1940 - acc: 0.9441 - val_loss: 0.1893 - val_acc: 0.9452\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1835 - acc: 0.9471 - val_loss: 0.1798 - val_acc: 0.9481\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1750 - acc: 0.9500 - val_loss: 0.1800 - val_acc: 0.9483\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1666 - acc: 0.9517 - val_loss: 0.1710 - val_acc: 0.9488\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1595 - acc: 0.9538 - val_loss: 0.1615 - val_acc: 0.9524\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1526 - acc: 0.9557 - val_loss: 0.1575 - val_acc: 0.9539\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1465 - acc: 0.9576 - val_loss: 0.1515 - val_acc: 0.9559\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1410 - acc: 0.9598 - val_loss: 0.1478 - val_acc: 0.9555\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1358 - acc: 0.9606 - val_loss: 0.1444 - val_acc: 0.9569\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1307 - acc: 0.9621 - val_loss: 0.1408 - val_acc: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29103382048>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291033824e0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29103382860>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291033f8208>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291033f8358>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291033ddcc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.96      0.94      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.97      0.94      0.95      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    1    1    0    5    5    1    1    0]\n",
      " [   0 1118    2    2    1    0    3    2    7    0]\n",
      " [   8    2  991    9    4    0    8    6    4    0]\n",
      " [   0    1   12  952    0   19    1    9   13    3]\n",
      " [   1    0    5    0  943    0   12    1    3   17]\n",
      " [   8    1    0    6    1  850    9    0   12    5]\n",
      " [   9    3    3    0    6    7  926    0    4    0]\n",
      " [   1   10   21    4    4    2    0  964    1   21]\n",
      " [   3    1    4   10    5    9   11    7  921    3]\n",
      " [   6    6    1    9   24    5    1    6    7  944]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.5226 - acc: 0.6077 - val_loss: 0.6739 - val_acc: 0.8524\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.5077 - acc: 0.8675 - val_loss: 0.3960 - val_acc: 0.8890\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3722 - acc: 0.8932 - val_loss: 0.3286 - val_acc: 0.9053\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3244 - acc: 0.9058 - val_loss: 0.3016 - val_acc: 0.9129\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2944 - acc: 0.9148 - val_loss: 0.2721 - val_acc: 0.9212\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2719 - acc: 0.9211 - val_loss: 0.2542 - val_acc: 0.9255\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2535 - acc: 0.9266 - val_loss: 0.2394 - val_acc: 0.9304\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2377 - acc: 0.9316 - val_loss: 0.2270 - val_acc: 0.9340\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2240 - acc: 0.9351 - val_loss: 0.2175 - val_acc: 0.9371\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2118 - acc: 0.9387 - val_loss: 0.2063 - val_acc: 0.9396\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2011 - acc: 0.9416 - val_loss: 0.1982 - val_acc: 0.9421\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1911 - acc: 0.9445 - val_loss: 0.1890 - val_acc: 0.9451\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1823 - acc: 0.9474 - val_loss: 0.1819 - val_acc: 0.9461\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1742 - acc: 0.9500 - val_loss: 0.1769 - val_acc: 0.9473\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1664 - acc: 0.9519 - val_loss: 0.1710 - val_acc: 0.9494\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1599 - acc: 0.9535 - val_loss: 0.1616 - val_acc: 0.9519\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1532 - acc: 0.9559 - val_loss: 0.1613 - val_acc: 0.9523\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1471 - acc: 0.9576 - val_loss: 0.1540 - val_acc: 0.9539\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1417 - acc: 0.9593 - val_loss: 0.1470 - val_acc: 0.9563\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1367 - acc: 0.9605 - val_loss: 0.1466 - val_acc: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29103727cc0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29103731208>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291037537b8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291037b2198>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291037b26d8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910379bc50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.93      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.95      0.96      0.95      1028\n",
      "           8       0.96      0.93      0.94       974\n",
      "           9       0.96      0.92      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    1    1    1    4    4    3    2    0]\n",
      " [   0 1119    2    2    0    1    3    2    6    0]\n",
      " [   6    3  986   12    5    1    3   10    5    1]\n",
      " [   1    0    7  974    0    9    0   12    5    2]\n",
      " [   1    1    5    0  945    0    7    3    3   17]\n",
      " [   7    2    1   22    2  842    8    0    6    2]\n",
      " [   9    3    2    0    9   10  920    0    5    0]\n",
      " [   1   11   16    2    3    1    0  982    2   10]\n",
      " [   5    2    6   21    5    7    9   12  905    2]\n",
      " [  10    6    2   16   22    1    0   15    4  933]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 1.4754 - acc: 0.5967 - val_loss: 0.6728 - val_acc: 0.8395\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.5107 - acc: 0.8653 - val_loss: 0.3997 - val_acc: 0.8924\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3758 - acc: 0.8941 - val_loss: 0.3328 - val_acc: 0.9071\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3278 - acc: 0.9052 - val_loss: 0.2997 - val_acc: 0.9143\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2989 - acc: 0.9140 - val_loss: 0.2783 - val_acc: 0.9209\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2764 - acc: 0.9194 - val_loss: 0.2586 - val_acc: 0.9280\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2584 - acc: 0.9262 - val_loss: 0.2445 - val_acc: 0.9280\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2425 - acc: 0.9309 - val_loss: 0.2352 - val_acc: 0.9342\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2289 - acc: 0.9347 - val_loss: 0.2190 - val_acc: 0.9366\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2166 - acc: 0.9383 - val_loss: 0.2086 - val_acc: 0.9399\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2055 - acc: 0.9410 - val_loss: 0.1969 - val_acc: 0.9443\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1952 - acc: 0.9441 - val_loss: 0.1912 - val_acc: 0.9468\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1861 - acc: 0.9468 - val_loss: 0.1812 - val_acc: 0.9481\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1777 - acc: 0.9490 - val_loss: 0.1729 - val_acc: 0.9514\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1699 - acc: 0.9514 - val_loss: 0.1680 - val_acc: 0.9522\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1626 - acc: 0.9534 - val_loss: 0.1611 - val_acc: 0.9533\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1561 - acc: 0.9554 - val_loss: 0.1550 - val_acc: 0.9552\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1499 - acc: 0.9572 - val_loss: 0.1494 - val_acc: 0.9562\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1441 - acc: 0.9590 - val_loss: 0.1457 - val_acc: 0.9573\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1432 - val_acc: 0.9574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29103b14898>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29103b14d30>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29103ad9390>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29103b65cf8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29103b71278>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29103b587f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.93      0.95       892\n",
      "           6       0.94      0.97      0.96       958\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.96      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 959    0    3    2    1    4    7    3    1    0]\n",
      " [   0 1119    3    2    0    1    4    2    4    0]\n",
      " [   6    2  988    4    4    0   10    9    7    2]\n",
      " [   0    1   11  964    1    6    1   11   12    3]\n",
      " [   1    2    8    0  942    0    9    3    3   14]\n",
      " [  10    1    0   17    2  830   14    0   11    7]\n",
      " [   9    3    1    0    6    8  926    1    4    0]\n",
      " [   0   10   18    4    4    1    0  979    1   11]\n",
      " [   5    2    3   14    3    8    8    7  923    1]\n",
      " [   8    9    1    6   19    3    1   11    7  944]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 1.4088 - acc: 0.6223 - val_loss: 0.6155 - val_acc: 0.8472\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4820 - acc: 0.8718 - val_loss: 0.3817 - val_acc: 0.8942\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3650 - acc: 0.8962 - val_loss: 0.3273 - val_acc: 0.9066\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3194 - acc: 0.9085 - val_loss: 0.2935 - val_acc: 0.9160\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2898 - acc: 0.9170 - val_loss: 0.2703 - val_acc: 0.9201\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2670 - acc: 0.9224 - val_loss: 0.2472 - val_acc: 0.9288\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2483 - acc: 0.9285 - val_loss: 0.2319 - val_acc: 0.9326\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2322 - acc: 0.9321 - val_loss: 0.2245 - val_acc: 0.9364\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2182 - acc: 0.9365 - val_loss: 0.2067 - val_acc: 0.9387\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2053 - acc: 0.9404 - val_loss: 0.2007 - val_acc: 0.9411\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1948 - acc: 0.9431 - val_loss: 0.1887 - val_acc: 0.9455\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1845 - acc: 0.9466 - val_loss: 0.1800 - val_acc: 0.9470\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1755 - acc: 0.9487 - val_loss: 0.1752 - val_acc: 0.9484\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1671 - acc: 0.9512 - val_loss: 0.1663 - val_acc: 0.9503\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1594 - acc: 0.9540 - val_loss: 0.1602 - val_acc: 0.9525\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1527 - acc: 0.9556 - val_loss: 0.1539 - val_acc: 0.9559\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1460 - acc: 0.9574 - val_loss: 0.1470 - val_acc: 0.9566\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1403 - acc: 0.9594 - val_loss: 0.1456 - val_acc: 0.9565\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1347 - acc: 0.9613 - val_loss: 0.1403 - val_acc: 0.9571\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1300 - acc: 0.9624 - val_loss: 0.1353 - val_acc: 0.9598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29108c4e438>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29108c4e8d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29107c10ef0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29108ca2400>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29108ca2550>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29108c8add8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.96      0.97      0.96       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.96      0.97      0.96       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.94      0.96      0.95       974\n",
      "           9       0.96      0.93      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 961    0    1    1    1    4    5    3    3    1]\n",
      " [   0 1114    4    2    0    1    4    2    8    0]\n",
      " [   6    1  987    9    3    1    6    7   10    2]\n",
      " [   0    1    9  967    0   13    0    8    9    3]\n",
      " [   1    0    5    0  949    0    6    1    3   17]\n",
      " [   5    1    0   18    0  844    9    1   12    2]\n",
      " [   8    3    1    0    4   10  925    0    7    0]\n",
      " [   0    7   23    4    3    0    0  977    3   11]\n",
      " [   4    1    4   11    3    6    6    3  935    1]\n",
      " [   7    9    1   12   24    4    1    5    7  939]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 1.4248 - acc: 0.6280 - val_loss: 0.6045 - val_acc: 0.8493\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.4832 - acc: 0.8713 - val_loss: 0.3822 - val_acc: 0.8909\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.3679 - acc: 0.8958 - val_loss: 0.3316 - val_acc: 0.9033\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3233 - acc: 0.9069 - val_loss: 0.2980 - val_acc: 0.9134\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2938 - acc: 0.9163 - val_loss: 0.2703 - val_acc: 0.9221\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2723 - acc: 0.9219 - val_loss: 0.2552 - val_acc: 0.9266\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2542 - acc: 0.9275 - val_loss: 0.2410 - val_acc: 0.9294\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2388 - acc: 0.9320 - val_loss: 0.2321 - val_acc: 0.9333\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2252 - acc: 0.9361 - val_loss: 0.2161 - val_acc: 0.9360\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2126 - acc: 0.9388 - val_loss: 0.2034 - val_acc: 0.9400\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2016 - acc: 0.9425 - val_loss: 0.1952 - val_acc: 0.9436\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1919 - acc: 0.9448 - val_loss: 0.1846 - val_acc: 0.9449\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1824 - acc: 0.9479 - val_loss: 0.1774 - val_acc: 0.9476\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1739 - acc: 0.9505 - val_loss: 0.1733 - val_acc: 0.9481\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1665 - acc: 0.9524 - val_loss: 0.1636 - val_acc: 0.9507\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1599 - acc: 0.9543 - val_loss: 0.1581 - val_acc: 0.9532\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1532 - acc: 0.9558 - val_loss: 0.1560 - val_acc: 0.9544\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1475 - acc: 0.9580 - val_loss: 0.1505 - val_acc: 0.9555\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1421 - acc: 0.9594 - val_loss: 0.1437 - val_acc: 0.9575\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1370 - acc: 0.9611 - val_loss: 0.1425 - val_acc: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29109fcac88>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29109fb41d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29109fb4710>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910a02ac50>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910a0361d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910a01c748>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.97      0.96      1032\n",
      "           3       0.93      0.97      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.97      0.92      0.95       892\n",
      "           6       0.96      0.97      0.97       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.97      0.93      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    1    2    0    4    4    2    1    0]\n",
      " [   0 1119    3    2    0    1    3    2    5    0]\n",
      " [   7    2 1000    5    2    1    3    6    4    2]\n",
      " [   0    1   10  979    1    4    0    9    4    2]\n",
      " [   1    1    5    0  942    0    6    3    2   22]\n",
      " [   9    1    2   26    2  824   10    2   11    5]\n",
      " [  10    3    3    0    4    7  928    1    2    0]\n",
      " [   2    9   15    5    1    1    0  979    0   16]\n",
      " [   4    2    7   16    8    6    9    9  910    3]\n",
      " [   7    6    3   14   18    3    1    8    4  945]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 1.4952 - acc: 0.5940 - val_loss: 0.6678 - val_acc: 0.8338\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.5153 - acc: 0.8603 - val_loss: 0.3967 - val_acc: 0.8869\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3730 - acc: 0.8953 - val_loss: 0.3270 - val_acc: 0.9036\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.3219 - acc: 0.9081 - val_loss: 0.2882 - val_acc: 0.9159\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2916 - acc: 0.9162 - val_loss: 0.2675 - val_acc: 0.9210\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2690 - acc: 0.9218 - val_loss: 0.2505 - val_acc: 0.9272\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2509 - acc: 0.9276 - val_loss: 0.2369 - val_acc: 0.9290\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2350 - acc: 0.9323 - val_loss: 0.2229 - val_acc: 0.9337\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2220 - acc: 0.9361 - val_loss: 0.2105 - val_acc: 0.9377\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2096 - acc: 0.9397 - val_loss: 0.2004 - val_acc: 0.9385\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1994 - acc: 0.9429 - val_loss: 0.1938 - val_acc: 0.9423\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1897 - acc: 0.9457 - val_loss: 0.1894 - val_acc: 0.9425\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1810 - acc: 0.9475 - val_loss: 0.1781 - val_acc: 0.9467\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1727 - acc: 0.9502 - val_loss: 0.1733 - val_acc: 0.9476\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1650 - acc: 0.9520 - val_loss: 0.1663 - val_acc: 0.9492\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1583 - acc: 0.9543 - val_loss: 0.1629 - val_acc: 0.9514\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1516 - acc: 0.9564 - val_loss: 0.1597 - val_acc: 0.9531\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1456 - acc: 0.9583 - val_loss: 0.1529 - val_acc: 0.9549\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1400 - acc: 0.9601 - val_loss: 0.1477 - val_acc: 0.9557\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1347 - acc: 0.9618 - val_loss: 0.1434 - val_acc: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910a393278>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910a393710>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910a34bd30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910a3ef748>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910a3ef898>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910a3de240>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.95      1032\n",
      "           3       0.94      0.95      0.94      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.94      0.96      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    0    2    0    5    3    2    2    2]\n",
      " [   0 1115    3    2    0    1    3    2    9    0]\n",
      " [   6    2  979   14    5    2    5    9    8    2]\n",
      " [   0    1    8  962    0   20    0    8    6    5]\n",
      " [   1    0    4    1  941    0    9    2    2   22]\n",
      " [   4    1    1   12    1  855    8    1    4    5]\n",
      " [  10    3    2    1    7   11  919    1    4    0]\n",
      " [   1    9   19    4    2    1    0  975    1   16]\n",
      " [   3    1    2   16    8   13    7    7  911    6]\n",
      " [  10    6    1   12   19    2    0    6    3  950]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 1.3832 - acc: 0.6286 - val_loss: 0.6012 - val_acc: 0.8433\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.4810 - acc: 0.8660 - val_loss: 0.3875 - val_acc: 0.8881\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.3671 - acc: 0.8932 - val_loss: 0.3268 - val_acc: 0.9044\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3211 - acc: 0.9066 - val_loss: 0.2956 - val_acc: 0.9152\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2918 - acc: 0.9148 - val_loss: 0.2730 - val_acc: 0.9223\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2697 - acc: 0.9215 - val_loss: 0.2556 - val_acc: 0.9258\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.2515 - acc: 0.9268 - val_loss: 0.2385 - val_acc: 0.9314\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2357 - acc: 0.9320 - val_loss: 0.2258 - val_acc: 0.9352\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2220 - acc: 0.9360 - val_loss: 0.2148 - val_acc: 0.9375\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2095 - acc: 0.9397 - val_loss: 0.2050 - val_acc: 0.9407\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1990 - acc: 0.9426 - val_loss: 0.1967 - val_acc: 0.9414\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1894 - acc: 0.9456 - val_loss: 0.1862 - val_acc: 0.9444\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1802 - acc: 0.9476 - val_loss: 0.1810 - val_acc: 0.9446\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1725 - acc: 0.9503 - val_loss: 0.1733 - val_acc: 0.9469\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1650 - acc: 0.9519 - val_loss: 0.1663 - val_acc: 0.9480\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1579 - acc: 0.9542 - val_loss: 0.1658 - val_acc: 0.9494\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1515 - acc: 0.9559 - val_loss: 0.1590 - val_acc: 0.9498\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1459 - acc: 0.9575 - val_loss: 0.1514 - val_acc: 0.9535\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1403 - acc: 0.9589 - val_loss: 0.1479 - val_acc: 0.9539\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1354 - acc: 0.9607 - val_loss: 0.1456 - val_acc: 0.9548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910b729048>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910b7294e0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910a719b00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910b775fd0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910b77f5c0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910b766ac8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.94      0.95      1032\n",
      "           3       0.92      0.97      0.95      1010\n",
      "           4       0.95      0.94      0.95       982\n",
      "           5       0.95      0.94      0.94       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.97      0.94      0.95      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.93      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.95     10000\n",
      "\n",
      "[[ 965    0    0    1    0    5    4    2    2    1]\n",
      " [   0 1116    2    5    0    1    3    2    6    0]\n",
      " [   7    2  975   19    6    2    6    8    7    0]\n",
      " [   0    0    2  982    0    9    0    7    7    3]\n",
      " [   1    0    6    1  925    0    9    1    2   37]\n",
      " [   7    3    1   20    2  836    9    0   10    4]\n",
      " [   8    3    4    0    7   11  919    0    6    0]\n",
      " [   1    9   17    7    4    1    0  966    2   21]\n",
      " [   6    1    4   22    4    9    7    5  916    0]\n",
      " [   6    8    1   10   21    8    0    6    1  948]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 1.3574 - acc: 0.6628 - val_loss: 0.5733 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4675 - acc: 0.8721 - val_loss: 0.3731 - val_acc: 0.8967\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.3612 - acc: 0.8966 - val_loss: 0.3210 - val_acc: 0.9070\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3175 - acc: 0.9086 - val_loss: 0.2872 - val_acc: 0.9180\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2895 - acc: 0.9160 - val_loss: 0.2636 - val_acc: 0.9255\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2682 - acc: 0.9222 - val_loss: 0.2463 - val_acc: 0.9294\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2504 - acc: 0.9275 - val_loss: 0.2356 - val_acc: 0.9320\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2352 - acc: 0.9322 - val_loss: 0.2203 - val_acc: 0.9366\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2219 - acc: 0.9362 - val_loss: 0.2085 - val_acc: 0.9384\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2099 - acc: 0.9399 - val_loss: 0.2005 - val_acc: 0.9426\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1992 - acc: 0.9422 - val_loss: 0.1919 - val_acc: 0.9434\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1895 - acc: 0.9454 - val_loss: 0.1816 - val_acc: 0.9460\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1808 - acc: 0.9477 - val_loss: 0.1755 - val_acc: 0.9465\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1730 - acc: 0.9497 - val_loss: 0.1695 - val_acc: 0.9513\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1660 - acc: 0.9515 - val_loss: 0.1628 - val_acc: 0.9515\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1591 - acc: 0.9546 - val_loss: 0.1598 - val_acc: 0.9524\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1527 - acc: 0.9561 - val_loss: 0.1513 - val_acc: 0.9542\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1474 - acc: 0.9576 - val_loss: 0.1478 - val_acc: 0.9574\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1419 - acc: 0.9594 - val_loss: 0.1454 - val_acc: 0.9570\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1369 - acc: 0.9606 - val_loss: 0.1408 - val_acc: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910babd898>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910babdda0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910babdeb8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910cb06860>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910cb069b0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910caf7278>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.94      0.97      0.95      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.97      0.96       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.96      0.97      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.97      0.92      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    2    1    0    3    6    1    1    0]\n",
      " [   0 1120    2    2    0    1    4    2    4    0]\n",
      " [   4    2  999    4    4    0    4    7    7    1]\n",
      " [   0    3   14  962    1    8    0   11    9    2]\n",
      " [   1    0    4    0  952    0    6    2    3   14]\n",
      " [   8    2    0   13    3  846   10    0    6    4]\n",
      " [   7    3    5    0    5   10  926    1    1    0]\n",
      " [   1   10   22    4    1    1    0  978    1   10]\n",
      " [   5    2    8   16    5    8    9    8  911    2]\n",
      " [   4    7    5   11   28    3    1   11    7  932]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 1.2792 - acc: 0.6676 - val_loss: 0.5521 - val_acc: 0.8576\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.4574 - acc: 0.8742 - val_loss: 0.3666 - val_acc: 0.8982\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3560 - acc: 0.8982 - val_loss: 0.3154 - val_acc: 0.9092\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.3138 - acc: 0.9097 - val_loss: 0.2836 - val_acc: 0.9199\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2868 - acc: 0.9166 - val_loss: 0.2664 - val_acc: 0.9226\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2663 - acc: 0.9228 - val_loss: 0.2471 - val_acc: 0.9289\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2490 - acc: 0.9278 - val_loss: 0.2338 - val_acc: 0.9326\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2343 - acc: 0.9320 - val_loss: 0.2212 - val_acc: 0.9352\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2209 - acc: 0.9359 - val_loss: 0.2097 - val_acc: 0.9386\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2092 - acc: 0.9388 - val_loss: 0.2010 - val_acc: 0.9398\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1985 - acc: 0.9426 - val_loss: 0.2004 - val_acc: 0.9399\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1885 - acc: 0.9459 - val_loss: 0.1851 - val_acc: 0.9449\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1793 - acc: 0.9486 - val_loss: 0.1784 - val_acc: 0.9478\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1716 - acc: 0.9511 - val_loss: 0.1679 - val_acc: 0.9501\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1643 - acc: 0.9523 - val_loss: 0.1634 - val_acc: 0.9526\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1574 - acc: 0.9547 - val_loss: 0.1579 - val_acc: 0.9529\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1512 - acc: 0.9566 - val_loss: 0.1538 - val_acc: 0.9541\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1452 - acc: 0.9580 - val_loss: 0.1493 - val_acc: 0.9559\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1396 - acc: 0.9599 - val_loss: 0.1418 - val_acc: 0.9571\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1346 - acc: 0.9612 - val_loss: 0.1390 - val_acc: 0.9587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910ce69128>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910ce69630>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910ce69ac8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910cec2c18>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910cecb198>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910ceb2630>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.96      0.97      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.96      0.93      0.95       974\n",
      "           9       0.95      0.95      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 970    0    1    1    0    2    4    1    1    0]\n",
      " [   0 1118    4    1    1    1    4    2    4    0]\n",
      " [   7    1  997    6    4    0    1    8    6    2]\n",
      " [   1    1   12  963    0   12    0    9    8    4]\n",
      " [   1    1    8    0  941    0    6    2    2   21]\n",
      " [   9    1    0   13    2  844   10    0    7    6]\n",
      " [   9    3    1    1   10   10  917    0    7    0]\n",
      " [   1   11   15    4    5    2    0  973    1   16]\n",
      " [   6    5    4   16    8    6    8    7  910    4]\n",
      " [   9    9    1    9   16    2    1    6    2  954]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 1.3621 - acc: 0.6548 - val_loss: 0.5754 - val_acc: 0.8552\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.4659 - acc: 0.8731 - val_loss: 0.3729 - val_acc: 0.8940\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3611 - acc: 0.8968 - val_loss: 0.3201 - val_acc: 0.9076\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.3188 - acc: 0.9079 - val_loss: 0.2906 - val_acc: 0.9138\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2911 - acc: 0.9150 - val_loss: 0.2799 - val_acc: 0.9204\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2710 - acc: 0.9207 - val_loss: 0.2563 - val_acc: 0.9256\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2535 - acc: 0.9261 - val_loss: 0.2390 - val_acc: 0.9320\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2382 - acc: 0.9302 - val_loss: 0.2276 - val_acc: 0.9360\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2249 - acc: 0.9345 - val_loss: 0.2163 - val_acc: 0.9383\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2126 - acc: 0.9380 - val_loss: 0.2049 - val_acc: 0.9404\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2010 - acc: 0.9421 - val_loss: 0.1994 - val_acc: 0.9409\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1905 - acc: 0.9454 - val_loss: 0.1885 - val_acc: 0.9457\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1808 - acc: 0.9476 - val_loss: 0.1794 - val_acc: 0.9467\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1721 - acc: 0.9503 - val_loss: 0.1707 - val_acc: 0.9491\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1641 - acc: 0.9527 - val_loss: 0.1638 - val_acc: 0.9523\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1563 - acc: 0.9551 - val_loss: 0.1579 - val_acc: 0.9538\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1493 - acc: 0.9571 - val_loss: 0.1516 - val_acc: 0.9555\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1433 - acc: 0.9588 - val_loss: 0.1488 - val_acc: 0.9565\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1375 - acc: 0.9604 - val_loss: 0.1428 - val_acc: 0.9578\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1320 - acc: 0.9624 - val_loss: 0.1383 - val_acc: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910d201f60>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910e1f7438>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910e1f7a58>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910e24ef28>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910e2580b8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910e258a58>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.95      0.94      0.95       974\n",
      "           9       0.96      0.92      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 959    0    1    3    0    7    7    1    0    2]\n",
      " [   0 1120    2    1    0    1    2    2    7    0]\n",
      " [   5    1  995    6    3    1    8    6    6    1]\n",
      " [   0    2   11  963    0   12    0   10   10    2]\n",
      " [   1    0    4    0  944    0   13    2    3   15]\n",
      " [   5    1    0   12    2  847   11    1   10    3]\n",
      " [   5    3    1    2    5    7  930    1    4    0]\n",
      " [   0   11   16    4    3    2    0  978    1   13]\n",
      " [   4    1    4   15    5    7   10    7  920    1]\n",
      " [   5    6    2   11   34    7    1   10    6  927]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.3653 - acc: 0.6457 - val_loss: 0.5973 - val_acc: 0.8490\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.4782 - acc: 0.8721 - val_loss: 0.3845 - val_acc: 0.8920\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.3686 - acc: 0.8952 - val_loss: 0.3311 - val_acc: 0.9036\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.3269 - acc: 0.9057 - val_loss: 0.3000 - val_acc: 0.9137\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.3007 - acc: 0.9129 - val_loss: 0.2795 - val_acc: 0.9209\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2801 - acc: 0.9198 - val_loss: 0.2656 - val_acc: 0.9253\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2633 - acc: 0.9243 - val_loss: 0.2523 - val_acc: 0.9283\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.2494 - acc: 0.9280 - val_loss: 0.2401 - val_acc: 0.9302\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2368 - acc: 0.9322 - val_loss: 0.2285 - val_acc: 0.9338\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2253 - acc: 0.9348 - val_loss: 0.2180 - val_acc: 0.9378\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2153 - acc: 0.9382 - val_loss: 0.2083 - val_acc: 0.9389\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2060 - acc: 0.9407 - val_loss: 0.2020 - val_acc: 0.9405\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1972 - acc: 0.9435 - val_loss: 0.1947 - val_acc: 0.9416\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1893 - acc: 0.9461 - val_loss: 0.1878 - val_acc: 0.9432\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1821 - acc: 0.9485 - val_loss: 0.1804 - val_acc: 0.9464\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1748 - acc: 0.9504 - val_loss: 0.1778 - val_acc: 0.9464\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.1684 - acc: 0.9517 - val_loss: 0.1685 - val_acc: 0.9496\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1622 - acc: 0.9539 - val_loss: 0.1632 - val_acc: 0.9515\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1563 - acc: 0.9547 - val_loss: 0.1624 - val_acc: 0.9523\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1511 - acc: 0.9570 - val_loss: 0.1575 - val_acc: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910e594828>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910e594cc0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910e56dcf8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910f5dd7f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910f5ddda0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910f5dde48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.95      1032\n",
      "           3       0.95      0.94      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.95      0.94      0.95       892\n",
      "           6       0.94      0.96      0.95       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.93      0.95      0.94       974\n",
      "           9       0.96      0.92      0.94      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[[ 965    0    1    2    0    3    6    2    1    0]\n",
      " [   0 1113    2    2    1    1    4    2   10    0]\n",
      " [   9    2  976    6    4    1   11    9   12    2]\n",
      " [   2    1    7  953    1   17    1   10   16    2]\n",
      " [   1    0    4    0  945    0   12    2    3   15]\n",
      " [   9    2    0   14    1  838   11    1   12    4]\n",
      " [   8    3    2    0    6   10  924    0    5    0]\n",
      " [   1   10   24    4    5    1    0  968    1   14]\n",
      " [   7    1    2   14    6    4   11    6  922    1]\n",
      " [   7    6    2   11   28    6    1   13    8  927]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 1.4616 - acc: 0.6055 - val_loss: 0.6416 - val_acc: 0.8459\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.4987 - acc: 0.8676 - val_loss: 0.3821 - val_acc: 0.8950\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.3667 - acc: 0.8975 - val_loss: 0.3237 - val_acc: 0.9079\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.3176 - acc: 0.9083 - val_loss: 0.2880 - val_acc: 0.9185\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2881 - acc: 0.9177 - val_loss: 0.2691 - val_acc: 0.9210\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2656 - acc: 0.9233 - val_loss: 0.2459 - val_acc: 0.9291\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2476 - acc: 0.9291 - val_loss: 0.2297 - val_acc: 0.9348\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2324 - acc: 0.9335 - val_loss: 0.2182 - val_acc: 0.9355\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2196 - acc: 0.9368 - val_loss: 0.2071 - val_acc: 0.9391\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2082 - acc: 0.9403 - val_loss: 0.1980 - val_acc: 0.9406\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1979 - acc: 0.9435 - val_loss: 0.1905 - val_acc: 0.9427\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1890 - acc: 0.9461 - val_loss: 0.1813 - val_acc: 0.9455\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1805 - acc: 0.9482 - val_loss: 0.1758 - val_acc: 0.9466\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1728 - acc: 0.9500 - val_loss: 0.1683 - val_acc: 0.9498\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1660 - acc: 0.9521 - val_loss: 0.1624 - val_acc: 0.9513\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1593 - acc: 0.9542 - val_loss: 0.1580 - val_acc: 0.9525\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1537 - acc: 0.9560 - val_loss: 0.1537 - val_acc: 0.9539\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1480 - acc: 0.9571 - val_loss: 0.1474 - val_acc: 0.9556\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1429 - acc: 0.9590 - val_loss: 0.1430 - val_acc: 0.9564\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1399 - val_acc: 0.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910f92a0b8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910f92a550>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910f90ba90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910f9a1518>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910f9a1668>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910f989fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.97      0.95      0.96       958\n",
      "           7       0.95      0.96      0.95      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 967    0    1    3    0    3    1    4    1    0]\n",
      " [   0 1116    3    2    0    1    3    2    8    0]\n",
      " [   8    1  983    9    7    0    2   11   10    1]\n",
      " [   0    1    9  963    1   10    0   11   10    5]\n",
      " [   1    0    4    0  940    0    6    2    3   26]\n",
      " [   8    1    0   12    2  846    9    1    8    5]\n",
      " [  12    3    1    0   12   13  912    0    5    0]\n",
      " [   2    8   17    4    1    1    0  982    0   13]\n",
      " [   4    2    3   14    5    7    7    6  921    5]\n",
      " [   5    5    1    8   20    5    1   11    3  950]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 1.3901 - acc: 0.6331 - val_loss: 0.6122 - val_acc: 0.8398\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.4890 - acc: 0.8687 - val_loss: 0.3891 - val_acc: 0.8919\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.3722 - acc: 0.8949 - val_loss: 0.3298 - val_acc: 0.9045\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.3255 - acc: 0.9080 - val_loss: 0.2964 - val_acc: 0.9160\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2958 - acc: 0.9157 - val_loss: 0.2725 - val_acc: 0.9218\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2735 - acc: 0.9216 - val_loss: 0.2575 - val_acc: 0.9276\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2563 - acc: 0.9262 - val_loss: 0.2400 - val_acc: 0.9328\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2408 - acc: 0.9312 - val_loss: 0.2297 - val_acc: 0.9349\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2277 - acc: 0.9346 - val_loss: 0.2165 - val_acc: 0.9403\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2158 - acc: 0.9378 - val_loss: 0.2048 - val_acc: 0.9425\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2053 - acc: 0.9410 - val_loss: 0.1982 - val_acc: 0.9435\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1958 - acc: 0.9438 - val_loss: 0.1888 - val_acc: 0.9475\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1866 - acc: 0.9455 - val_loss: 0.1799 - val_acc: 0.9468\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1784 - acc: 0.9489 - val_loss: 0.1746 - val_acc: 0.9501\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1708 - acc: 0.9505 - val_loss: 0.1693 - val_acc: 0.9506\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1638 - acc: 0.9529 - val_loss: 0.1649 - val_acc: 0.9521\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1573 - acc: 0.9549 - val_loss: 0.1576 - val_acc: 0.9556\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1513 - acc: 0.9564 - val_loss: 0.1559 - val_acc: 0.9553\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1458 - acc: 0.9584 - val_loss: 0.1485 - val_acc: 0.9574\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1403 - acc: 0.9595 - val_loss: 0.1422 - val_acc: 0.9590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910fccaa58>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910fccaef0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910fcbb470>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910fd5da20>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2910fd5db70>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2910fd4c518>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.97      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.96      0.93      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.95      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    0    3    0    6    2    2    1    0]\n",
      " [   0 1116    2    2    0    1    3    3    8    0]\n",
      " [   5    3  988    5    9    1    3   12    5    1]\n",
      " [   0    0    8  977    0    4    1    9    5    6]\n",
      " [   1    1    4    0  945    0    7    2    2   20]\n",
      " [   9    1    1   19    5  830    9    2    9    7]\n",
      " [  10    3    4    1   10    9  918    0    3    0]\n",
      " [   0    7   17    2    2    1    0  984    2   13]\n",
      " [   3    2    4   18    6    6    9    6  916    4]\n",
      " [   7    6    2   12   17    3    1    9    2  950]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 1.4661 - acc: 0.6167 - val_loss: 0.6402 - val_acc: 0.8377\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.5009 - acc: 0.8655 - val_loss: 0.3944 - val_acc: 0.8891\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.3714 - acc: 0.8952 - val_loss: 0.3277 - val_acc: 0.9062\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.3205 - acc: 0.9081 - val_loss: 0.2883 - val_acc: 0.9164\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2890 - acc: 0.9180 - val_loss: 0.2654 - val_acc: 0.9229\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2654 - acc: 0.9231 - val_loss: 0.2470 - val_acc: 0.9282\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.2471 - acc: 0.9289 - val_loss: 0.2371 - val_acc: 0.9315\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.2312 - acc: 0.9335 - val_loss: 0.2227 - val_acc: 0.9374\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.2173 - acc: 0.9382 - val_loss: 0.2088 - val_acc: 0.9404\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2054 - acc: 0.9411 - val_loss: 0.1985 - val_acc: 0.9417\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1944 - acc: 0.9439 - val_loss: 0.1888 - val_acc: 0.9459\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1851 - acc: 0.9464 - val_loss: 0.1801 - val_acc: 0.9475\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1764 - acc: 0.9487 - val_loss: 0.1736 - val_acc: 0.9483\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1680 - acc: 0.9514 - val_loss: 0.1690 - val_acc: 0.9495\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1607 - acc: 0.9536 - val_loss: 0.1656 - val_acc: 0.9522\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1540 - acc: 0.9558 - val_loss: 0.1559 - val_acc: 0.9543\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1478 - acc: 0.9574 - val_loss: 0.1508 - val_acc: 0.9564\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1420 - acc: 0.9590 - val_loss: 0.1460 - val_acc: 0.9574\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1367 - acc: 0.9611 - val_loss: 0.1442 - val_acc: 0.9575\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1317 - acc: 0.9625 - val_loss: 0.1412 - val_acc: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291100a92e8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291100a9780>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291100a9c18>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911011e748>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911011e898>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29110126208>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.94      0.97      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.93      0.95      0.94       974\n",
      "           9       0.97      0.93      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    0    1    1    3    5    3    3    0]\n",
      " [   0 1109    2    2    1    1    5    2   13    0]\n",
      " [   8    1  982    7    7    1    6    8   12    0]\n",
      " [   0    0    3  969    0   12    1    9   16    0]\n",
      " [   1    0    5    0  954    0    6    2    2   12]\n",
      " [   8    1    0   15    3  842    7    0   11    5]\n",
      " [   8    3    1    0   10    8  921    0    7    0]\n",
      " [   1   10   14   10    4    2    0  977    2    8]\n",
      " [   4    1    2   13    6    7    7    6  926    2]\n",
      " [   7    7    1   13   25    2    1    7    8  938]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 1.3895 - acc: 0.6332 - val_loss: 0.5996 - val_acc: 0.8455\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4761 - acc: 0.8702 - val_loss: 0.3799 - val_acc: 0.8915\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.3611 - acc: 0.8962 - val_loss: 0.3194 - val_acc: 0.9080\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.3151 - acc: 0.9087 - val_loss: 0.2897 - val_acc: 0.9143\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.2847 - acc: 0.9175 - val_loss: 0.2636 - val_acc: 0.9221\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2625 - acc: 0.9239 - val_loss: 0.2483 - val_acc: 0.9260\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2442 - acc: 0.9293 - val_loss: 0.2289 - val_acc: 0.9332\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.2290 - acc: 0.9338 - val_loss: 0.2155 - val_acc: 0.9358\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2155 - acc: 0.9372 - val_loss: 0.2064 - val_acc: 0.9394\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2037 - acc: 0.9412 - val_loss: 0.1948 - val_acc: 0.9414\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1934 - acc: 0.9446 - val_loss: 0.1874 - val_acc: 0.9447\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.1841 - acc: 0.9478 - val_loss: 0.1776 - val_acc: 0.9468\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.1758 - acc: 0.9499 - val_loss: 0.1706 - val_acc: 0.9500\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1679 - acc: 0.9523 - val_loss: 0.1650 - val_acc: 0.9502\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.1611 - acc: 0.9538 - val_loss: 0.1611 - val_acc: 0.9524\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1547 - acc: 0.9562 - val_loss: 0.1540 - val_acc: 0.9543\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.1487 - acc: 0.9577 - val_loss: 0.1497 - val_acc: 0.9554\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1433 - acc: 0.9591 - val_loss: 0.1451 - val_acc: 0.9561\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1381 - acc: 0.9610 - val_loss: 0.1401 - val_acc: 0.9570\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1332 - acc: 0.9623 - val_loss: 0.1348 - val_acc: 0.9595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911046f048>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911046f4e0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2911044ca20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291104d7fd0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291104e1160>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291104e1ac8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.96      0.96      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.97      0.95      0.96       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    0    1    0    3    8    1    3    1]\n",
      " [   0 1119    3    1    0    1    5    2    4    0]\n",
      " [   7    3  988    6    2    0    9    8    8    1]\n",
      " [   0    2   10  969    1    7    0    9    9    3]\n",
      " [   1    0    5    0  937    0   10    2    2   25]\n",
      " [   9    2    0   11    1  843   11    0   11    4]\n",
      " [   7    3    0    0    8    8  928    0    4    0]\n",
      " [   2    9   15    5    3    2    0  976    2   14]\n",
      " [   3    2    3   16    4    5   10    5  921    5]\n",
      " [   5    8    1    9   20    3    1    7    4  951]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 1.4527 - acc: 0.6341 - val_loss: 0.6302 - val_acc: 0.8460\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.4885 - acc: 0.8687 - val_loss: 0.3837 - val_acc: 0.8926\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.3659 - acc: 0.8956 - val_loss: 0.3313 - val_acc: 0.9029\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.3205 - acc: 0.9081 - val_loss: 0.2949 - val_acc: 0.9138\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2928 - acc: 0.9160 - val_loss: 0.2727 - val_acc: 0.9217\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2728 - acc: 0.9217 - val_loss: 0.2520 - val_acc: 0.9268\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2556 - acc: 0.9266 - val_loss: 0.2450 - val_acc: 0.9302\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2417 - acc: 0.9304 - val_loss: 0.2266 - val_acc: 0.9355\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2287 - acc: 0.9333 - val_loss: 0.2183 - val_acc: 0.9353\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2170 - acc: 0.9371 - val_loss: 0.2058 - val_acc: 0.9406\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2061 - acc: 0.9405 - val_loss: 0.1951 - val_acc: 0.9427\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1962 - acc: 0.9432 - val_loss: 0.1924 - val_acc: 0.9435\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1868 - acc: 0.9453 - val_loss: 0.1837 - val_acc: 0.9444\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1789 - acc: 0.9481 - val_loss: 0.1724 - val_acc: 0.9496\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1707 - acc: 0.9509 - val_loss: 0.1719 - val_acc: 0.9478\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1638 - acc: 0.9522 - val_loss: 0.1594 - val_acc: 0.9528\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1570 - acc: 0.9543 - val_loss: 0.1543 - val_acc: 0.9536\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1507 - acc: 0.9566 - val_loss: 0.1488 - val_acc: 0.9555\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1451 - acc: 0.9586 - val_loss: 0.1427 - val_acc: 0.9575\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1399 - acc: 0.9595 - val_loss: 0.1392 - val_acc: 0.9586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29110821898>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29110821d30>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291108042b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911eb9c860>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911eb9c9b0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2911eb8c278>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.96      0.93      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.95      0.96      0.96      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.96      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    1    2    1    3    5    1    1    1]\n",
      " [   0 1114    3    2    0    1    3    3    9    0]\n",
      " [   7    1  985    6    8    1    5   10    8    1]\n",
      " [   1    2   12  960    0    8    0   14    9    4]\n",
      " [   1    0    6    0  945    0    7    2    3   18]\n",
      " [  10    2    1   18    2  834   10    0   10    5]\n",
      " [   8    3    2    0    8   10  924    0    3    0]\n",
      " [   0    8   14    4    2    1    0  988    1   10]\n",
      " [   4    1    2   12    6    4    7    9  927    2]\n",
      " [   5    7    0    9   21    5    1   12    5  944]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 1.3854 - acc: 0.6526 - val_loss: 0.5856 - val_acc: 0.8498\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.4698 - acc: 0.8710 - val_loss: 0.3786 - val_acc: 0.8898\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3595 - acc: 0.8970 - val_loss: 0.3190 - val_acc: 0.9068\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.3145 - acc: 0.9097 - val_loss: 0.2871 - val_acc: 0.9161\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.2850 - acc: 0.9176 - val_loss: 0.2652 - val_acc: 0.9234\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.2628 - acc: 0.9241 - val_loss: 0.2444 - val_acc: 0.9286\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.2445 - acc: 0.9291 - val_loss: 0.2293 - val_acc: 0.9347\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2293 - acc: 0.9327 - val_loss: 0.2145 - val_acc: 0.9375\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.2160 - acc: 0.9376 - val_loss: 0.2029 - val_acc: 0.9397\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.2044 - acc: 0.9409 - val_loss: 0.1946 - val_acc: 0.9433\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1942 - acc: 0.9443 - val_loss: 0.1860 - val_acc: 0.9458\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1848 - acc: 0.9474 - val_loss: 0.1799 - val_acc: 0.9464\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1767 - acc: 0.9491 - val_loss: 0.1704 - val_acc: 0.9492\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1686 - acc: 0.9513 - val_loss: 0.1667 - val_acc: 0.9492\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1619 - acc: 0.9531 - val_loss: 0.1579 - val_acc: 0.9530\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1551 - acc: 0.9551 - val_loss: 0.1540 - val_acc: 0.9547\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1489 - acc: 0.9570 - val_loss: 0.1490 - val_acc: 0.9551\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1435 - acc: 0.9585 - val_loss: 0.1441 - val_acc: 0.9563\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1380 - acc: 0.9602 - val_loss: 0.1405 - val_acc: 0.9579\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1330 - acc: 0.9612 - val_loss: 0.1365 - val_acc: 0.9591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911eee8128>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911eee85c0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2911eee8b70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911ff2f0f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911ff2f240>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2911ff17ac8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.93      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.95      0.94      0.94       892\n",
      "           6       0.97      0.96      0.96       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.96      0.95      0.95       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 964    0    0    1    0    3    7    2    3    0]\n",
      " [   0 1120    2    2    0    2    2    1    6    0]\n",
      " [   5    2  995    9    3    1    3    9    4    1]\n",
      " [   0    0    6  974    1   13    0    5   10    1]\n",
      " [   1    0    6    0  945    0    7    2    4   17]\n",
      " [   8    1    2   19    2  839    9    1    7    4]\n",
      " [   8    3    4    0   10   13  918    0    2    0]\n",
      " [   1    7   14    5    3    2    0  977    2   17]\n",
      " [   4    2    2   18    5    7    4    7  921    4]\n",
      " [   6    7    1   17   22    6    1    7    4  938]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 1.4179 - acc: 0.6415 - val_loss: 0.6156 - val_acc: 0.8457\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.4900 - acc: 0.8670 - val_loss: 0.3870 - val_acc: 0.8906\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3709 - acc: 0.8945 - val_loss: 0.3305 - val_acc: 0.9054\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.3247 - acc: 0.9060 - val_loss: 0.2975 - val_acc: 0.9132\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2958 - acc: 0.9144 - val_loss: 0.2752 - val_acc: 0.9186\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2737 - acc: 0.9205 - val_loss: 0.2584 - val_acc: 0.9248\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2560 - acc: 0.9254 - val_loss: 0.2472 - val_acc: 0.9278\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2408 - acc: 0.9302 - val_loss: 0.2311 - val_acc: 0.9326\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2272 - acc: 0.9341 - val_loss: 0.2215 - val_acc: 0.9361\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2147 - acc: 0.9378 - val_loss: 0.2086 - val_acc: 0.9384\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2046 - acc: 0.9405 - val_loss: 0.1999 - val_acc: 0.9397\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1944 - acc: 0.9442 - val_loss: 0.1916 - val_acc: 0.9429\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1855 - acc: 0.9460 - val_loss: 0.1815 - val_acc: 0.9455\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1775 - acc: 0.9484 - val_loss: 0.1753 - val_acc: 0.9482\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1699 - acc: 0.9507 - val_loss: 0.1716 - val_acc: 0.9480\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1630 - acc: 0.9528 - val_loss: 0.1651 - val_acc: 0.9511\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1568 - acc: 0.9544 - val_loss: 0.1580 - val_acc: 0.9529\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1505 - acc: 0.9564 - val_loss: 0.1530 - val_acc: 0.9537\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1452 - acc: 0.9575 - val_loss: 0.1552 - val_acc: 0.9544\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1397 - acc: 0.9595 - val_loss: 0.1441 - val_acc: 0.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912026c978>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912026ce10>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912025c390>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291212b7940>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291212b7ef0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29121253358>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.95      0.95      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.97      0.94      0.95      1028\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    3    1    3    6    1    1    1]\n",
      " [   0 1114    4    2    1    1    4    1    8    0]\n",
      " [  11    1  982    6    9    0    6    9    7    1]\n",
      " [   1    1    7  961    0   12    1    9   12    6]\n",
      " [   1    0    7    0  941    0    7    3    3   20]\n",
      " [  10    1    2   12    2  838   11    0   10    6]\n",
      " [  10    3    1    0    8    7  924    0    5    0]\n",
      " [   0    9   20    2    4    1    0  971    2   19]\n",
      " [   5    1    3   13    5    8    9    4  919    7]\n",
      " [   5    6    2    8   23    6    1    8    6  944]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 1.3790 - acc: 0.6620 - val_loss: 0.5962 - val_acc: 0.8515\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.4797 - acc: 0.8709 - val_loss: 0.3864 - val_acc: 0.8922\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.3674 - acc: 0.8944 - val_loss: 0.3286 - val_acc: 0.9069\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.3213 - acc: 0.9070 - val_loss: 0.2919 - val_acc: 0.9169\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.2917 - acc: 0.9152 - val_loss: 0.2674 - val_acc: 0.9229\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2695 - acc: 0.9221 - val_loss: 0.2609 - val_acc: 0.9232\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.2517 - acc: 0.9269 - val_loss: 0.2410 - val_acc: 0.9285\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2368 - acc: 0.9317 - val_loss: 0.2230 - val_acc: 0.9358\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.2238 - acc: 0.9354 - val_loss: 0.2166 - val_acc: 0.9382\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2119 - acc: 0.9385 - val_loss: 0.2052 - val_acc: 0.9385\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2019 - acc: 0.9418 - val_loss: 0.1941 - val_acc: 0.9435\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1924 - acc: 0.9446 - val_loss: 0.1880 - val_acc: 0.9436\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1844 - acc: 0.9474 - val_loss: 0.1800 - val_acc: 0.9473\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1764 - acc: 0.9496 - val_loss: 0.1782 - val_acc: 0.9477\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1695 - acc: 0.9514 - val_loss: 0.1682 - val_acc: 0.9520\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1625 - acc: 0.9540 - val_loss: 0.1626 - val_acc: 0.9524\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1564 - acc: 0.9556 - val_loss: 0.1586 - val_acc: 0.9539\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1506 - acc: 0.9569 - val_loss: 0.1537 - val_acc: 0.9559\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1456 - acc: 0.9583 - val_loss: 0.1483 - val_acc: 0.9563\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1405 - acc: 0.9608 - val_loss: 0.1433 - val_acc: 0.9585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291215fb208>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291215fb6a0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291215fba20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912264b1d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912264b320>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29122633ba8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.97      0.93      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    1    0    4    6    1    3    1]\n",
      " [   0 1118    2    2    1    1    5    2    4    0]\n",
      " [   6    1  989    9    5    0    5    9    8    0]\n",
      " [   0    1    7  970    0    8    1   10    8    5]\n",
      " [   1    0    3    1  937    0    9    2    2   27]\n",
      " [   7    1    0   20    1  834   12    1   10    6]\n",
      " [   7    3    1    2    7    9  926    0    3    0]\n",
      " [   0    7   17    4    2    1    0  979    0   18]\n",
      " [   3    2    3   16    7    4   10    9  916    4]\n",
      " [   5    6    2   10   17    3    1    7    5  953]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.4622 - acc: 0.6274 - val_loss: 0.6542 - val_acc: 0.8303\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.4997 - acc: 0.8640 - val_loss: 0.3863 - val_acc: 0.8946\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.3670 - acc: 0.8959 - val_loss: 0.3264 - val_acc: 0.9066\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.3197 - acc: 0.9077 - val_loss: 0.2949 - val_acc: 0.9155\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2910 - acc: 0.9165 - val_loss: 0.2684 - val_acc: 0.9235\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2694 - acc: 0.9223 - val_loss: 0.2520 - val_acc: 0.9275\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2517 - acc: 0.9279 - val_loss: 0.2350 - val_acc: 0.9330\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2369 - acc: 0.9317 - val_loss: 0.2254 - val_acc: 0.9347\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2237 - acc: 0.9350 - val_loss: 0.2123 - val_acc: 0.9383\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2122 - acc: 0.9389 - val_loss: 0.2024 - val_acc: 0.9409\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.2013 - acc: 0.9415 - val_loss: 0.1935 - val_acc: 0.9423\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1916 - acc: 0.9446 - val_loss: 0.1863 - val_acc: 0.9440\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1830 - acc: 0.9471 - val_loss: 0.1761 - val_acc: 0.9483\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1749 - acc: 0.9491 - val_loss: 0.1704 - val_acc: 0.9505\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1676 - acc: 0.9515 - val_loss: 0.1643 - val_acc: 0.9530\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1610 - acc: 0.9537 - val_loss: 0.1590 - val_acc: 0.9537\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1547 - acc: 0.9552 - val_loss: 0.1606 - val_acc: 0.9526\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1488 - acc: 0.9570 - val_loss: 0.1506 - val_acc: 0.9563\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1435 - acc: 0.9583 - val_loss: 0.1478 - val_acc: 0.9570\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1385 - acc: 0.9600 - val_loss: 0.1475 - val_acc: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912298ba58>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912298bef0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912299c4a8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29122a03a20>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29122a03fd0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291229f3438>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.97      0.93      0.95       892\n",
      "           6       0.94      0.97      0.95       958\n",
      "           7       0.95      0.96      0.96      1028\n",
      "           8       0.97      0.91      0.94       974\n",
      "           9       0.94      0.95      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    0    2    0    4    7    1    1    0]\n",
      " [   0 1116    2    2    1    1    6    2    5    0]\n",
      " [  10    1  982    6    7    1   10   11    3    1]\n",
      " [   1    0   10  971    0    9    0   11    2    6]\n",
      " [   1    0    5    0  934    0   13    2    2   25]\n",
      " [   9    1    0   18    3  832   12    3    8    6]\n",
      " [   9    3    0    1    5    6  931    1    2    0]\n",
      " [   0    9   14    1    3    1    0  986    0   14]\n",
      " [   8    2    4   17    8    7   15    9  890   14]\n",
      " [   6    6    0    8   21    1    0    7    3  957]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 1.5281 - acc: 0.6049 - val_loss: 0.6706 - val_acc: 0.8357\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.5064 - acc: 0.8654 - val_loss: 0.3961 - val_acc: 0.8893\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.3733 - acc: 0.8936 - val_loss: 0.3304 - val_acc: 0.9061\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.3269 - acc: 0.9050 - val_loss: 0.2992 - val_acc: 0.9109\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2983 - acc: 0.9131 - val_loss: 0.2754 - val_acc: 0.9221\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2765 - acc: 0.9206 - val_loss: 0.2593 - val_acc: 0.9256\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2588 - acc: 0.9250 - val_loss: 0.2417 - val_acc: 0.9324\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2428 - acc: 0.9293 - val_loss: 0.2310 - val_acc: 0.9341\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2291 - acc: 0.9335 - val_loss: 0.2189 - val_acc: 0.9382\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2164 - acc: 0.9375 - val_loss: 0.2057 - val_acc: 0.9413\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.2055 - acc: 0.9406 - val_loss: 0.1969 - val_acc: 0.9435\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1957 - acc: 0.9436 - val_loss: 0.1878 - val_acc: 0.9444\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1862 - acc: 0.9470 - val_loss: 0.1812 - val_acc: 0.9488\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1776 - acc: 0.9487 - val_loss: 0.1749 - val_acc: 0.9500\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1697 - acc: 0.9508 - val_loss: 0.1688 - val_acc: 0.9523\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1626 - acc: 0.9532 - val_loss: 0.1628 - val_acc: 0.9542\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1560 - acc: 0.9547 - val_loss: 0.1559 - val_acc: 0.9549\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1496 - acc: 0.9571 - val_loss: 0.1513 - val_acc: 0.9565\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1439 - acc: 0.9581 - val_loss: 0.1476 - val_acc: 0.9574\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1386 - acc: 0.9600 - val_loss: 0.1405 - val_acc: 0.9589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29123cf1f28>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29123d0b400>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29123d0b9b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29123d97438>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29123d97588>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29123d97e80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.94      0.96      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.96      0.93      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    1    0    4    8    1    1    1]\n",
      " [   0 1118    2    2    0    1    5    2    5    0]\n",
      " [   6    1  993    8    6    1    4    9    4    0]\n",
      " [   0    0    9  974    0   10    0    8    8    1]\n",
      " [   1    0    5    0  944    0    9    2    2   19]\n",
      " [   8    1    0   19    2  838   10    1    8    5]\n",
      " [   8    3    3    1    8    8  924    0    3    0]\n",
      " [   1    9   17    3    4    2    0  980    0   12]\n",
      " [   3    2    5   16   10    9    8    7  912    2]\n",
      " [   5    7    2   12   25    3    1    5    6  943]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 1.5115 - acc: 0.6175 - val_loss: 0.6448 - val_acc: 0.8384\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.4938 - acc: 0.8676 - val_loss: 0.3903 - val_acc: 0.8908\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.3701 - acc: 0.8957 - val_loss: 0.3256 - val_acc: 0.9060\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.3248 - acc: 0.9071 - val_loss: 0.2964 - val_acc: 0.9132\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2968 - acc: 0.9140 - val_loss: 0.2753 - val_acc: 0.9191\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2752 - acc: 0.9208 - val_loss: 0.2599 - val_acc: 0.9244\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2573 - acc: 0.9258 - val_loss: 0.2435 - val_acc: 0.9302\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2422 - acc: 0.9306 - val_loss: 0.2337 - val_acc: 0.9308\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2287 - acc: 0.9339 - val_loss: 0.2194 - val_acc: 0.9364\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.2168 - acc: 0.9372 - val_loss: 0.2093 - val_acc: 0.9404\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2065 - acc: 0.9404 - val_loss: 0.2002 - val_acc: 0.9433\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1961 - acc: 0.9432 - val_loss: 0.1904 - val_acc: 0.9444\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1875 - acc: 0.9460 - val_loss: 0.1841 - val_acc: 0.9458\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1793 - acc: 0.9478 - val_loss: 0.1780 - val_acc: 0.9468\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1719 - acc: 0.9508 - val_loss: 0.1706 - val_acc: 0.9508\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1648 - acc: 0.9523 - val_loss: 0.1643 - val_acc: 0.9518\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1586 - acc: 0.9539 - val_loss: 0.1591 - val_acc: 0.9536\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.1520 - acc: 0.9561 - val_loss: 0.1562 - val_acc: 0.9536\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1469 - acc: 0.9576 - val_loss: 0.1497 - val_acc: 0.9561\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1414 - acc: 0.9590 - val_loss: 0.1442 - val_acc: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291240d5dd8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291240e6320>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291240c67f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29125124e80>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912512f400>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912512f978>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.97      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.95      0.94      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    2    0    6    5    2    1    0]\n",
      " [   0 1116    2    2    0    2    4    3    6    0]\n",
      " [   7    1  996    7    6    0    3    7    4    1]\n",
      " [   0    1    6  969    0   13    0    9   10    2]\n",
      " [   1    0    4    0  944    0    8    4    2   19]\n",
      " [   7    3    1   17    4  837    9    2    7    5]\n",
      " [   8    3    2    0    7    9  923    1    5    0]\n",
      " [   1    8   15    7    2    2    0  980    0   13]\n",
      " [   4    1    7   16    7    3   10    9  915    2]\n",
      " [   6    6    1   12   25    6    1   11    2  939]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 1.3528 - acc: 0.6820 - val_loss: 0.5933 - val_acc: 0.8463\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.4757 - acc: 0.8707 - val_loss: 0.3776 - val_acc: 0.8934\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.3599 - acc: 0.8979 - val_loss: 0.3208 - val_acc: 0.9076\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.3146 - acc: 0.9100 - val_loss: 0.2864 - val_acc: 0.9189\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2863 - acc: 0.9176 - val_loss: 0.2668 - val_acc: 0.9240\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2652 - acc: 0.9241 - val_loss: 0.2495 - val_acc: 0.9274\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2480 - acc: 0.9284 - val_loss: 0.2344 - val_acc: 0.9313\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2337 - acc: 0.9325 - val_loss: 0.2231 - val_acc: 0.9335\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2208 - acc: 0.9360 - val_loss: 0.2124 - val_acc: 0.9373\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.2098 - acc: 0.9396 - val_loss: 0.2018 - val_acc: 0.9399\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1996 - acc: 0.9419 - val_loss: 0.1931 - val_acc: 0.9433\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1897 - acc: 0.9450 - val_loss: 0.1828 - val_acc: 0.9462\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1810 - acc: 0.9479 - val_loss: 0.1789 - val_acc: 0.9468\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1732 - acc: 0.9502 - val_loss: 0.1707 - val_acc: 0.9490\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1657 - acc: 0.9523 - val_loss: 0.1668 - val_acc: 0.9496\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1588 - acc: 0.9544 - val_loss: 0.1599 - val_acc: 0.9529\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1523 - acc: 0.9561 - val_loss: 0.1558 - val_acc: 0.9537\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1464 - acc: 0.9577 - val_loss: 0.1478 - val_acc: 0.9548\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1409 - acc: 0.9597 - val_loss: 0.1442 - val_acc: 0.9570\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1356 - acc: 0.9612 - val_loss: 0.1386 - val_acc: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29125468748>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29125468be0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29125459240>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291264b6278>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291264b67b8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912649fc50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.96      0.96      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.95      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 960    0    0    2    0    6    8    2    1    1]\n",
      " [   0 1121    3    2    0    1    2    2    4    0]\n",
      " [   3    3  991    5    4    1    6   10    8    1]\n",
      " [   0    2    9  974    1    5    0   10    7    2]\n",
      " [   1    0    7    0  940    0    7    3    2   22]\n",
      " [   6    3    0   15    0  841   12    1    7    7]\n",
      " [   7    3    1    0    5   15  922    1    4    0]\n",
      " [   1   13   13    4    2    1    0  978    1   15]\n",
      " [   3    2    3   15    6    8    7    7  920    3]\n",
      " [   7    8    2   10   18    2    1    7    4  950]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 1.4213 - acc: 0.6335 - val_loss: 0.6207 - val_acc: 0.8417\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.4945 - acc: 0.8668 - val_loss: 0.3905 - val_acc: 0.8901\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.3710 - acc: 0.8949 - val_loss: 0.3232 - val_acc: 0.9089\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.3236 - acc: 0.9077 - val_loss: 0.2909 - val_acc: 0.9173\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.2938 - acc: 0.9159 - val_loss: 0.2700 - val_acc: 0.9233\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2721 - acc: 0.9214 - val_loss: 0.2533 - val_acc: 0.9267\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2541 - acc: 0.9267 - val_loss: 0.2384 - val_acc: 0.9320\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.2391 - acc: 0.9308 - val_loss: 0.2261 - val_acc: 0.9341\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2258 - acc: 0.9355 - val_loss: 0.2146 - val_acc: 0.9363\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2139 - acc: 0.9382 - val_loss: 0.2048 - val_acc: 0.9373\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.2031 - acc: 0.9417 - val_loss: 0.1947 - val_acc: 0.9427\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1935 - acc: 0.9445 - val_loss: 0.1871 - val_acc: 0.9443\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1843 - acc: 0.9464 - val_loss: 0.1791 - val_acc: 0.9466\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1768 - acc: 0.9488 - val_loss: 0.1741 - val_acc: 0.9476\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1692 - acc: 0.9510 - val_loss: 0.1668 - val_acc: 0.9491\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1624 - acc: 0.9528 - val_loss: 0.1606 - val_acc: 0.9510\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.1560 - acc: 0.9548 - val_loss: 0.1562 - val_acc: 0.9520\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.1502 - acc: 0.9566 - val_loss: 0.1519 - val_acc: 0.9535\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1445 - acc: 0.9585 - val_loss: 0.1447 - val_acc: 0.9553\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1396 - acc: 0.9593 - val_loss: 0.1413 - val_acc: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291267f1ac8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291267f1f60>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291267df5c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29126871a90>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29126871f28>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29126863588>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.94      0.95      0.94       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    2    0    6    3    2    3    0]\n",
      " [   0 1119    2    2    0    1    3    1    7    0]\n",
      " [   3    2  987    9    4    2    4    9   11    1]\n",
      " [   0    1   10  965    0   15    0    8   11    0]\n",
      " [   1    2    5    0  930    0    7    2    5   30]\n",
      " [   7    1    1   11    1  845   11    0   10    5]\n",
      " [   9    3    2    1    7   10  920    1    5    0]\n",
      " [   1   10   15    6    2    1    0  975    2   16]\n",
      " [   4    1    3   16    4    8    6    8  922    2]\n",
      " [   5    8    1    9   17    4    1   10    9  945]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 1.3880 - acc: 0.6625 - val_loss: 0.5867 - val_acc: 0.8594\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.4655 - acc: 0.8750 - val_loss: 0.3810 - val_acc: 0.8951\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.3607 - acc: 0.8986 - val_loss: 0.3288 - val_acc: 0.9061\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.3194 - acc: 0.9084 - val_loss: 0.2930 - val_acc: 0.9151\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.2933 - acc: 0.9158 - val_loss: 0.2716 - val_acc: 0.9223\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.2729 - acc: 0.9210 - val_loss: 0.2609 - val_acc: 0.9240\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2557 - acc: 0.9265 - val_loss: 0.2423 - val_acc: 0.9299\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2411 - acc: 0.9307 - val_loss: 0.2300 - val_acc: 0.9333\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2280 - acc: 0.9346 - val_loss: 0.2226 - val_acc: 0.9362\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.2159 - acc: 0.9380 - val_loss: 0.2058 - val_acc: 0.9407\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.2050 - acc: 0.9407 - val_loss: 0.1959 - val_acc: 0.9425\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1951 - acc: 0.9434 - val_loss: 0.1904 - val_acc: 0.9453\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.1864 - acc: 0.9462 - val_loss: 0.1815 - val_acc: 0.9461\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1781 - acc: 0.9484 - val_loss: 0.1773 - val_acc: 0.9476\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1703 - acc: 0.9509 - val_loss: 0.1661 - val_acc: 0.9506\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1636 - acc: 0.9524 - val_loss: 0.1613 - val_acc: 0.9507\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1566 - acc: 0.9539 - val_loss: 0.1563 - val_acc: 0.9533\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1512 - acc: 0.9561 - val_loss: 0.1496 - val_acc: 0.9555\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1458 - acc: 0.9575 - val_loss: 0.1451 - val_acc: 0.9569\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1405 - acc: 0.9590 - val_loss: 0.1434 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29126bb8358>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29126bb8898>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29126ba0e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29127c00320>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29127c00470>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29127c00c88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.94      0.96      0.95      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.97      0.93      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.95      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    1    2    0    3    3    3    2    0]\n",
      " [   0 1110    3    2    0    2    3    2   13    0]\n",
      " [   5    1  995    7    3    0    4   10    6    1]\n",
      " [   1    1   19  962    0    8    0    9    9    1]\n",
      " [   1    0    8    1  937    0    9    3    2   21]\n",
      " [  10    1    1   15    2  832   12    1   13    5]\n",
      " [   8    3    3    0    8    7  924    0    5    0]\n",
      " [   2    8   22    3    0    1    0  977    1   14]\n",
      " [   4    3    7   12    4    4   12    8  917    3]\n",
      " [   7    6    2    9   20    2    1   12    5  945]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 1.3756 - acc: 0.6655 - val_loss: 0.5984 - val_acc: 0.8584\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.4786 - acc: 0.8726 - val_loss: 0.3827 - val_acc: 0.8946\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.3670 - acc: 0.8965 - val_loss: 0.3331 - val_acc: 0.9050\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.3243 - acc: 0.9073 - val_loss: 0.2993 - val_acc: 0.9151\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.2973 - acc: 0.9144 - val_loss: 0.2755 - val_acc: 0.9208\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.2762 - acc: 0.9207 - val_loss: 0.2601 - val_acc: 0.9265\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.2591 - acc: 0.9261 - val_loss: 0.2466 - val_acc: 0.9296\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.2437 - acc: 0.9300 - val_loss: 0.2329 - val_acc: 0.9352\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2301 - acc: 0.9337 - val_loss: 0.2232 - val_acc: 0.9368\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2182 - acc: 0.9372 - val_loss: 0.2115 - val_acc: 0.9400\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.2074 - acc: 0.9395 - val_loss: 0.2030 - val_acc: 0.9412\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.1974 - acc: 0.9422 - val_loss: 0.1947 - val_acc: 0.9445\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.1882 - acc: 0.9452 - val_loss: 0.1868 - val_acc: 0.9463\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1795 - acc: 0.9480 - val_loss: 0.1786 - val_acc: 0.9480\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1717 - acc: 0.9504 - val_loss: 0.1712 - val_acc: 0.9499\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1640 - acc: 0.9522 - val_loss: 0.1658 - val_acc: 0.9511\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1574 - acc: 0.9544 - val_loss: 0.1639 - val_acc: 0.9531\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1515 - acc: 0.9559 - val_loss: 0.1582 - val_acc: 0.9533\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1455 - acc: 0.9575 - val_loss: 0.1529 - val_acc: 0.9565\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.1403 - acc: 0.9599 - val_loss: 0.1475 - val_acc: 0.9555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29127f44ba8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29127f530f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29127f345c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29128f8d6d8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29128f8dc88>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29128f97208>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.96      0.95      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.96      0.95      0.95       982\n",
      "           5       0.95      0.94      0.94       892\n",
      "           6       0.96      0.95      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.96      0.93      0.94       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.95      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 969    0    1    2    0    3    3    1    1    0]\n",
      " [   0 1116    3    2    0    1    3    2    8    0]\n",
      " [   7    1  993    7    4    0    3    8    7    2]\n",
      " [   0    0   13  968    0   12    0    9    5    3]\n",
      " [   2    0    7    0  928    0    7    2    2   34]\n",
      " [   7    2    1   14    2  840   10    1    9    6]\n",
      " [  13    3    4    1    7   13  912    2    3    0]\n",
      " [   1    7   20    5    3    2    0  973    0   17]\n",
      " [   7    3    5   11    6   13   12   10  904    3]\n",
      " [   8    6    2   11   17    3    0    8    2  952]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 1.4607 - acc: 0.6494 - val_loss: 0.6132 - val_acc: 0.8461\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.4785 - acc: 0.8726 - val_loss: 0.3835 - val_acc: 0.8935\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 0.3643 - acc: 0.8967 - val_loss: 0.3237 - val_acc: 0.9060\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.3209 - acc: 0.9083 - val_loss: 0.2929 - val_acc: 0.9153\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.2934 - acc: 0.9159 - val_loss: 0.2747 - val_acc: 0.9193\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2724 - acc: 0.9214 - val_loss: 0.2543 - val_acc: 0.9260\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2553 - acc: 0.9266 - val_loss: 0.2391 - val_acc: 0.9304\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.2406 - acc: 0.9311 - val_loss: 0.2283 - val_acc: 0.9328\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2269 - acc: 0.9349 - val_loss: 0.2163 - val_acc: 0.9349\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.2155 - acc: 0.9379 - val_loss: 0.2058 - val_acc: 0.9394\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2045 - acc: 0.9410 - val_loss: 0.1970 - val_acc: 0.9404\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1951 - acc: 0.9437 - val_loss: 0.1887 - val_acc: 0.9445\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1862 - acc: 0.9458 - val_loss: 0.1819 - val_acc: 0.9460\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1783 - acc: 0.9483 - val_loss: 0.1753 - val_acc: 0.9485\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1710 - acc: 0.9503 - val_loss: 0.1690 - val_acc: 0.9507\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1640 - acc: 0.9521 - val_loss: 0.1648 - val_acc: 0.9502\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1579 - acc: 0.9540 - val_loss: 0.1574 - val_acc: 0.9515\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.1518 - acc: 0.9556 - val_loss: 0.1531 - val_acc: 0.9536\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1463 - acc: 0.9579 - val_loss: 0.1514 - val_acc: 0.9554\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1409 - acc: 0.9588 - val_loss: 0.1426 - val_acc: 0.9566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29129415f28>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29129424400>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29129431a20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29129496ef0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912949f080>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291294869e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.96      0.94      0.95      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.95      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    0    0    0    4    5    2    2    1]\n",
      " [   0 1118    2    2    0    1    3    2    7    0]\n",
      " [   7    3  975   10    5    2    9    9   10    2]\n",
      " [   0    1    4  966    0   11    1   11   15    1]\n",
      " [   1    0    7    0  939    0    9    2    3   21]\n",
      " [   7    1    0   15    3  838   11    0   11    6]\n",
      " [   8    3    1    1    8   11  924    0    2    0]\n",
      " [   2   12   15    3    4    0    0  975    1   16]\n",
      " [   4    3    6   14    5    8    8    6  917    3]\n",
      " [   7    7    2    9   18    2    1   11    4  948]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 1.3891 - acc: 0.6466 - val_loss: 0.6242 - val_acc: 0.8416\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.4907 - acc: 0.8667 - val_loss: 0.3846 - val_acc: 0.8942\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.3687 - acc: 0.8946 - val_loss: 0.3223 - val_acc: 0.9087\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3239 - acc: 0.9071 - val_loss: 0.2933 - val_acc: 0.9163\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2970 - acc: 0.9154 - val_loss: 0.2759 - val_acc: 0.9229\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2768 - acc: 0.9206 - val_loss: 0.2586 - val_acc: 0.9272\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2601 - acc: 0.9252 - val_loss: 0.2442 - val_acc: 0.9321\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2460 - acc: 0.9294 - val_loss: 0.2351 - val_acc: 0.9323\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2336 - acc: 0.9328 - val_loss: 0.2215 - val_acc: 0.9349\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2221 - acc: 0.9366 - val_loss: 0.2149 - val_acc: 0.9402\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.2121 - acc: 0.9396 - val_loss: 0.2028 - val_acc: 0.9419\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2029 - acc: 0.9423 - val_loss: 0.2008 - val_acc: 0.9436\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1947 - acc: 0.9439 - val_loss: 0.1891 - val_acc: 0.9457\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1865 - acc: 0.9467 - val_loss: 0.1842 - val_acc: 0.9471\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1792 - acc: 0.9485 - val_loss: 0.1763 - val_acc: 0.9481\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1720 - acc: 0.9509 - val_loss: 0.1716 - val_acc: 0.9507\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1653 - acc: 0.9523 - val_loss: 0.1644 - val_acc: 0.9525\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1594 - acc: 0.9545 - val_loss: 0.1599 - val_acc: 0.9530\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1536 - acc: 0.9559 - val_loss: 0.1549 - val_acc: 0.9548\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1484 - acc: 0.9576 - val_loss: 0.1531 - val_acc: 0.9559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912a7c17b8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912a7c1c50>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912a7c1dd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912b80b780>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912b80bd30>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912b7fb198>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.94      0.95      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.96      0.95      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.93      0.95      0.94       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 958    0    0    2    1    5    5    4    3    2]\n",
      " [   0 1112    2    2    0    1    4    2   11    1]\n",
      " [   7    1  965   14    7    2    9    8   16    3]\n",
      " [   1    0    5  971    0   11    0    4   13    5]\n",
      " [   1    0    4    0  934    1    9    2    5   26]\n",
      " [   7    1    1   12    2  850    7    0    6    6]\n",
      " [   6    3    2    0    8   11  922    0    6    0]\n",
      " [   1    7   16    8    3    1    0  969    3   20]\n",
      " [   3    1    2   18    4    5    8    4  928    1]\n",
      " [   5    7    2    8   15    8    1    6    7  950]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 1.3969 - acc: 0.6618 - val_loss: 0.6046 - val_acc: 0.8487\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.4818 - acc: 0.8703 - val_loss: 0.3797 - val_acc: 0.8918\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.3655 - acc: 0.8977 - val_loss: 0.3207 - val_acc: 0.9072\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.3220 - acc: 0.9080 - val_loss: 0.2960 - val_acc: 0.9153\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.2955 - acc: 0.9149 - val_loss: 0.2764 - val_acc: 0.9202\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2751 - acc: 0.9208 - val_loss: 0.2598 - val_acc: 0.9240\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2589 - acc: 0.9257 - val_loss: 0.2421 - val_acc: 0.9300\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.2439 - acc: 0.9306 - val_loss: 0.2334 - val_acc: 0.9329\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.2307 - acc: 0.9335 - val_loss: 0.2179 - val_acc: 0.9357\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2192 - acc: 0.9373 - val_loss: 0.2093 - val_acc: 0.9374\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.2088 - acc: 0.9393 - val_loss: 0.2020 - val_acc: 0.9412\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1991 - acc: 0.9428 - val_loss: 0.1923 - val_acc: 0.9433\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1902 - acc: 0.9453 - val_loss: 0.1856 - val_acc: 0.9459\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1822 - acc: 0.9476 - val_loss: 0.1770 - val_acc: 0.9477\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1743 - acc: 0.9493 - val_loss: 0.1709 - val_acc: 0.9496\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1672 - acc: 0.9518 - val_loss: 0.1652 - val_acc: 0.9521\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1605 - acc: 0.9538 - val_loss: 0.1596 - val_acc: 0.9527\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1545 - acc: 0.9557 - val_loss: 0.1570 - val_acc: 0.9529\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1486 - acc: 0.9569 - val_loss: 0.1536 - val_acc: 0.9552\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.1432 - acc: 0.9587 - val_loss: 0.1465 - val_acc: 0.9555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912bb5d048>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912bb5d4e0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912bb3ca20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912bbc5fd0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912bbce160>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912bbb69e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.95      0.95      1032\n",
      "           3       0.96      0.94      0.95      1010\n",
      "           4       0.94      0.97      0.95       982\n",
      "           5       0.94      0.94      0.94       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.94      0.95      0.95       974\n",
      "           9       0.97      0.92      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.95     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 965    0    0    0    0    6    5    2    2    0]\n",
      " [   0 1116    2    2    0    1    4    2    8    0]\n",
      " [   8    2  982    6    6    2    8   10    8    0]\n",
      " [   0    1   12  951    0   18    1   12   14    1]\n",
      " [   1    0    4    0  949    1    8    2    3   14]\n",
      " [   9    1    1   13    4  841   11    0    8    4]\n",
      " [   8    3    3    0    6   10  923    1    4    0]\n",
      " [   3   10   20    3    3    0    0  979    1    9]\n",
      " [   4    1    4   10    7    5   12    7  923    1]\n",
      " [  10    7    1    8   35    7    1    7    7  926]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 1.4493 - acc: 0.6395 - val_loss: 0.6072 - val_acc: 0.8585\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.4809 - acc: 0.8722 - val_loss: 0.3798 - val_acc: 0.8971\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3665 - acc: 0.8964 - val_loss: 0.3252 - val_acc: 0.9064\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.3221 - acc: 0.9068 - val_loss: 0.2894 - val_acc: 0.9182\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.2950 - acc: 0.9151 - val_loss: 0.2744 - val_acc: 0.9228\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2741 - acc: 0.9204 - val_loss: 0.2548 - val_acc: 0.9258\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.2571 - acc: 0.9258 - val_loss: 0.2393 - val_acc: 0.9315\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2422 - acc: 0.9304 - val_loss: 0.2272 - val_acc: 0.9354\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.2293 - acc: 0.9343 - val_loss: 0.2212 - val_acc: 0.9366\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2174 - acc: 0.9369 - val_loss: 0.2115 - val_acc: 0.9381\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2068 - acc: 0.9403 - val_loss: 0.1981 - val_acc: 0.9427\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1970 - acc: 0.9435 - val_loss: 0.1910 - val_acc: 0.9446\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.1881 - acc: 0.9459 - val_loss: 0.1825 - val_acc: 0.9465\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1802 - acc: 0.9485 - val_loss: 0.1772 - val_acc: 0.9483\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1728 - acc: 0.9504 - val_loss: 0.1715 - val_acc: 0.9496\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1661 - acc: 0.9528 - val_loss: 0.1682 - val_acc: 0.9509\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1597 - acc: 0.9537 - val_loss: 0.1618 - val_acc: 0.9530\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1535 - acc: 0.9551 - val_loss: 0.1589 - val_acc: 0.9522\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1481 - acc: 0.9572 - val_loss: 0.1520 - val_acc: 0.9548\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1430 - acc: 0.9586 - val_loss: 0.1448 - val_acc: 0.9573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29122d11dd8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912bf053c8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912baff240>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912cf3e5f8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912cf3e748>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912cf27d68>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.93      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.96      0.93      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.95      0.94      0.94       974\n",
      "           9       0.96      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 959    0    1    2    1    4    7    2    2    2]\n",
      " [   0 1115    2    2    0    1    5    2    8    0]\n",
      " [   6    2  986   11    6    1    2    8    8    2]\n",
      " [   1    0    9  971    0    8    0   10    9    2]\n",
      " [   1    0    7    1  947    0    5    1    4   16]\n",
      " [   8    1    1   17    1  830   12    2   14    6]\n",
      " [   7    3    3    1    8   10  924    0    2    0]\n",
      " [   1   10   16    8    6    1    0  975    1   10]\n",
      " [   3    1    3   18    7    6   10    4  919    3]\n",
      " [   3    6    2   11   25    1    1    8    5  947]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 1.4588 - acc: 0.6332 - val_loss: 0.6409 - val_acc: 0.8446\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.4993 - acc: 0.8650 - val_loss: 0.3931 - val_acc: 0.8892\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.3741 - acc: 0.8941 - val_loss: 0.3331 - val_acc: 0.9034\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.3269 - acc: 0.9057 - val_loss: 0.2998 - val_acc: 0.9149\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.2968 - acc: 0.9144 - val_loss: 0.2756 - val_acc: 0.9187\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.2746 - acc: 0.9211 - val_loss: 0.2546 - val_acc: 0.9264\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2561 - acc: 0.9266 - val_loss: 0.2394 - val_acc: 0.9306\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2407 - acc: 0.9303 - val_loss: 0.2301 - val_acc: 0.9320\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2267 - acc: 0.9346 - val_loss: 0.2177 - val_acc: 0.9352\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2145 - acc: 0.9375 - val_loss: 0.2087 - val_acc: 0.9400\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2040 - acc: 0.9412 - val_loss: 0.1965 - val_acc: 0.9420\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1942 - acc: 0.9442 - val_loss: 0.1930 - val_acc: 0.9431\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1849 - acc: 0.9468 - val_loss: 0.1814 - val_acc: 0.9466\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1768 - acc: 0.9492 - val_loss: 0.1746 - val_acc: 0.9474\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1691 - acc: 0.9512 - val_loss: 0.1686 - val_acc: 0.9510\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1620 - acc: 0.9536 - val_loss: 0.1613 - val_acc: 0.9520\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1556 - acc: 0.9556 - val_loss: 0.1586 - val_acc: 0.9522\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1495 - acc: 0.9573 - val_loss: 0.1518 - val_acc: 0.9539\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1440 - acc: 0.9585 - val_loss: 0.1471 - val_acc: 0.9552\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1388 - acc: 0.9599 - val_loss: 0.1450 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912e265c88>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912e2771d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912e254780>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912e2e3c50>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912e2eb1d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912e2e3da0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.93      0.97      0.95      1010\n",
      "           4       0.96      0.95      0.95       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.96      0.95      0.96       958\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.97      0.92      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    0    2    0    5    2    2    1    2]\n",
      " [   0 1120    3    2    1    1    3    2    3    0]\n",
      " [   7    6  981   12    4    0    5   11    6    0]\n",
      " [   0    1    3  979    0   11    0    8    5    3]\n",
      " [   1    1    5    1  934    0    7    3    3   27]\n",
      " [   7    2    1   13    2  846    9    0    5    7]\n",
      " [  11    4    4    1    7   15  913    0    3    0]\n",
      " [   0   11   11    5    2    1    0  980    0   18]\n",
      " [   5    5    2   21    9   10    7    9  900    6]\n",
      " [   5    9    2   12   17    2    1   13    2  946]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 1.3983 - acc: 0.6642 - val_loss: 0.5989 - val_acc: 0.8520\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.4837 - acc: 0.8700 - val_loss: 0.3823 - val_acc: 0.8957\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.3699 - acc: 0.8957 - val_loss: 0.3247 - val_acc: 0.9088\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3253 - acc: 0.9060 - val_loss: 0.2941 - val_acc: 0.9162\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.2971 - acc: 0.9140 - val_loss: 0.2737 - val_acc: 0.9213\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.2755 - acc: 0.9196 - val_loss: 0.2548 - val_acc: 0.9257\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2579 - acc: 0.9249 - val_loss: 0.2422 - val_acc: 0.9312\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2431 - acc: 0.9297 - val_loss: 0.2265 - val_acc: 0.9353\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.2290 - acc: 0.9337 - val_loss: 0.2173 - val_acc: 0.9391\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2171 - acc: 0.9370 - val_loss: 0.2060 - val_acc: 0.9396\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2060 - acc: 0.9405 - val_loss: 0.2002 - val_acc: 0.9413\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1959 - acc: 0.9431 - val_loss: 0.1898 - val_acc: 0.9435\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1872 - acc: 0.9454 - val_loss: 0.1825 - val_acc: 0.9477\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1788 - acc: 0.9484 - val_loss: 0.1762 - val_acc: 0.9495\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1713 - acc: 0.9503 - val_loss: 0.1699 - val_acc: 0.9493\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.1641 - acc: 0.9524 - val_loss: 0.1667 - val_acc: 0.9513\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1575 - acc: 0.9541 - val_loss: 0.1583 - val_acc: 0.9529\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1516 - acc: 0.9564 - val_loss: 0.1532 - val_acc: 0.9543\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1461 - acc: 0.9576 - val_loss: 0.1478 - val_acc: 0.9559\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1407 - acc: 0.9590 - val_loss: 0.1453 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912f5f6518>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912f5f69b0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912f61bfd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912f6764e0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2912f676630>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2912f65ef98>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.96      1032\n",
      "           3       0.96      0.95      0.95      1010\n",
      "           4       0.95      0.96      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.97      0.94      0.95      1028\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.93      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    1    1    0    4    5    1    1    1]\n",
      " [   0 1115    2    2    0    1    5    1    9    0]\n",
      " [   6    1  983   10    6    1    9    7    8    1]\n",
      " [   2    0    9  956    0   15    0    8   16    4]\n",
      " [   1    0    4    0  941    0    9    2    2   23]\n",
      " [   9    1    2    8    2  843   10    2    9    6]\n",
      " [   7    3    2    0    7   10  925    0    4    0]\n",
      " [   0   10   16    4    5    1    0  963    1   28]\n",
      " [   3    2    4   13    5    7   10    5  920    5]\n",
      " [   5    7    1    6   22    1    1    5    8  953]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 1.4690 - acc: 0.6143 - val_loss: 0.6401 - val_acc: 0.8431\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.4943 - acc: 0.8690 - val_loss: 0.3841 - val_acc: 0.8931\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.3680 - acc: 0.8964 - val_loss: 0.3283 - val_acc: 0.9042\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.3211 - acc: 0.9076 - val_loss: 0.2915 - val_acc: 0.9158\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.2916 - acc: 0.9158 - val_loss: 0.2664 - val_acc: 0.9235\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.2693 - acc: 0.9227 - val_loss: 0.2496 - val_acc: 0.9284\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.2508 - acc: 0.9277 - val_loss: 0.2346 - val_acc: 0.9313\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.2350 - acc: 0.9323 - val_loss: 0.2191 - val_acc: 0.9367\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.2211 - acc: 0.9360 - val_loss: 0.2091 - val_acc: 0.9403\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.2092 - acc: 0.9395 - val_loss: 0.1967 - val_acc: 0.9437\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.1984 - acc: 0.9423 - val_loss: 0.1895 - val_acc: 0.9451\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1890 - acc: 0.9451 - val_loss: 0.1834 - val_acc: 0.9475\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1802 - acc: 0.9476 - val_loss: 0.1722 - val_acc: 0.9506\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.1718 - acc: 0.9499 - val_loss: 0.1674 - val_acc: 0.9501\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1646 - acc: 0.9523 - val_loss: 0.1604 - val_acc: 0.9521\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.1578 - acc: 0.9538 - val_loss: 0.1542 - val_acc: 0.9544\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1514 - acc: 0.9560 - val_loss: 0.1496 - val_acc: 0.9548\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1458 - acc: 0.9579 - val_loss: 0.1455 - val_acc: 0.9567\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1406 - acc: 0.9594 - val_loss: 0.1410 - val_acc: 0.9584\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1357 - acc: 0.9600 - val_loss: 0.1344 - val_acc: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29130c1cd68>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29130c252b0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29130c36780>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29130ca6208>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29130ca67b8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29130c8fcc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.97      0.96      0.96      1032\n",
      "           3       0.95      0.96      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.95      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 963    0    1    1    0    4    6    2    2    1]\n",
      " [   0 1115    1    3    0    1    5    2    8    0]\n",
      " [   9    1  986    8    5    0    3    8   10    2]\n",
      " [   0    0    5  974    0   11    0    7    8    5]\n",
      " [   1    0    2    1  945    0    9    1    2   21]\n",
      " [   7    1    1   12    2  846    9    0   11    3]\n",
      " [   6    3    0    0    9   10  924    0    6    0]\n",
      " [   2   11   16    3    3    0    0  973    2   18]\n",
      " [   4    2    2   19    6    6    8    6  918    3]\n",
      " [   5    6    2    9   18    3    1    7    6  952]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 1.4756 - acc: 0.6226 - val_loss: 0.6314 - val_acc: 0.8399\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.4903 - acc: 0.8682 - val_loss: 0.3847 - val_acc: 0.8946\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.3661 - acc: 0.8965 - val_loss: 0.3214 - val_acc: 0.9087\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.3213 - acc: 0.9080 - val_loss: 0.2930 - val_acc: 0.9173\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.2935 - acc: 0.9160 - val_loss: 0.2733 - val_acc: 0.9239\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.2724 - acc: 0.9219 - val_loss: 0.2530 - val_acc: 0.9273\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.2555 - acc: 0.9261 - val_loss: 0.2408 - val_acc: 0.9306\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2402 - acc: 0.9309 - val_loss: 0.2328 - val_acc: 0.9322\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2273 - acc: 0.9341 - val_loss: 0.2171 - val_acc: 0.9374\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.2154 - acc: 0.9376 - val_loss: 0.2079 - val_acc: 0.9378\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.2048 - acc: 0.9406 - val_loss: 0.2005 - val_acc: 0.9408\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.1951 - acc: 0.9433 - val_loss: 0.1904 - val_acc: 0.9438\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1859 - acc: 0.9461 - val_loss: 0.1841 - val_acc: 0.9454\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1778 - acc: 0.9488 - val_loss: 0.1750 - val_acc: 0.9475\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1706 - acc: 0.9509 - val_loss: 0.1700 - val_acc: 0.9489\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1635 - acc: 0.9531 - val_loss: 0.1651 - val_acc: 0.9506\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1572 - acc: 0.9547 - val_loss: 0.1573 - val_acc: 0.9524\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1511 - acc: 0.9567 - val_loss: 0.1548 - val_acc: 0.9547\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1454 - acc: 0.9578 - val_loss: 0.1490 - val_acc: 0.9568\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1402 - acc: 0.9599 - val_loss: 0.1428 - val_acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29130fdcac8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29130fdcf60>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291310024e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29131061a90>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29131061f28>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291310504a8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.96      0.93      0.95       892\n",
      "           6       0.96      0.97      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.96      0.95      0.95       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 960    0    1    1    0    6    6    2    3    1]\n",
      " [   0 1119    3    2    0    1    3    1    6    0]\n",
      " [   5    2  994    8    6    0    5    5    6    1]\n",
      " [   0    1    5  974    0    7    0   11    8    4]\n",
      " [   1    1    6    0  940    0    5    2    3   24]\n",
      " [   7    2    1   21    3  833    9    1    9    6]\n",
      " [   8    3    4    0    6    8  925    1    3    0]\n",
      " [   0    9   17    4    1    1    0  982    0   14]\n",
      " [   3    2    3   15    6    7    7    5  923    3]\n",
      " [   5    8    3   13   26    4    1    8    3  938]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ########################## FINISHED ##########################\n",
      "\n",
      " Total execution time 4008.715296284522\n"
     ]
    }
   ],
   "source": [
    "#global variables\n",
    "plots_folder = Path(\"plots/\")\n",
    "models_folder = Path(\"models/\")\n",
    "times_dict = {\"Compilation time\": [], \"Training time\": []}\n",
    "total_history = []\n",
    "text_file = \"score file.txt\"\n",
    "train_scores = []\n",
    "evaluation_scores = []\n",
    "model_name = \"fnn_mnist\"\n",
    "\n",
    "#neural net architecture config\n",
    "n_hlayers = 0\n",
    "n_neurons = 401\n",
    "initial_neurons = 128\n",
    "neurons_step = 10\n",
    "n_epochs= 20\n",
    "n_batch_size= 128\n",
    "    \n",
    "text_file =  model_name + \"_\" + text_file\n",
    "\n",
    "start_time = time.clock()\n",
    "print(\"Using keras version %s\" % keras.__version__)\n",
    "\n",
    "#Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # loading of MNIST dataset\n",
    "\n",
    "#check sizes\n",
    "print(\"\\n\")\n",
    "print(\"Number of training examples: '{0}'\".format(x_train.shape[0]))\n",
    "print(\"Size of train samples: '{0}'\".format(x_train.shape[1:]))\n",
    "print(\"Size of test samples: '{0}'\".format(x_test.shape[1:]))\n",
    "\n",
    "#Data to 1D and normalization\n",
    "x_train = x_train.reshape(60000, 784) #60000 observations of 784 features\n",
    "x_test = x_test.reshape(10000, 784) # 10000 observations of 784 features\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Adapts labels to one hot encoding vector for softmax classifier\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "#Neural network architecture\n",
    "if n_neurons==0:\n",
    "    neurons=64\n",
    "    model_name = \"fnn_fixed_neurons\"\n",
    "    plots_folder = plots_folder / model_name\n",
    "    text_file = model_name + \"_\" + text_file\n",
    "    for layers in range(n_hlayers):\n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(initial_neurons, activation='relu', input_shape=(784,)))\n",
    "        for i in range(layers):\n",
    "            nn.add(Dense(neurons, activation = 'relu'))\n",
    "        nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        #Model visualization\n",
    "        #The plot of the model needs pydot, graphviz and pydot-ng\n",
    "        #plot_model(nn, to_file='nn.png', show_shapes = True)\n",
    "\n",
    "        #Compile the model\n",
    "        time_compiling = time.clock()\n",
    "        nn.compile(optimizer = 'sgd', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "        print(\"Compiling the network time {0} with layers equal to {1}\".format(time.clock() - time_compiling, layers + 1))\n",
    "        times_dict[\"Compilation time\"].append(time.clock() - time_compiling)\n",
    "        time_training = time.clock()\n",
    "        #train the model\n",
    "        history = nn.fit(x_train, y_train, batch_size = n_batch_size, epochs=n_epochs, validation_data=(x_test,y_test))\n",
    "        print(\"Training time {0} with layers equal to {1}\".format(time.clock() - time_training, layers + 1))\n",
    "        times_dict[\"Training time\"].append(time.clock() - time_training)\n",
    "        train_scores.append((history.history[\"acc\"][-1], history.history[\"loss\"][-1]))\n",
    "\n",
    "        #Evaluate the model\n",
    "        score = nn.evaluate(x_test, y_test, verbose=0) #returns loss and metrics (accuracy)\n",
    "        evaluation_scores.append(score)\n",
    "\n",
    "        with open('{}'.format(text_file), 'a') as f:\n",
    "            f.write(\"Scores for neural network with {} layers: \\n\".format(layers + 1))\n",
    "            f.write(\"Loss {}\".format(score[0]))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"Accuracy {}\".format(score[1]))\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "        #Store plots\n",
    "        # Accuracy plot\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plot_name = \"model_accuracy_with_{}_layers_and_{}_neurons.\".format(layers+1, neurons)\n",
    "        plt.savefig(plots_folder / plot_name)\n",
    "        plt.close()\n",
    "        # Loss plot\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plot_name = 'model_loss_with_{}_layers_{}_neurons.'.format(layers + 1, neurons)\n",
    "        plt.savefig(plots_folder / plot_name)\n",
    "        plt.close()\n",
    "\n",
    "        total_history.append(history)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        # Compute probabilities\n",
    "        Y_pred = nn.predict(x_test)\n",
    "        # Assign most probable label\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "        # Plot statistics\n",
    "        print('Analysis of results')\n",
    "        target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "        print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "else:\n",
    "    layers = 2\n",
    "    model_name = \"fnn_fixed_layers\"\n",
    "    plots_folder = plots_folder / model_name\n",
    "    text_file = model_name + \"_\" + text_file\n",
    "    for neurons in range(2, n_neurons, neurons_step):\n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(initial_neurons, activation='relu', input_shape=(784,)))\n",
    "        for i in range(layers):\n",
    "            nn.add(Dense(neurons, activation = 'relu'))\n",
    "        nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        #Model visualization\n",
    "        #The plot of the model needs pydot, graphviz and pydot-ng\n",
    "        #plot_model(nn, to_file='nn.png', show_shapes = True)\n",
    "\n",
    "        #Compile the model\n",
    "        time_compiling = time.clock()\n",
    "        nn.compile(optimizer = 'sgd', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "        times_dict[\"Compilation time\"].append(time.clock() - time_compiling)\n",
    "        time_training = time.clock()\n",
    "        #train the model\n",
    "        history = nn.fit(x_train, y_train, batch_size = n_batch_size, epochs=n_epochs, validation_data=(x_test,y_test))\n",
    "        times_dict[\"Training time\"].append(time.clock() - time_training)\n",
    "        train_scores.append((history.history[\"acc\"][-1], history.history[\"loss\"][-1]))\n",
    "\n",
    "        #Evaluate the model\n",
    "        score = nn.evaluate(x_test, y_test, verbose=0) #returns loss and metrics (accuracy)\n",
    "        evaluation_scores.append(score)\n",
    "\n",
    "        with open('{}'.format(text_file), 'a') as f:\n",
    "            f.write(\"Scores for neural network with {} layers: \\n\".format(layers + 1))\n",
    "            f.write(\"Loss {}\".format(score[0]))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"Accuracy {}\".format(score[1]))\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "        #Store plots\n",
    "        # Accuracy plot\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plot_name = \"model_accuracy_with_{}_layers_and_{}_neurons.\".format(layers+1, neurons)\n",
    "        plt.savefig(plots_folder / plot_name)\n",
    "        plt.close()\n",
    "        # Loss plot\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plot_name = 'model_loss_with_{}_layers_{}_neurons.'.format(layers + 1, neurons)\n",
    "        plt.savefig(plots_folder / plot_name)\n",
    "        plt.close()\n",
    "\n",
    "        total_history.append(history)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        # Compute probabilities\n",
    "        Y_pred = nn.predict(x_test)\n",
    "        # Assign most probable label\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "        # Plot statistics\n",
    "        print('Analysis of results')\n",
    "        target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "        print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "#Execution time\n",
    "print(\"\\n\\n\\n\\n ########################## FINISHED ##########################\")\n",
    "print(\"\\n Total execution time {}\".format(time.clock()-start_time))\n",
    "\n",
    "# Ejemplo Confunde el 0 con el 6 (7 errores), el 9 con el 4 (20 errores) y el 3 con el 8 (21 errores).\n",
    "#La NN tiene un 96% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155590780>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291555904a8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155590b70>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291555a2ac8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291555a2fd0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291555a2748>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155a19cc0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29156a4ee48>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29156a4eef0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155574e80>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155535860>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155574b38>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2915552bcc0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2915552bd68>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2915552b518>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2915552b940>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291555812b0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155581358>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155581be0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155588f98>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155588f28>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155588cc0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291555880b8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155a2cbe0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29155a2c4a8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291540cb9b0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2913106f4e0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2913108e2b0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29131093320>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291310fd0b8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291310fd208>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291310fd9e8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291310fda58>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29131103208>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29131103710>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291311037b8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29131103c18>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2913110c278>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2913110c8d0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2913110c9b0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2913110b0f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy by number of neurons')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAKNCAYAAADPmHe4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend = []\n",
    "if n_neurons == 0:\n",
    "    for i in range(n_hlayers):\n",
    "        plt.plot(total_history[i].history['acc'])\n",
    "        legend.append('{} layers'.format(i+1))\n",
    "    plt.legend(legend, loc='lower right')\n",
    "    plt.title('model accuracy by layers')\n",
    "else:\n",
    "    for i in range(len(range(2, n_neurons, neurons_step))):\n",
    "        plt.plot(total_history[i].history['acc'])\n",
    "        legend.append('{} neurons'.format((i+1)*neurons_step))\n",
    "    plt.legend(legend, loc='lower right')\n",
    "    plt.title('model accuracy by number of neurons')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plot_name = \"model_accuracy_by_{}\".format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)    \n",
    "plt.figure(figsize=(18, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'neurons (x10)')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29132524160>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291325826a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy by fnn_fixed_layers')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wM4T/eHvybeFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs = []\n",
    "if n_neurons == 0:\n",
    "    plt.xlabel('layers')\n",
    "    for i in range(n_hlayers):\n",
    "        accs.append(total_history[i].history['acc'][-1])\n",
    "else:\n",
    "    plt.xlabel('neurons (x10)')\n",
    "    for i in range(len(range(2, n_neurons, neurons_step))):\n",
    "        accs.append(total_history[i].history['acc'][-1])\n",
    "plt.plot(accs)\n",
    "plt.legend([\"accuracy\"], loc='lower right')\n",
    "plt.title('model accuracy by {}'.format(model_name))\n",
    "plt.ylabel('accuracy')\n",
    "plot_name = \"model_accuracy_by_{}_end_train\".format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "plt.figure(figsize=(18, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**What is the impact of using more fully connected layers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original code will be rewrited in order to control the number of hidden layers via a global variables called *n_layers* and we will iterate adding that number of hidden layers and comparing the results for *Execution time*, *Accuracy* and *Overfit*.\n",
    "\n",
    "**Observations**\n",
    "1. **Loss / Accuracy**: As we increment the number of layers, usually the first epoch have more loss than the neural network with one less hidden layer but in the following epochs, this loss reduces greatly achieving better accuracy as more hidden layers are in the neural network.\n",
    "2. **Execution time**: It can be seen that compiling time for each new architecture with more layers increases a little. The important one, training time, increases notably as we increment the number of layers. See the table.\n",
    "\n",
    "3. **Overfitting**: An increment on the number of layers is translated to an overfit of the model to the train data in early epochs, meaning that as epochs go, more overfitted is the model.\n",
    "4. It can be seen that the model accuracy increases as more layers are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compilation time</th>\n",
       "      <th>Training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062095</td>\n",
       "      <td>40.741848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064641</td>\n",
       "      <td>43.340195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057543</td>\n",
       "      <td>47.575815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.178859</td>\n",
       "      <td>47.775040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058968</td>\n",
       "      <td>51.453802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.083213</td>\n",
       "      <td>58.632684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.065071</td>\n",
       "      <td>59.571938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.068126</td>\n",
       "      <td>68.751527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.105532</td>\n",
       "      <td>65.098420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.059949</td>\n",
       "      <td>63.728539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compilation time  Training time\n",
       "0          0.062095      40.741848\n",
       "1          0.064641      43.340195\n",
       "2          0.057543      47.575815\n",
       "3          0.178859      47.775040\n",
       "4          0.058968      51.453802\n",
       "5          0.083213      58.632684\n",
       "6          0.065071      59.571938\n",
       "7          0.068126      68.751527\n",
       "8          0.105532      65.098420\n",
       "9          0.059949      63.728539"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Compilation time  Training time\n",
      "0           0.055802      47.947479\n",
      "1           0.077883      51.792892\n",
      "2           0.055119      50.463595\n",
      "3           0.065108      50.621776\n",
      "4           0.055141      50.499480\n",
      "5           0.058145      54.086513\n",
      "6           0.065021      56.869419\n",
      "7           0.053210      54.719876\n",
      "8           0.059923      59.743045\n",
      "9           0.137334      60.796580\n",
      "10          0.057382      67.133086\n",
      "11          0.057005      78.889623\n",
      "12          0.068088      73.143212\n",
      "13          0.058191      71.083842\n",
      "14          0.061237      77.597369\n",
      "15          0.055412      84.911355\n",
      "16          0.066315     108.297998\n",
      "17          0.116726      98.397048\n",
      "18          0.087252     111.641004\n",
      "19          0.142608     123.621867\n",
      "20          0.545281     128.514980\n",
      "21          0.104430     108.078645\n",
      "22          0.107077     118.461728\n",
      "23          0.125893      97.139773\n",
      "24          0.074221     108.984443\n",
      "25          0.068068      98.996843\n",
      "26          0.060766      98.141547\n",
      "27          0.052394     105.820765\n",
      "28          0.087662     110.789414\n",
      "29          0.105689     122.555573\n",
      "30          0.111155     125.802197\n",
      "31          0.063764     162.784012\n",
      "32          0.092644     148.296793\n",
      "33          0.076433     114.287868\n",
      "34          0.053956     115.989889\n",
      "35          0.056926     126.441522\n",
      "36          0.058361     116.050506\n",
      "37          0.076554     124.102406\n",
      "38          0.063167     184.660686\n",
      "39          0.140502     142.187375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Neurons (x10)')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Time')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJuMqEJAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compilation_time = [0.24594317327546378, 0.043510568686087936, 0.04459838010097883, 0.045250085238876636, 0.056358901495514147, 0.052324446456623264, 0.053702240227266884, 0.05874068365619678, 0.05362408092014448, 0.05278094211780626] \n",
    "# train_time = [39.99011794503713, 43.14482466451, 47.26708281148467, 49.6701730114778, 51.091938377238876, 51.03244404152338, 52.43567205865202, 55.833798198711065, 59.904547097023624, 61.02969902625591]\n",
    "\n",
    "times_df = pd.DataFrame(times_dict)\n",
    "print(times_df)\n",
    "ax = times_df.plot(title = 'Execution times comparisson by layers', legend = True)\n",
    "if n_neurons == 0:\n",
    "    ax.set_xlabel(\"Layers\")\n",
    "else:\n",
    "    ax.set_xlabel(\"Neurons (x10)\")\n",
    "ax.set_ylabel(\"Time\")\n",
    "plot_name = \"execution_times\"\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(plots_folder / plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the impact of increasing the number of neurons per layer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From increasing the number of neurons we can draw conclusions similar to the increase of the number of layers:\n",
    "1. An increase in the overall of the training time.\n",
    "2. As more neurons are used, higher is the accuracy.\n",
    "3. Using more neurons seems to be **harder** to get overfitting issues compared to when increasing the number of layers, that makes the overfitting to happen earlier (in epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the best performance you can get out of a basic neural net?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because FNN can get good scores with the MNIST10 dataset, we will use the CIFAR10 dataset and try to achieve a good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using keras version 2.2.2\n",
      "\n",
      "\n",
      "Number of training examples: '50000'\n",
      "Number of test examples: '10000'\n",
      "Size of train samples: '(32, 32, 3)'\n",
      "--Call--\n",
      "> \u001b[1;32mc:\\users\\worldsensing\\anaconda3\\lib\\site-packages\\ipython\\core\\displayhook.py\u001b[0m(247)\u001b[0;36m__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    246 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 247 \u001b[1;33m    \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    248 \u001b[1;33m        \"\"\"Printing with history cache management.\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 14s 275us/step - loss: 2.0359 - acc: 0.2152\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.8486 - acc: 0.3041\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.7761 - acc: 0.3476\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 1.7090 - acc: 0.3744\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 1.6575 - acc: 0.3985\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 1.6155 - acc: 0.4155\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.5756 - acc: 0.4324\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.5504 - acc: 0.4416\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 1.5185 - acc: 0.4547\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.4821 - acc: 0.4691\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 1.4669 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.4472 - acc: 0.4791\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.4189 - acc: 0.4932\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.4049 - acc: 0.4935\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 1.3818 - acc: 0.5049\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3680 - acc: 0.5088\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.3445 - acc: 0.5189\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.3351 - acc: 0.5223\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3174 - acc: 0.5262\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.3003 - acc: 0.53470s - loss: 1.2997 - acc:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22e15bc0208>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22e15bc07f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22e159e0710>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'model loss')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22e159e0860>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.59      0.54      1000\n",
      "           1       0.61      0.58      0.60      1000\n",
      "           2       0.39      0.21      0.27      1000\n",
      "           3       0.32      0.22      0.26      1000\n",
      "           4       0.42      0.43      0.42      1000\n",
      "           5       0.43      0.40      0.42      1000\n",
      "           6       0.46      0.62      0.53      1000\n",
      "           7       0.48      0.61      0.54      1000\n",
      "           8       0.56      0.68      0.62      1000\n",
      "           9       0.61      0.52      0.56      1000\n",
      "\n",
      "   micro avg       0.49      0.49      0.49     10000\n",
      "   macro avg       0.48      0.49      0.48     10000\n",
      "weighted avg       0.48      0.49      0.48     10000\n",
      "\n",
      "[[589  27  39  22  31  10  31  51 162  38]\n",
      " [ 79 582   7  37  17   7  23  34  89 125]\n",
      " [108  23 212  67 196  94 140 110  40  10]\n",
      " [ 44  25  66 221  49 240 183  86  50  36]\n",
      " [ 65  13  89  38 430  43 147 132  33  10]\n",
      " [ 33  15  56 152  53 404 107 118  50  12]\n",
      " [  5  15  37  44 147  61 616  42  19  14]\n",
      " [ 72  22  29  48  78  53  31 610  20  37]\n",
      " [110  53   4  26  20  14  17  19 680  57]\n",
      " [ 65 181   6  44   8  12  31  69  64 520]]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models\\\\fnn_cifar.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-cb214e88005f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[0mnn_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[0mjson_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{0}.json'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_folder\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mjson_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mweights_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"weights-{0}_\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".hdf5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models\\\\fnn_cifar.json'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl81dWd//HXJztZyL6xhkVZBYSA\nAoqoFRC1roNa92qp1VbtdNrazkw7v3Zm2k6ntbZVUUcqLgO2rlRxQwuooBKQfZFFlrAlBMgCCdnO\n7497yaQxCQnk3u/Nzfv5eOTBzf2ee+8nX27yvud8v+d8zTmHiIgIQITXBYiISOhQKIiISAOFgoiI\nNFAoiIhIA4WCiIg0UCiIiEgDhYJIG5nZ02b2721su8PMvnK6zyMSbAoFERFpoFAQEZEGCgUJK/5h\nm++b2RozO2pmT5lZtpm9aWblZrbQzFIbtf+qma03syNmtsjMhjTadraZrfQ/7gUgrslrXW5mq/yP\nXWpmI06x5m+Y2VYzO2Rm882sh/9+M7OHzKzIzEr9P9Nw/7bpZrbBX9seM/unU9phIk0oFCQcXQtc\nApwJXAG8CfwYyMD3nr8PwMzOBOYCDwCZwALgr2YWY2YxwKvAs0Aa8Bf/8+J/7GhgNvBNIB14HJhv\nZrHtKdTMLgJ+AcwAcoGdwDz/5inAJP/PkQJcD5T4tz0FfNM5lwQMB95vz+uKtEShIOHoD865A865\nPcAHwCfOuc+cc8eBV4Cz/e2uB95wzr3rnKsB/hvoBkwAzgWigd8552qccy8Cyxu9xjeAx51znzjn\n6pxzc4Dj/se1x03AbOfcSn99PwLGm1keUAMkAYMBc85tdM7t8z+uBhhqZt2dc4edcyvb+boizVIo\nSDg60Oh2ZTPfJ/pv98D3yRwA51w9sBvo6d+2x/39ipE7G93uC3zPP3R0xMyOAL39j2uPpjVU4OsN\n9HTOvQ/8EXgEOGBmT5hZd3/Ta4HpwE4zW2xm49v5uiLNUihIV7YX3x93wDeGj+8P+x5gH9DTf98J\nfRrd3g38h3MupdFXvHNu7mnWkIBvOGoPgHPu9865McAwfMNI3/ffv9w5dyWQhW+Y68/tfF2RZikU\npCv7M3CZmV1sZtHA9/ANAS0FlgG1wH1mFmVm1wDjGj32SeBuMzvHf0A4wcwuM7Okdtbwv8AdZjbK\nfzziP/ENd+0ws7H+548GjgJVQJ3/mMdNZpbsH/YqA+pOYz+INFAoSJflnNsM3Az8ATiI76D0Fc65\naudcNXANcDtwGN/xh5cbPbYA33GFP/q3b/W3bW8N7wH/CryEr3cyALjBv7k7vvA5jG+IqQTfcQ+A\nW4AdZlYG3O3/OUROm+kiOyIicoJ6CiIi0kChICIiDRQKIiLSQKEgIiINorwuoL0yMjJcXl6e12WI\niHQqK1asOOicyzxZu04XCnl5eRQUFHhdhohIp2JmO0/eSsNHIiLSiEJBREQaKBRERKRBpzum0Jya\nmhoKCwupqqryupSAi4uLo1evXkRHR3tdioiEobAIhcLCQpKSksjLy+PvF7UML845SkpKKCwspF+/\nfl6XIyJhKCyGj6qqqkhPTw/rQAAwM9LT07tEj0hEvBEWoQCEfSCc0FV+ThHxRtiEwslU1dSx90gl\n9VoVVkSkRV0mFKpr6zlYcZyK47Ud/txHjhzh0Ucfbffjpk+fzpEjRzq8HhGRU9VlQiExLopIM8oq\nazr8uVsKhbq61i+GtWDBAlJSUjq8HhGRUxUWZx+1RYQZSXHRlFXW4lJch47NP/jgg2zbto1Ro0YR\nHR1NYmIiubm5rFq1ig0bNnDVVVexe/duqqqquP/++5k5cybwf0t2VFRUcOmll3LeeeexdOlSevbs\nyWuvvUa3bt06rEYRkbYIu1D4f39dz4a9Zc1uq613HK+pIy4mksh2hMLQHt356RXDWtz+y1/+knXr\n1rFq1SoWLVrEZZddxrp16xpOG509ezZpaWlUVlYyduxYrr32WtLT0//uObZs2cLcuXN58sknmTFj\nBi+99BI336wrLIpIcHWZ4SOAqAgDg7q6wB5sHjdu3N/NI/j973/PyJEjOffcc9m9ezdbtmz50mP6\n9evHqFGjABgzZgw7duwIaI0iIs0Ju55Ca5/oAXYcPEpVTR2DcpICdnpnQkJCw+1FixaxcOFCli1b\nRnx8PJMnT252nkFsbGzD7cjISCorKwNSm4hIa7pUTwGge7doquvqqaxp/SBweyQlJVFeXt7sttLS\nUlJTU4mPj2fTpk18/PHHHfa6IiIdLWA9BTPrDTwD5AD1wBPOuYebtDHgYWA6cAy43Tm3MlA1AXSP\ni8KAsspa4mM65sdPT09n4sSJDB8+nG7dupGdnd2wbdq0acyaNYsRI0YwaNAgzj333A55TRGRQDAX\noMlcZpYL5DrnVppZErACuMo5t6FRm+nAd/CFwjnAw865c1p73vz8fNf0IjsbN25kyJAhba5te3EF\nNXWOQTlJbX5MKGnvzysiYmYrnHP5J2sXsOEj59y+E5/6nXPlwEagZ5NmVwLPOJ+PgRR/mARU927R\nHK+to6oDh5BERMJBUI4pmFkecDbwSZNNPYHdjb4v5MvBgZnNNLMCMysoLi4+7Xq6x/mWnQ7ERDYR\nkc4s4KFgZonAS8ADzrmmEwiaO/3nS+NZzrknnHP5zrn8zMzmrzvdnmGwmKgI4mMiKavqfKEQqOE+\nEREIcCiYWTS+QHjeOfdyM00Kgd6Nvu8F7G3v68TFxVFSUtKuP5jdu0VzrLqO6tr69r6cZ05cTyEu\nLs7rUkQkTAXy7CMDngI2Oud+20Kz+cC3zWwevgPNpc65fe19rV69elFYWEh7hpZq6uo5UHac4wej\nSYztPNM1Tlx5TUQkEAL513AicAuw1sxW+e/7MdAHwDk3C1iA78yjrfhOSb3jVF4oOjr6lK5Edslv\nF5OeGMO8meNP5WVFRMJOwELBOfchzR8zaNzGAfcGqoaTmTosh0cXbeXQ0WrSEmK8KkNEJGR0uRnN\njU0bnkO9g4UbDnhdiohISOjSoTCsR3d6pnTj7fX7vS5FRCQkdOlQMDOmDsvhgy0HA3JFNhGRzqZL\nhwLA1GHZVNfVs2hzkdeliIh4rsuHQn5eGukJMby1TkNIIiJdPhQiI4xLhmbzt01FWgtJRLq8Lh8K\nAFOH53C0uo6l2w56XYqIiKcUCsCEAekkxkbx9jqdmioiXZtCAYiNiuSiwVm8u/EAtXWdZy0kEZGO\nplDwmzosh0NHqynYedjrUkREPKNQ8Js8KJOYqAidhSQiXZpCwS8hNopJZ2Twzvr9umaBiHRZCoVG\npg7LYW9pFWv3lHpdioiIJxQKjXxlSDaREaa1kESky1IoNJKaEMM5/dJ0XEFEuiyFQhNTh+Wwrfgo\nW4vKvS5FRCToFApNTBmWDcDb6zWRTUS6HoVCE7nJ3RjZO0XHFUSkSwpYKJjZbDMrMrN1LWxPNbNX\nzGyNmX1qZsMDVUt7TRuWw5rCUvYcqfS6FBGRoApkT+FpYFor238MrHLOjQBuBR4OYC3tMtU/hPSO\negsi0sUELBScc0uAQ600GQq852+7Ccgzs+xA1dMe/TMTOTM7UWchiUiX4+UxhdXANQBmNg7oC/Rq\nrqGZzTSzAjMrKC4uDkpxU4flsHzHIUoqjgfl9UREQoGXofBLINXMVgHfAT4Dmr1QsnPuCedcvnMu\nPzMzMyjFTR2WQ72DhRt1FpKIdB2ehYJzrsw5d4dzbhS+YwqZwBde1dPUsB7d6ZnSTaemikiX4lko\nmFmKmcX4v70LWOKcK/OqnqbMjGnDc/hwy0HKq2q8LkdEJCgCeUrqXGAZMMjMCs3sTjO728zu9jcZ\nAqw3s03ApcD9garlVE0dlkN1XT2LNgfnOIaIiNeiAvXEzrkbT7J9GXBGoF6/I4zpm0pGYgxvrd/P\nFSN7eF2OiEjAaUZzKyIjjEuGZrNoUxFVNXVelyMiEnAKhZOYOiyHo9V1fLT1oNeliIgEnELhJCYM\nyCApNkprIYlIl6BQOImYqAguGpLFuxsOUFtX73U5IiIBpVBog6nDcjh8rIblOw57XYqISEApFNrg\ngjMziY2K0BCSiIQ9hUIbJMRGMenMTN5evx/nnNfliIgEjEKhjS4dnsO+0ipeXFHodSkiIgGjUGij\nK0b2YHz/dP75lXWs3KVjCyISnhQKbRQdGcGjN40mOzmWbz67gv2lVV6XJCLS4RQK7ZCaEMP/3DqW\nY8drmflsgWY5i0jYUSi006CcJH53w9ms3VPKD15cowPPIhJWFAqn4JKh2fzTlEHMX72XRxdt87oc\nEZEOE7BVUsPdPZMHsHl/Of/9zmbOzE7ikqEhcXlpEZHTop7CKTIz/uu6EQzvkcwD8z7j8wPlXpck\nInLaFAqnIS46kiduHUN8bBR3zSng8NFqr0sSETktCoXTlJvcjcdvGcP+sirueX4lNVo0T0Q6sUBe\njnO2mRWZ2boWtieb2V/NbLWZrTezOwJVS6CN7pPKL64+i2XbS/jZXzd4XY6IyCkLZE/haWBaK9vv\nBTY450YCk4HfmFlMAOsJqGvH9GLmpP48+/FOnvt4p9fliIickoCFgnNuCXCotSZAkpkZkOhvWxuo\neoLhh9MGM3lQJv82fz3LtpV4XY6ISLt5eUzhj8AQYC+wFrjfOdepB+QjI4zf33g2fdLjuef5Few+\ndMzrkkRE2sXLUJgKrAJ6AKOAP5pZ9+YamtlMMysws4Li4uJg1thu3eOieeq2sdTVO+6aU0DF8U7d\n+RGRLsbLULgDeNn5bAW+AAY319A594RzLt85l5+ZmRnUIk9Fv4wEHrlpNFuKyvnuC6uor9dSGCLS\nOXgZCruAiwHMLBsYBGz3sJ4Odf4ZmfzLZUN5d8MBHlr4udfliIi0ScCWuTCzufjOKsows0Lgp0A0\ngHNuFvBz4GkzWwsY8EPn3MFA1eOFOybmsXl/OX94fytnZidxxcgeXpckItKqgIWCc+7Gk2zfC0wJ\n1OuHAjPjZ1cNY1txBd9/cTV56Qmc1SvZ67JERFqkGc0BFhsVyWM3jyEtPoaZzxZwoEwX5xGR0KVQ\nCILMpFievC2f0soabv/TcsqrarwuSUSkWQqFIBnWI5lHbxrN5wfK+dZzK6mu7dRTMkQkTCkUgmjy\noCx+ec1ZfLj1ID98SVdtE5HQo4vsBNk/5Pdmf2kVv3n3c3KS4/jhtGanZoiIeEKh4IFvXzSQvaVV\nPLZoGz2S47hlfJ7XJYmIAAoFT5gZP79yGMXlVfxk/noyk+KYNjzH67JERHRMwStRkRH84cbRjOyV\nwv3zPmPFztYWlBURCQ6Fgoe6xUTy1G355CbHceecArYVV3hdkoh0cQoFj6UnxjLn6+OIijBum/0p\nRZrcJiIeUiiEgL7pCcy+fSyHjlZzx9PLtdy2iHhGoRAiRvRK4ZGbRrNpfznfem4FNXWa3CYiwadQ\nCCEXDsriF1efxQdbNLlNRLyhU1JDzIyxvdlXWsVDCz8nNzmO70/V5DYRCR6FQgi67+KB7C+r5JG/\nbSM3uRs3n9vX65JEpItQKIQg3+S24RwoO85PXltHVlIsU4ZpcpuIBJ6OKYSoqMgI/vi1szmrZzLf\nmfsZK3Ye9rokEekCFAohLD4miqduH0tOchx3zVnOdk1uE5EAC1gomNlsMysys3UtbP++ma3yf60z\nszozSwtUPZ1VRmIsc+4YR4QZt87+lMLDx7wuSUTCWCB7Ck8D01ra6Jz7tXNulHNuFPAjYLFzTgsA\nNSMvI4Gnbh9LaWUNVz+6lDWFR7wuSUTCVMBCwTm3BGjrH/kbgbmBqiUcjOqdwkvfmkBMZATXP/4x\n76zf73VJIhKGPD+mYGbx+HoUL3ldS6g7MzuJV+6dwJnZiXzzuRXM/vALr0sSkTDjeSgAVwAftTZ0\nZGYzzazAzAqKi4uDWFroyUqKY97M8VwyJJufvb6Bf5u/nrp6zXwWkY4RCqFwAycZOnLOPeGcy3fO\n5WdmZgaprNDVLSaSx24ew53n9ePppTv45rMFHNUieiLSAdoUCmZ2v5l1N5+nzGylmU053Rc3s2Tg\nAuC1032uriYywvjXy4fysyuH8f6mIq5/YpmW3RaR09bWnsLXnXNlwBQgE7gD+GVrDzCzucAyYJCZ\nFZrZnWZ2t5nd3ajZ1cA7zrmjp1C7ALeOz+PJW/PZXnyUqx75iE37y7wuSUQ6MWvLSpxmtsY5N8LM\nHgYWOedeMbPPnHNnB77Ev5efn+8KCgqC/bIhb92eUr7+9HKOVdfx6E2jmXSmhtlE5P+Y2QrnXP7J\n2rW1p7DCzN4BpgNvm1kSoAX/Q8jwnsm8eu9EeqV2446nlzP3011elyQinVBbQ+FO4EFgrHPuGBCN\nbwhJQkiPlG785e7xTByYwY9eXsuv3tpEvc5MEpF2aGsojAc2O+eOmNnNwL8ApYErS05VUlw0T92W\nz43j+vDYom18Z95nVNXUeV2WiHQSbQ2Fx4BjZjYS+AGwE3gmYFXJaYmOjOA/rx7Ojy4dzBtr9nHT\n/3xCScVxr8sSkU6graFQ63xHpK8EHnbOPQwkBa4sOV1mxjcvGMCjN41m3Z5SrnlsqVZZFZGTamso\nlJvZj4BbgDfMLBLfcQUJcdPPyuV/v3EuFVW1XPPYUhZuOOB1SSISwtoaCtcDx/HNV9gP9AR+HbCq\npEON6ZvKK/dMJDe5G3c9U8CPX1nLsWrNgBaRL2tTKPiD4Hkg2cwuB6qcczqm0In0SY/n1XsnMHNS\nf+Z+uovLf/+hluAWkS9p6zIXM4BPgX8AZgCfmNl1gSxMOl5sVCQ/nj6E5+88h8qaOq55dCmP/G2r\nFtQTkQZtndG8GrjEOVfk/z4TWOicGxng+r5EM5o7RumxGn786lreWLOPcXlp/GbGSHqnxXtdlogE\nSEfPaI44EQh+Je14rISg5Pho/njj2fx2xkg27Ctj+sMf8MpnhbTlQ4KIhK+2/mF/y8zeNrPbzex2\n4A1gQeDKkmAwM64Z3Ys37z+fwblJfPeF1dw3bxWlx2q8Lk1EPNKm4SMAM7sWmAgYsMQ590ogC2uJ\nho8Co67eMWvxNh5693OykmL5zYxRjB+Q7nVZItJB2jp81OZQCBUKhcBavfsI331hFV+UHGXmpP58\n75JBxERppFCks+uQYwpmVm5mZc18lZuZFu4PQyN7p/D6fedx47g+PL54O1c98hFbi8q9LktEgqTV\nUHDOJTnnujfzleSc6x6sIiW44mOi+M+rz+LJW/PZX1bFZb//kGeW7dBBaJEuQOMC0qJLhmbz1gPn\nM2FAOj95bT13PL2cA7rkp0hYUyhIq7KS4ph9+1h+fuUwPt5ewpSHlujUVZEwFrBQMLPZZlZkZuta\naTPZzFaZ2XozWxyoWuT0mBm3jM9jwX3nMzArke++sJpvPLOConL1GkTCTSB7Ck8D01raaGYpwKPA\nV51zw/AtoSEhrH9mIn/+5nj+5bIhfLClmEt+u4RXP9ujXoNIGAlYKDjnlgCHWmnyNeBl59wuf/ui\nVtpKiIiMMO46vz8L7j+fAZkJPPDCKr75rHoNIuHCy2MKZwKpZrbIzFaY2a0tNTSzmWZWYGYFxcXF\nQSxRWjIgM5G/3D2BH08fzKLPi5ny0BJeW6Veg0hn52UoRAFjgMuAqcC/mtmZzTV0zj3hnMt3zuVn\nZmYGs0ZpRWSEMXPSABbcdz556QncP28Vdz+3guJyXfpTpLPyMhQKgbecc0edcweBJUDQV12V0zcw\nK5GXvjWBBy8dzN82FzPlocX8dfVe9RpEOiEvQ+E14HwzizKzeOAcYKOH9chpiIww7r5gAAvuO48+\n6Ql8Z+5n3PP8Sg5WqNcg0pkE8pTUucAyYJCZFZrZnWZ2t5ndDeCc2wi8BazBdwGf/3HOtXj6qnQO\nA7OSeOnu8fxg2iDe21jElIeW8PqavV6XJSJtpAXxJGA+P1DOP/1lNWsKS5l+Vg4/v3I46YmxXpcl\n0iV19EV2RNrtzOwkXv7WBL4/dRDvbjjAJQ8t4Y/vb9GQkkgIU09BgmLz/nL+/Y0NfLDlIDGREVw+\nIpdbJ+QxqneK16WJdAm6noKEpK1F5Ty7bCcvrijkaHUdI3uncNv4vlw2IpfYqEivyxMJWwoFCWnl\nVTW8vHIPc5btYHvxUdITYrhhXG9uOqcvPVK6eV2eSNhRKEin4Jzjo60lzFm2g/c2HsDMmDI0m1vH\n53Fu/zTMzOsSRcJCW0MhKhjFiLTEzDjvjAzOOyOD3YeO8fwnu5i3fBdvrtvPoOwkbp3Ql6tG9SQh\nVm9VkWBQT0FCTlVNHfNX72XO0h2s31tGUlwU/zCmN7eM70u/jASvyxPplDR8JJ2ec46Vu44wZ+kO\nFqzdR51zfHVkD753ySD6pMd7XZ5Ip6JQkLBSVFbFn5bu4E8ffUFdveNr4/rw7YvOIDNJk+FE2kKh\nIGHpQFkVD7+3hReW7yY2KoK7zu/PN87vR1JctNeliYQ0hYKEte3FFfzm3c95Y80+0hJiuPfCgdx8\nbh/NdRBpgUJBuoQ1hUf4r7c28+HWg/RM6cY/XnImV53dk8gIncoq0pjWPpIuYUSvFJ676xyeu/Mc\n0hJi+N5fVjP94Q94b+MBXc9B5BQoFCQsnHdGBq/dO5FHvjaa6rp67pxTwIzHl1Gwo7XLhItIUwoF\nCRsREcZlI3J557uT+I+rh7Oz5BjXzVrGXXOWs3l/udfliXQKOqYgYauyuo7ZH33BrMXbqDhey9Vn\n9+QHUweTkxzndWkiQadjCtLldYuJ5N4LB/LBDy5k5vn9eX3NPr7y28U89eEX1NbVe12eSEhSKEjY\nS4mP4UfTh7DwuxeQn5fKz1/fwBV//IgVOw97XZpIyAnkNZpnm1mRmTV73WUzm2xmpWa2yv/1k0DV\nIgLQJz2eP90+llk3j+bIsWqufWwpD760hsNHq70uTSRkBLKn8DQw7SRtPnDOjfJ//SyAtYgAvlVZ\npw3PZeE/XsDMSf35y4pCLvrNIv68fDf19Z3r+JpIIAQsFJxzSwCdDyghKSE2ih9PH8Ib953HwKxE\nfvDSGmY8voyN+8q8Lk3EU14fUxhvZqvN7E0zG9ZSIzObaWYFZlZQXFwczPokzA3O6c4LM8fz6+tG\nsP3gUS7/w4f8++sbqDhe63VpIp4I6CmpZpYHvO6cG97Mtu5AvXOuwsymAw8758442XPqlFQJlMNH\nq/mvtzcz99Nd5HSP4ydXDOXS4Tm6+puEhZA/JdU5V+acq/DfXgBEm1mGV/WIpCbE8ItrzuLleyaQ\nlhDDPc+v5PY/LWfHwaNelyYSNJ6FgpnlmP8jmJmN89dS4lU9IieM7pPK/G9P5KdXDGXFzsNM+d0S\nfrfwc6pq6rwuTSTgAnbhWzObC0wGMsysEPgpEA3gnJsFXAd8y8xqgUrgBtfZpldL2IqKjOCOif2Y\nflYu//7GRn63cAuvfraHq8/uxYSB6YzslUJMlNeH5EQ6npa5EGmDD7cc5NfvbGZN4RGcg27RkeTn\npTJ+QDoTBmQwvEd3oiIVEhK6dD0FkQA4cqyaT744xLJtJSzbVsLmA76F9pJioxjXL43xA9IZPyCd\nITndidA1HSSEtDUUAjZ8JBKOUuJjmDosh6nDcgA4WHGcj7eXNITEe5uK/O2iObdfur8nkc7ArESd\nxSSdgkJB5DRkJMZy+YgeXD6iBwD7S6tYtv0gy7aVsHRbCW+t39/QbvyAdL4yJIuLh2STGKtfPQlN\nGj4SCaDdh475ehHbS/hw60GKy48TExXBpDMyuWxEDhcPyaZ7XLTXZUoXoOEjkRDQOy2e3mnxzBjb\nm/p6x8pdh1mwdj9vrtvHwo0HiImM4LwzMph+Vi6XDMkmOV4BId5ST0HEA/X1jlWFR3hz7T4WrN3P\nniOVREUYEwdmcNlZuVwyNJvUhBivy5QworOPRDoJ5xxrCktZsHYfC9btY/ehSiIjjAkD0pl+Vi5T\nhmaTnhjrdZnSySkURDoh5xzr95bxxtp9LFi7j50lx4iMMM7tn8alw3O5clQPknQMQk6BQkGkk3PO\nsWFfGW+u3c+CtfvYfvAoSXFR3DY+jzsm5qn3IO2iUBAJIyeGmGYt3sZb6/cTGxXBjeP68I3z+9Mj\npZvX5UknoFAQCVNbiyqYtXgbr362BzO4+uye3H3BAPpnJnpdmoQwhYJImCs8fIwnl2xn3vLdVNfV\nM314Lt+aPIDhPZO9Lk1CkEJBpIsoLj/O7I++4LllOyk/XsvkQZncM3kg4/qleV2ahBCFgkgXU1pZ\nw3Mf7+SpD7/g0NFqxualcs+FA5l8ZqbWXRKFgkhXVVldx7zlu3hyyXb2llYxNLc791w4gEuH5xKp\nlVu7LIWCSBdXXVvPq6v2MGvRNrYfPEq/jASmDc9hbF4qY/qkaUmNLkahICIA1NU73lq3nz999AWr\ndh+htt73Oz8oO4n8vFTG5qWRn5dKr9R4jyuVQFIoiMiXVFbXsWr3EQp2HGL5zsOs3HmYiuO1APRI\njiM/L42xeank56VxZnaShpvCiOerpJrZbOByoMg5N7yVdmOBj4HrnXMvBqoeEYFuMZENV4cDXy9i\n0/4yCnYcZvmOQ3zyRQnzV+8FICkuijF9/T2JvqmM7J1CXHSkl+VLEASsp2Bmk4AK4JmWQsHMIoF3\ngSpgdltCQT0FkcBxzlF4uJLlOw6xfMdhCnYcYktRBQAxkRFcODiT68f2ZtIZmbomdSfjeU/BObfE\nzPJO0uw7wEvA2EDVISJtZ2YN14C4ZnQvAA4frWbFzsN8tO0g81ft5e31B8jpHsd1Y3oxI783fdJ1\nLCKcBPSYgj8UXm+up2BmPYH/BS4CnvK3a7anYGYzgZkAffr0GbNz585AlSwiraiuref9TQd4Yflu\nFn9eTL2DCQPSuX5sb6YOy9HwUgjzvKfQBr8DfuicqzvZxBrn3BPAE+AbPgpCbSLSjJioCKYNz2Xa\n8Fz2lVbyYkEhf16xm/vnrSK5WzRXjerBjLG9GdZDS210Vl72FL4ATqRBBnAMmOmce7W159QxBZHQ\nUl/vWLa9hBeW7+at9fuprq3nrJ7JzBjbm6+O7EFyN82HCAUhcUpqa6HQpN3TtDJ81JhCQSR0HTlW\nzauf7eGFgkI27isjNiqC6WdjHzt1AAAMKUlEQVTlcv3Y3pzTL03LbXjI8+EjM5sLTAYyzKwQ+CkQ\nDeCcmxWo1xUR76TEx3D7xH7cNiGPdXvKmLd8F/NX7eWVz/aQlx7P5EFZ5Oelkt83jZzkOK/LlWZo\n8pqIBFRldR1vrtvHyyv3ULDzEFU19QD0Su1Gft9UxvjnQWiyXGCFxPBRICgURDqvmrp61u8to2DH\nIVbsPEzBzsMUlx8HfJPlRvdJ9QdFKqN6pxAf4+W5MOFFoSAiIc85x+5DvslyBTsPs2LnIT4/4Jss\nFxVhDO3Rnfy+af4hp1SyumvI6VQpFESkUyo9VsPKXYcp2OmbVb169xGO1/qGnM7uk8KNY/tw+chc\n9SLaSaEgImGhurae9XtLWba9hBdXFLK9+CiJsVF8dVQPbhjbm7N6JuuspjZQKIhI2HHOUbDzMHM/\n3cUba/ZxvLaeobnduXFcb746qqfmRLRCoSAiYa20sob5q/Yw99PdbNhXRly0b07EjeP6kN83Vb2H\nJhQKItIlOOdYu6eUect3M3/VXiqO1zIgM4EbxvbhmtE9SU+M9brEkKBQEJEu5+jxWt5Ys4+5y3fx\n2a4jREcaU4bmcMO43kwckEFEF54HoVAQkS5t8/5y5i3fxcsr91BaWUOv1G6M75/OgKxEBmYmMjAr\nkd5p8V1mwpxCQUQEqKqp4+31+3l55R427CtrmCwHvgsH9ctIYGBWoi8sshIZkJnAgMzEsFsG3PO1\nj0REQkFcdCRXjurJlaN6Ar55EFuLK9hWXMG2ogq2FlWwfm8pb67bR73/M7KZbxmOAZn/16sYmJXI\n8J7JYRcWTSkURKRLSY6PZkzfVMb0Tf27+6tq6thRcpStRRVsKzrK1mJfYCzbVtIweS4uOoLzBmZw\n0eBsLhqcFZaL+ikURETw9SgG53RncE73v7u/vt6x50glm/eX88GWYt7bVMTCjUUADM3tzsVDsrho\ncBYje6WExYFsHVMQEWkH5xxbiyp4b1MR728somDnIeodZCTGMHmQLyDOPyODpLjQmkinA80iIkFw\n5Fg1iz8v5v1NRSzaXExpZQ3Rkca4fmlcNDibiwdnkZeR4HWZCgURkWCrratn5a4jvLfpAO9vLGJL\nkW/F1/6ZCVw8OIsLB2WRn5dGTFRE0GtTKIiIeGz3oWO8v6mI9zYV8fG2Eqrr6kmIiWTiwAwuHJzF\n5EGZ5CZ3C0otCgURkRBy9HgtS7eVsGizb5hpz5FKAAbnJHHBoEwuHJTFmL6pREcGphfheSiY2Wzg\ncqDIOTe8me1XAj8H6oFa4AHn3Icne16Fgoh0ds45thRVsGhzEX/bVMzyHYeorXckxUZx3hkZXDgo\niwsGZZLdgRcVCoVQmARUAM+0EAqJwFHnnDOzEcCfnXODT/a8CgURCTflVTV8tLWExZ/7QmJ/WRXg\nO+V18qBMLhycxdm9U4g6jV6E5zOanXNLzCyvle0Vjb5NADrXOJaISAdJiotm2vAcpg3PwTnH5gPl\n/G1TMX/bXMTjS7bz6KJtdI+L4jsXncE3JvUPaC2eTl4zs6uBXwBZwGWttJsJzATo06dPcIoTEfGA\nmTVMovvW5AGUVtbw0daDLNpcRHYQZlAH9ECzv6fwenPDR03aTQJ+4pz7ysmeU8NHIiLt19bho+Cf\nLNsM59wSYICZZXhdi4hIV+ZZKJjZQPNfL8/MRgMxQIlX9YiISACPKZjZXGAykGFmhcBPgWgA59ws\n4FrgVjOrASqB611nmzQhIhJmAnn20Y0n2f4r4FeBen0REWm/kDimICIioUGhICIiDRQKIiLSQKEg\nIiINOt0qqWZWDOw8xYdnAAc7sJyOFur1QejXqPpOj+o7PaFcX1/nXObJGnW6UDgdZlbQlhl9Xgn1\n+iD0a1R9p0f1nZ5Qr68tNHwkIiINFAoiItKgq4XCE14XcBKhXh+Efo2q7/SovtMT6vWdVJc6piAi\nIq3raj0FERFphUJBREQahGUomNk0M9tsZlvN7MFmtsea2Qv+7Z+0dtnQANTW28z+ZmYbzWy9md3f\nTJvJZlZqZqv8Xz8JVn3+199hZmv9r/2lKxqZz+/9+2+Nf+nzYNU2qNF+WWVmZWb2QJM2Qd9/Zjbb\nzIrMbF2j+9LM7F0z2+L/N7WFx97mb7PFzG4LYn2/NrNN/v/DV8wspYXHtvp+CGB9/2Zmexr9P05v\n4bGt/r4HsL4XGtW2w8xWtfDYgO+/DuWcC6svIBLYBvTHd42G1cDQJm3uAWb5b98AvBDE+nKB0f7b\nScDnzdQ3Gd8V67zahzuAjFa2TwfeBAw4F/jEw//r/fgm5Xi6/4BJwGhgXaP7/gt40H/7QeBXzTwu\nDdju/zfVfzs1SPVNAaL8t3/VXH1teT8EsL5/A/6pDe+BVn/fA1Vfk+2/wXf1SE/2X0d+hWNPYRyw\n1Tm33TlXDcwDrmzS5kpgjv/2i8DFJy74E2jOuX3OuZX+2+XARqBnMF67A10JPON8PgZSzCzXgzou\nBrY55051hnuHcb6rBx5qcnfj99kc4KpmHjoVeNc5d8g5dxh4F5gWjPqcc+8452r9334M9Oro122r\nFvZfW7Tl9/20tVaf/2/HDGBuR7+uF8IxFHoCuxt9X8iX/+g2tPH/UpQC6UGprhH/sNXZwCfNbB5v\nZqvN7E0zGxbUwsAB75jZCjOb2cz2tuzjYLiBln8Rvdx/J2Q75/aB78MAkNVMm1DZl1/H1/trzsne\nD4H0bf/w1uwWht9CYf+dDxxwzm1pYbuX+6/dwjEUmvvE3/S827a0CSgzSwReAh5wzpU12bwS35DI\nSOAPwKvBrA2Y6JwbDVwK3Gtmk5psD4X9FwN8FfhLM5u93n/tEQr78p+BWuD5Fpqc7P0QKI8BA4BR\nwD58QzRNeb7/gBtpvZfg1f47JeEYCoVA70bf9wL2ttTGzKKAZE6t63pKzCwaXyA875x7uel251yZ\nc67Cf3sBEG1mGcGqzzm31/9vEfAKvi56Y23Zx4F2KbDSOXeg6Qav918jB04Mq/n/LWqmjaf70n9g\n+3LgJucfAG+qDe+HgHDOHXDO1Tnn6oEnW3hdr/dfFHAN8EJLbbzaf6cqHENhOXCGmfXzf5q8AZjf\npM184MRZHtcB77f0C9HR/OOPTwEbnXO/baFNzoljHGY2Dt//U0mQ6ksws6QTt/EdjFzXpNl8fNfX\nNjM7Fyg9MUwSRC1+OvNy/zXR+H12G/BaM23eBqaYWap/eGSK/76AM7NpwA+BrzrnjrXQpi3vh0DV\n1/g41dUtvG5bft8D6SvAJudcYXMbvdx/p8zrI92B+MJ3dszn+M5K+Gf/fT/D9+YHiMM37LAV+BTo\nH8TazsPXvV0DrPJ/TQfuBu72t/k2sB7fmRQfAxOCWF9//+uu9tdwYv81rs+AR/z7dy2QH+T/33h8\nf+STG93n6f7DF1D7gBp8n17vxHec6j1gi//fNH/bfOB/Gj326/734lbgjiDWtxXfePyJ9+GJM/J6\nAAtaez8Eqb5n/e+vNfj+0Oc2rc///Zd+34NRn//+p0+87xq1Dfr+68gvLXMhIiINwnH4SERETpFC\nQUREGigURESkgUJBREQaKBRERKSBQkEkiPwruL7udR0iLVEoiIhIA4WCSDPM7GYz+9S/Bv7jZhZp\nZhVm9hszW2lm75lZpr/tKDP7uNF1CVL99w80s4X+hflWmtkA/9MnmtmL/msZPB+sFXpF2kKhINKE\nmQ0Brse3kNkooA64CUjAt97SaGAx8FP/Q54BfuicG4FvBu6J+58HHnG+hfkm4JsRC76VcR8AhuKb\n8Tox4D+USBtFeV2ASAi6GBgDLPd/iO+GbzG7ev5v4bPngJfNLBlIcc4t9t8/B/iLf72bns65VwCc\nc1UA/uf71PnXyvFfrSsP+DDwP5bIySkURL7MgDnOuR/93Z1m/9qkXWtrxLQ2JHS80e069HsoIUTD\nRyJf9h5wnZllQcO1lvvi+325zt/ma8CHzrlS4LCZne+//xZgsfNdI6PQzK7yP0esmcUH9acQOQX6\nhCLShHNug5n9C76rZUXgWxnzXuAoMMzMVuC7Wt/1/ofcBszy/9HfDtzhv/8W4HEz+5n/Of4hiD+G\nyCnRKqkibWRmFc65RK/rEAkkDR+JiEgD9RRERKSBegoiItJAoSAiIg0UCiIi0kChICIiDRQKIiLS\n4P8DciHopTweeCQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NN architecture\n",
    "# n_hlayers = 10\n",
    "# n_neurons = 401\n",
    "\n",
    "initial_neurons = 128\n",
    "neurons = 200\n",
    "layers = 10\n",
    "neurons_step = 8\n",
    "n_epochs= 40\n",
    "n_batch_size= 128\n",
    "\n",
    "\n",
    "#global variables\n",
    "plots_folder = Path(\"plots/\")\n",
    "models_folder = Path(\"models/\")\n",
    "dataset_name = \"cifar\"\n",
    "model_name = 'fnn_{}'.format(dataset_name)\n",
    "cifar_nn_times_dict = {\"Compilation time\": [], \"Training time\": []}\n",
    "cifar_fnn_total_history = []\n",
    "text_file = \"CIFAR-FNN score file.txt\"\n",
    "cifar_fnn_train_scores = []\n",
    "cifar_fnn_evaluation_scores = []\n",
    "start_time = time.clock()\n",
    "print(\"Using keras version {0}\".format(keras.__version__))\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # loading of CIFAR10 dataset\n",
    "\n",
    "# check sizes\n",
    "print(\"\\n\")\n",
    "print(\"Number of training examples: '{0}'\".format(x_train.shape[0]))\n",
    "print(\"Number of test examples: '{0}'\".format(x_test.shape[0]))\n",
    "print(\"Size of train samples: '{0}'\".format(x_train.shape[1:]))\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape(50000,np.prod(x_train.shape[1:]))\n",
    "x_test = x_test.reshape(10000, np.prod(x_train.shape[1:]))\n",
    "bp()\n",
    "\n",
    "# Adapts labels to one hot encoding vector for softmax classifier\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Neural network architecture\n",
    "nn = Sequential()\n",
    "nn.add(Dense(initial_neurons, activation='relu', input_shape=x_train.shape[1:]))\n",
    "for i in range(layers):\n",
    "    nn.add(Dense(neurons, activation = 'relu'))\n",
    "nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn.fit(x_train, y_train, batch_size=128, epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Store plots\n",
    "# Accuracy plot\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plot_name = 'model_accuracy_{0}.pdf'.format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "plt.close()\n",
    "# Loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plot_name = 'model_loss_{0}.pdf'.format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "\n",
    "# Confusion Matrix\n",
    "# Compute probabilities\n",
    "Y_pred = nn.predict(test_input_shape)\n",
    "# Assign most probable label\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "# Plot statistics\n",
    "print('Analysis of results')\n",
    "target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "# Saving model and weights\n",
    "nn_json = nn.to_json()\n",
    "json_file_name = '{0}.json'.format(model_name)\n",
    "with open(models_folder / json_file_name, 'w') as json_file:\n",
    "    json_file.write(nn_json)\n",
    "weights_file_name = \"weights-{0}_\".format(model_name) + str(score[1]) + \".hdf5\"\n",
    "weights_file = models_folder / weights_file_name\n",
    "nn.save_weights(weights_file, overwrite=True)\n",
    "\n",
    "# Loading model and weights\n",
    "json_file = open(models_folder / json_file_name, 'r')\n",
    "nn_json = json_file.read()\n",
    "json_file.close()\n",
    "nn = model_from_json(nn_json)\n",
    "nn.load_weights(weights_file)\n",
    "\n",
    "#measuring execution time\n",
    "print(\"Total execution time {} seconds\".format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CNN part the CIFAR10 dataset will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-b0e48495b435>\", line 24, in <module>\n",
      "    get_ipython().magic('matplotlib inline')\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2146, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2067, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-108>\", line 2, in matplotlib\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2930, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 307, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"C:\\Users\\Worldsensing\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import ipdb\n",
    "from ipdb import set_trace as bp\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import plot_model\n",
    "from keras.models import model_from_json #to load a model from a json file.\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(12345678)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global variables\n",
    "plots_folder = Path(\"plots/\")\n",
    "models_folder = Path(\"models/\")\n",
    "times_dict = {\"Compilation time\": [], \"Training time\": []}\n",
    "total_history = []\n",
    "text_file = \"CNN score file.txt\"\n",
    "train_scores = []\n",
    "evaluation_scores = []\n",
    "\n",
    "#neural net architecture config\n",
    "n_hlayers = 0\n",
    "n_neurons = 10\n",
    "initial_neurons = 128\n",
    "neurons_step = 2\n",
    "n_epochs= 20\n",
    "n_batch_size= 128\n",
    "    \n",
    "text_file =  model_name + \"_\" + text_file\n",
    "\n",
    "start_time = time.clock()\n",
    "print(\"Using keras version %s\" % keras.__version__)\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # loading of MNIST dataset\n",
    "\n",
    "# check sizes\n",
    "print(\"\\n\")\n",
    "print(\"Number of training examples: '{0}'\".format(x_train.shape[0]))\n",
    "print(\"Number of test examples: '{0}'\".format(x_test.shape[0]))\n",
    "print(\"Size of train samples: '{0}'\".format(x_train.shape[1:]))\n",
    "\n",
    "# Data to 1D and normalization\n",
    "#x_train = x_train.reshape(60000, 784)  # 60000 observations of 784 features\n",
    "#x_test = x_test.reshape(10000, 784)  # 10000 observations of 784 features\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "train_input_shape = x_train.reshape(*x_train.shape)\n",
    "test_input_shape = x_test.reshape(*x_test.shape)\n",
    "\n",
    "# Adapts labels to one hot encoding vector for softmax classifier\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Neural network architecture\n",
    "# CNN\n",
    "nn = Sequential()\n",
    "nn.add(Conv2D(32, kernel_size=(3,3), activation = 'relu', input_shape=x_train.shape[1:]))\n",
    "nn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "nn.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "nn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(128, activation='relu'))\n",
    "nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Model visualization\n",
    "# The plot of the model needs pydot, graphviz and pydot-ng\n",
    "#plot_model(nn, to_file='nn.png', show_shapes=True)\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn.fit(train_input_shape, y_train, batch_size=128, epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "score = nn.evaluate(test_input_shape, y_test, verbose=0)\n",
    "\n",
    "# Store plots\n",
    "# Accuracy plot\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plot_name = 'model_accuracy_{0}.pdf'.format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "plt.close()\n",
    "# Loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plot_name = 'model_loss_{0}.pdf'.format(model_name)\n",
    "plt.savefig(plots_folder / plot_name)\n",
    "\n",
    "# Confusion Matrix\n",
    "# Compute probabilities\n",
    "Y_pred = nn.predict(test_input_shape)\n",
    "# Assign most probable label\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "# Plot statistics\n",
    "print('Analysis of results')\n",
    "target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "# Saving model and weights\n",
    "nn_json = nn.to_json()\n",
    "json_file_name = '{0}.json'.format(model_name)\n",
    "with open(models_folder / json_file_name, 'w') as json_file:\n",
    "    json_file.write(nn_json)\n",
    "weights_file_name = \"weights-{0}_\".format(model_name) + str(score[1]) + \".hdf5\"\n",
    "weights_file = models_folder / weights_file_name\n",
    "nn.save_weights(weights_file, overwrite=True)\n",
    "\n",
    "# Loading model and weights\n",
    "json_file = open(models_folder / json_file_name, 'r')\n",
    "nn_json = json_file.read()\n",
    "json_file.close()\n",
    "nn = model_from_json(nn_json)\n",
    "nn.load_weights(weights_file)\n",
    "\n",
    "#measuring execution time\n",
    "print(\"Total execution time {} seconds\".format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "1. **Can you design and train a model that overfits on the training data (or on a subset of it)?**\n",
    "2. **When overfitting, what is the result of applying various regularization techniques?**\n",
    "3. **When using ReLUs, how many neurons are dead after a training?**\n",
    "4. **Adding data augmentation improves performance?**\n",
    "5. **How do the different learning algorithms behave for equal architectures? Does regularization have the same affect when using different algorithms?**\n",
    "6. **How hard is it to match the performance of an adaptative algorithm (e.g., Adam) by using an algorithm where parameters have to be hand tunned (e.g., SGD)?**\n",
    "7. **What is the result of using different weight initializations in the training process?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self normalizing activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House numbers, mnist and transer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function visualization"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
